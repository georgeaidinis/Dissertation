{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97cf239",
   "metadata": {},
   "source": [
    "# Use DeepCCA to transform ADNI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3582a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "from objectives import cca_loss\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08db7d",
   "metadata": {},
   "source": [
    "### Read the database, examine it:\n",
    "\n",
    "Instead of reading the whole database, we read only the data that's useful to us. That is, we read only specific columns of data, and we take only the row containing the first scan for each person. \n",
    "\n",
    "In \"ADNI Regressional Analysis.ipynb\" we have done that exactly, as well as performed linear regression transformation to the imaging data, in order to remove any age, sex, and DLICV_baseline effect. \n",
    "\n",
    "Furthermore, in \"ADNI OPNMF.ipynb\" we have performed dimensionality reduction through the OPNMF method, reducing the number of the ROIs from 145 to just 18. (Hasn't been done so this does not apply)\n",
    "\n",
    "The data is located at \"./DATA/Reduced_Linearly_Transformed_Unique_Dataset.pkl\" \n",
    "\n",
    "(Need to run the RA code if data is not found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009c840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 208)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DLICV_baseline</th>\n",
       "      <th>APOE4_Alleles</th>\n",
       "      <th>APOE_Genotype</th>\n",
       "      <th>Diagnosis_nearest_2.0</th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>MUSE_Volume_11</th>\n",
       "      <th>...</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "      <th>Diagnosis_nearest_2.0_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>2006-04-18</td>\n",
       "      <td>84.742466</td>\n",
       "      <td>0</td>\n",
       "      <td>1485405.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>-440.777069</td>\n",
       "      <td>-507.297168</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>2006-05-02</td>\n",
       "      <td>76.283562</td>\n",
       "      <td>1</td>\n",
       "      <td>1364116.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>577.755137</td>\n",
       "      <td>-188.813792</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>2006-05-23</td>\n",
       "      <td>79.223288</td>\n",
       "      <td>0</td>\n",
       "      <td>1570479.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>198.499249</td>\n",
       "      <td>1080.290951</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>002_S_0619</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>77.447945</td>\n",
       "      <td>0</td>\n",
       "      <td>1859348.250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>2623.687012</td>\n",
       "      <td>649.558822</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>2006-07-17</td>\n",
       "      <td>65.056164</td>\n",
       "      <td>1</td>\n",
       "      <td>1166961.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>246.226215</td>\n",
       "      <td>628.340793</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>70.767123</td>\n",
       "      <td>0</td>\n",
       "      <td>1444128.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-145.138564</td>\n",
       "      <td>-193.593195</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>002_S_0938</td>\n",
       "      <td>2006-10-05</td>\n",
       "      <td>82.167123</td>\n",
       "      <td>1</td>\n",
       "      <td>1309685.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>169.421397</td>\n",
       "      <td>-610.085153</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>002_S_0954</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>69.198630</td>\n",
       "      <td>1</td>\n",
       "      <td>1075661.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-81.664210</td>\n",
       "      <td>1343.833768</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>002_S_0955</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>78.161644</td>\n",
       "      <td>1</td>\n",
       "      <td>1363607.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1036.385233</td>\n",
       "      <td>-353.324662</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>002_S_1018</td>\n",
       "      <td>2006-11-29</td>\n",
       "      <td>70.658904</td>\n",
       "      <td>1</td>\n",
       "      <td>1355603.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-495.018850</td>\n",
       "      <td>486.447691</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>002_S_1070</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>73.564384</td>\n",
       "      <td>0</td>\n",
       "      <td>1550701.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>248.001697</td>\n",
       "      <td>515.447841</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>002_S_1261</td>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>71.067123</td>\n",
       "      <td>1</td>\n",
       "      <td>1350714.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>-213.577546</td>\n",
       "      <td>489.130696</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>002_S_1268</td>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>82.642466</td>\n",
       "      <td>0</td>\n",
       "      <td>1435189.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>208.117466</td>\n",
       "      <td>-496.119467</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>002_S_2043</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>72.180822</td>\n",
       "      <td>1</td>\n",
       "      <td>1280567.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-515.936926</td>\n",
       "      <td>-240.054535</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>002_S_4171</td>\n",
       "      <td>2011-08-08</td>\n",
       "      <td>69.353425</td>\n",
       "      <td>0</td>\n",
       "      <td>1522107.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>59.829735</td>\n",
       "      <td>-941.052654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PTID        Date        Age  Sex  DLICV_baseline  APOE4_Alleles  \\\n",
       "0    002_S_0295  2006-04-18  84.742466    0     1485405.375            1.0   \n",
       "9    002_S_0413  2006-05-02  76.283562    1     1364116.000            0.0   \n",
       "24   002_S_0559  2006-05-23  79.223288    0     1570479.625            1.0   \n",
       "31   002_S_0619  2006-06-01  77.447945    0     1859348.250            2.0   \n",
       "45   002_S_0729  2006-07-17  65.056164    1     1166961.750            1.0   \n",
       "64   002_S_0816  2006-08-30  70.767123    0     1444128.125            2.0   \n",
       "69   002_S_0938  2006-10-05  82.167123    1     1309685.000            0.0   \n",
       "74   002_S_0954  2006-10-10  69.198630    1     1075661.500            1.0   \n",
       "81   002_S_0955  2006-10-11  78.161644    1     1363607.000            1.0   \n",
       "84   002_S_1018  2006-11-29  70.658904    1     1355603.000            0.0   \n",
       "90   002_S_1070  2006-11-28  73.564384    0     1550701.375            0.0   \n",
       "113  002_S_1261  2007-02-15  71.067123    1     1350714.875            0.0   \n",
       "127  002_S_1268  2007-02-14  82.642466    0     1435189.875            1.0   \n",
       "147  002_S_2043  2010-08-31  72.180822    1     1280567.125            1.0   \n",
       "163  002_S_4171  2011-08-08  69.353425    0     1522107.375            0.0   \n",
       "\n",
       "    APOE_Genotype Diagnosis_nearest_2.0  MUSE_Volume_4  MUSE_Volume_11  ...  \\\n",
       "0           E3/E4                    CN    -440.777069     -507.297168  ...   \n",
       "9           E3/E3                    CN     577.755137     -188.813792  ...   \n",
       "24          E3/E4                    CN     198.499249     1080.290951  ...   \n",
       "31          E4/E4              Dementia    2623.687012      649.558822  ...   \n",
       "45          E3/E4                   MCI     246.226215      628.340793  ...   \n",
       "64          E4/E4              Dementia    -145.138564     -193.593195  ...   \n",
       "69          E3/E3              Dementia     169.421397     -610.085153  ...   \n",
       "74          E3/E4                   MCI     -81.664210     1343.833768  ...   \n",
       "81          E3/E4              Dementia    1036.385233     -353.324662  ...   \n",
       "84          E3/E3              Dementia    -495.018850      486.447691  ...   \n",
       "90          E3/E3                   MCI     248.001697      515.447841  ...   \n",
       "113         E3/E3                    CN    -213.577546      489.130696  ...   \n",
       "127         E3/E4                   MCI     208.117466     -496.119467  ...   \n",
       "147         E3/E4                   MCI    -515.936926     -240.054535  ...   \n",
       "163         E3/E3                   MCI      59.829735     -941.052654  ...   \n",
       "\n",
       "     rs111278892  rs3752246  rs4147929  rs41289512  rs3865444  rs6024870  \\\n",
       "0              1          1          1           0          0          0   \n",
       "9              0          1          1           0          1          0   \n",
       "24             0          0          0           0          1          0   \n",
       "31             0          0          0           1          1          0   \n",
       "45             0          0          0           1          1          0   \n",
       "64             0          0          0           0          1          0   \n",
       "69             0          1          1           0          1          0   \n",
       "74             2          1          1           0          1          0   \n",
       "81             1          0          0           0          1          0   \n",
       "84             1          1          1           0          0          0   \n",
       "90             0          0          0           0          0          0   \n",
       "113            0          0          0           0          0          1   \n",
       "127            0          0          0           0          1          1   \n",
       "147            0          0          0           1          0          0   \n",
       "163            0          0          0           0          0          0   \n",
       "\n",
       "     rs6014724  rs7274581  rs429358  Diagnosis_nearest_2.0_cat  \n",
       "0            0          0         1                          0  \n",
       "9            0          0         0                          0  \n",
       "24           0          0         0                          0  \n",
       "31           0          0         2                          1  \n",
       "45           0          0         1                          2  \n",
       "64           0          0         2                          1  \n",
       "69           0          0         0                          1  \n",
       "74           0          0         1                          2  \n",
       "81           0          0         1                          1  \n",
       "84           0          0         0                          1  \n",
       "90           0          0         0                          2  \n",
       "113          1          1         0                          0  \n",
       "127          1          1         1                          2  \n",
       "147          0          0         1                          2  \n",
       "163          0          1         0                          2  \n",
       "\n",
       "[15 rows x 208 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = pd.read_pickle(\"./DATA/Linearly_Transformed_Unique_Dataset.pkl\")\n",
    "print(unique.shape)\n",
    "unique.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c020f",
   "metadata": {},
   "source": [
    "### Create the 2 views:\n",
    "\n",
    "The first view consists of the imaging data, that are in the form of 145 real numbers. Those numbers are based on a prediction from a Linear Regression estimator trained only on the Cognitive Normal datapoints. The predictions then are subtracted from the actual values, and the remaining value (residual) is the datapoint for each ROI.\n",
    "\n",
    "The second view consists of the 54 SNP (Single Nucleotide Polymorphism, \"snip\"), for each individual. They are either 0 or 1. \n",
    "\n",
    "The 2 views are the most basic views that can be used for the Deep CCA, and in further tests more features will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ded1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afced851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>MUSE_Volume_11</th>\n",
       "      <th>MUSE_Volume_23</th>\n",
       "      <th>MUSE_Volume_30</th>\n",
       "      <th>MUSE_Volume_31</th>\n",
       "      <th>MUSE_Volume_32</th>\n",
       "      <th>MUSE_Volume_35</th>\n",
       "      <th>MUSE_Volume_36</th>\n",
       "      <th>MUSE_Volume_37</th>\n",
       "      <th>MUSE_Volume_38</th>\n",
       "      <th>...</th>\n",
       "      <th>MUSE_Volume_198</th>\n",
       "      <th>MUSE_Volume_199</th>\n",
       "      <th>MUSE_Volume_200</th>\n",
       "      <th>MUSE_Volume_201</th>\n",
       "      <th>MUSE_Volume_202</th>\n",
       "      <th>MUSE_Volume_203</th>\n",
       "      <th>MUSE_Volume_204</th>\n",
       "      <th>MUSE_Volume_205</th>\n",
       "      <th>MUSE_Volume_206</th>\n",
       "      <th>MUSE_Volume_207</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-440.777069</td>\n",
       "      <td>-507.297168</td>\n",
       "      <td>-35.171797</td>\n",
       "      <td>-14.510211</td>\n",
       "      <td>90.244138</td>\n",
       "      <td>140.075639</td>\n",
       "      <td>299.828133</td>\n",
       "      <td>63.889680</td>\n",
       "      <td>56.259492</td>\n",
       "      <td>4434.963481</td>\n",
       "      <td>...</td>\n",
       "      <td>745.557312</td>\n",
       "      <td>-188.954470</td>\n",
       "      <td>-1594.432454</td>\n",
       "      <td>-1648.308374</td>\n",
       "      <td>798.003198</td>\n",
       "      <td>-468.672456</td>\n",
       "      <td>-81.798945</td>\n",
       "      <td>283.990527</td>\n",
       "      <td>-134.708868</td>\n",
       "      <td>-102.291612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>577.755137</td>\n",
       "      <td>-188.813792</td>\n",
       "      <td>35.574764</td>\n",
       "      <td>-39.881572</td>\n",
       "      <td>40.161648</td>\n",
       "      <td>58.255314</td>\n",
       "      <td>-909.956510</td>\n",
       "      <td>-107.325098</td>\n",
       "      <td>118.445748</td>\n",
       "      <td>-932.590538</td>\n",
       "      <td>...</td>\n",
       "      <td>1336.384182</td>\n",
       "      <td>2631.004114</td>\n",
       "      <td>1410.754665</td>\n",
       "      <td>30.295558</td>\n",
       "      <td>-1258.071206</td>\n",
       "      <td>115.187177</td>\n",
       "      <td>-175.177715</td>\n",
       "      <td>-533.517736</td>\n",
       "      <td>-37.990106</td>\n",
       "      <td>-475.586534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>198.499249</td>\n",
       "      <td>1080.290951</td>\n",
       "      <td>137.416288</td>\n",
       "      <td>142.586830</td>\n",
       "      <td>121.231074</td>\n",
       "      <td>41.449232</td>\n",
       "      <td>1825.886437</td>\n",
       "      <td>-267.694901</td>\n",
       "      <td>6.605333</td>\n",
       "      <td>-947.176391</td>\n",
       "      <td>...</td>\n",
       "      <td>-1764.158370</td>\n",
       "      <td>-2206.292278</td>\n",
       "      <td>1473.087979</td>\n",
       "      <td>532.054466</td>\n",
       "      <td>1714.763199</td>\n",
       "      <td>2469.640085</td>\n",
       "      <td>209.533224</td>\n",
       "      <td>-49.858132</td>\n",
       "      <td>-206.268764</td>\n",
       "      <td>-117.520261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2623.687012</td>\n",
       "      <td>649.558822</td>\n",
       "      <td>-162.939446</td>\n",
       "      <td>-122.191780</td>\n",
       "      <td>-329.934406</td>\n",
       "      <td>-351.510297</td>\n",
       "      <td>-3426.992838</td>\n",
       "      <td>-826.297201</td>\n",
       "      <td>-713.213854</td>\n",
       "      <td>-355.750507</td>\n",
       "      <td>...</td>\n",
       "      <td>-641.454806</td>\n",
       "      <td>583.322773</td>\n",
       "      <td>-701.560285</td>\n",
       "      <td>-1369.412583</td>\n",
       "      <td>-2919.253412</td>\n",
       "      <td>-2766.270514</td>\n",
       "      <td>-757.912814</td>\n",
       "      <td>-822.771500</td>\n",
       "      <td>-347.672981</td>\n",
       "      <td>-131.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>246.226215</td>\n",
       "      <td>628.340793</td>\n",
       "      <td>10.979183</td>\n",
       "      <td>24.346908</td>\n",
       "      <td>-165.999584</td>\n",
       "      <td>-114.587813</td>\n",
       "      <td>171.517739</td>\n",
       "      <td>628.498317</td>\n",
       "      <td>88.705570</td>\n",
       "      <td>-521.590388</td>\n",
       "      <td>...</td>\n",
       "      <td>-346.626209</td>\n",
       "      <td>-670.579403</td>\n",
       "      <td>163.045892</td>\n",
       "      <td>1008.186971</td>\n",
       "      <td>-1557.957769</td>\n",
       "      <td>-1396.447884</td>\n",
       "      <td>-146.495250</td>\n",
       "      <td>-188.233592</td>\n",
       "      <td>-200.821122</td>\n",
       "      <td>-254.208574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MUSE_Volume_4  MUSE_Volume_11  MUSE_Volume_23  MUSE_Volume_30  \\\n",
       "0     -440.777069     -507.297168      -35.171797      -14.510211   \n",
       "9      577.755137     -188.813792       35.574764      -39.881572   \n",
       "24     198.499249     1080.290951      137.416288      142.586830   \n",
       "31    2623.687012      649.558822     -162.939446     -122.191780   \n",
       "45     246.226215      628.340793       10.979183       24.346908   \n",
       "\n",
       "    MUSE_Volume_31  MUSE_Volume_32  MUSE_Volume_35  MUSE_Volume_36  \\\n",
       "0        90.244138      140.075639      299.828133       63.889680   \n",
       "9        40.161648       58.255314     -909.956510     -107.325098   \n",
       "24      121.231074       41.449232     1825.886437     -267.694901   \n",
       "31     -329.934406     -351.510297    -3426.992838     -826.297201   \n",
       "45     -165.999584     -114.587813      171.517739      628.498317   \n",
       "\n",
       "    MUSE_Volume_37  MUSE_Volume_38  ...  MUSE_Volume_198  MUSE_Volume_199  \\\n",
       "0        56.259492     4434.963481  ...       745.557312      -188.954470   \n",
       "9       118.445748     -932.590538  ...      1336.384182      2631.004114   \n",
       "24        6.605333     -947.176391  ...     -1764.158370     -2206.292278   \n",
       "31     -713.213854     -355.750507  ...      -641.454806       583.322773   \n",
       "45       88.705570     -521.590388  ...      -346.626209      -670.579403   \n",
       "\n",
       "    MUSE_Volume_200  MUSE_Volume_201  MUSE_Volume_202  MUSE_Volume_203  \\\n",
       "0      -1594.432454     -1648.308374       798.003198      -468.672456   \n",
       "9       1410.754665        30.295558     -1258.071206       115.187177   \n",
       "24      1473.087979       532.054466      1714.763199      2469.640085   \n",
       "31      -701.560285     -1369.412583     -2919.253412     -2766.270514   \n",
       "45       163.045892      1008.186971     -1557.957769     -1396.447884   \n",
       "\n",
       "    MUSE_Volume_204  MUSE_Volume_205  MUSE_Volume_206  MUSE_Volume_207  \n",
       "0        -81.798945       283.990527      -134.708868      -102.291612  \n",
       "9       -175.177715      -533.517736       -37.990106      -475.586534  \n",
       "24       209.533224       -49.858132      -206.268764      -117.520261  \n",
       "31      -757.912814      -822.771500      -347.672981      -131.863034  \n",
       "45      -146.495250      -188.233592      -200.821122      -254.208574  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs4575098</th>\n",
       "      <th>rs6656401</th>\n",
       "      <th>rs2093760</th>\n",
       "      <th>rs4844610</th>\n",
       "      <th>rs4663105</th>\n",
       "      <th>rs6733839</th>\n",
       "      <th>rs10933431</th>\n",
       "      <th>rs35349669</th>\n",
       "      <th>rs6448453</th>\n",
       "      <th>rs190982</th>\n",
       "      <th>...</th>\n",
       "      <th>rs28394864</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs4575098  rs6656401  rs2093760  rs4844610  rs4663105  rs6733839  \\\n",
       "0           0          0          0          0          1          1   \n",
       "9           1          0          0          0          0          0   \n",
       "24          0          0          0          0          1          0   \n",
       "31          0          1          1          1          0          0   \n",
       "45          0          0          0          0          1          1   \n",
       "\n",
       "    rs10933431  rs35349669  rs6448453  rs190982  ...  rs28394864  rs111278892  \\\n",
       "0            1           0          0         1  ...           0            1   \n",
       "9            0           1          0         0  ...           1            0   \n",
       "24           1           0          0         1  ...           2            0   \n",
       "31           0           2          1         1  ...           1            0   \n",
       "45           0           1          0         0  ...           1            0   \n",
       "\n",
       "    rs3752246  rs4147929  rs41289512  rs3865444  rs6024870  rs6014724  \\\n",
       "0           1          1           0          0          0          0   \n",
       "9           1          1           0          1          0          0   \n",
       "24          0          0           0          1          0          0   \n",
       "31          0          0           1          1          0          0   \n",
       "45          0          0           1          1          0          0   \n",
       "\n",
       "    rs7274581  rs429358  \n",
       "0           0         1  \n",
       "9           0         0  \n",
       "24          0         0  \n",
       "31          0         2  \n",
       "45          0         1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"View 1:\")\n",
    "display(view_1.head())\n",
    "print(\"View 2:\")\n",
    "display(view_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8102d",
   "metadata": {},
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2abc22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a gpu exists, torch.device should be 'gpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 145\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 145 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "# this apparently can be different for each network, some experimentation is needed!\n",
    "layer_sizes1 = [256, 1024, 1024, outdim_size]\n",
    "layer_sizes2 = [256, 1024, 1024, outdim_size]\n",
    "# layer_sizes1 = [64, 128, outdim_size]\n",
    "# layer_sizes2 = [64, 128, outdim_size]\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-3\n",
    "epoch_num = 400\n",
    "batch_size = 1000\n",
    "\n",
    "# the path to save the final learned features, as DCCA-o-d.\n",
    "save_to = './DATA/ADNI_DCCA_features_'+str(outdim_size)+'_'+str(len(layer_sizes1)-1)+'.pkl'\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-3\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top \n",
    "# outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = False\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32dded",
   "metadata": {},
   "source": [
    "###  Building, training, and producing the new features by DCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4ebdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e14d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145) <class 'numpy.ndarray'> float64\n",
      "(1302, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1302, 145]) <class 'torch.Tensor'>\n",
      "torch.Size([1302, 54]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Scramble the datapoints for randomness:\n",
    "indices = np.arange(view_1_n.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "view_1_n = view_1_n[indices]\n",
    "view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f516e24f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2022-01-18 20:04:09,889 ] - DataParallel(\n",
      "  (module): DeepCCA(\n",
      "    (model1): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=145, out_features=256, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=145, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model2): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=54, out_features=256, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=145, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[ INFO : 2022-01-18 20:04:09,890 ] - RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    weight_decay: 0.001\n",
      ")\n",
      "[ INFO : 2022-01-18 20:04:10,817 ] - Epoch 1: val_loss improved from 0.0000 to -7.2871\n",
      "[ INFO : 2022-01-18 20:04:10,817 ] - Epoch 1/400 - time: 0.93 - training_loss: -42.1357 - val_loss: -7.2871\n",
      "[ INFO : 2022-01-18 20:04:11,722 ] - Epoch 2: val_loss improved from -7.2871 to -10.0987\n",
      "[ INFO : 2022-01-18 20:04:12,615 ] - Epoch 3: val_loss improved from -10.0987 to -12.5239\n",
      "[ INFO : 2022-01-18 20:04:13,523 ] - Epoch 4: val_loss improved from -12.5239 to -14.7283\n",
      "[ INFO : 2022-01-18 20:04:14,415 ] - Epoch 5: val_loss improved from -14.7283 to -16.7445\n",
      "[ INFO : 2022-01-18 20:04:15,309 ] - Epoch 6: val_loss improved from -16.7445 to -18.6885\n",
      "[ INFO : 2022-01-18 20:04:16,212 ] - Epoch 7: val_loss improved from -18.6885 to -20.6345\n",
      "[ INFO : 2022-01-18 20:04:17,101 ] - Epoch 8: val_loss improved from -20.6345 to -22.2768\n",
      "[ INFO : 2022-01-18 20:04:17,988 ] - Epoch 9: val_loss improved from -22.2768 to -23.9260\n",
      "[ INFO : 2022-01-18 20:04:18,881 ] - Epoch 10: val_loss improved from -23.9260 to -25.7469\n",
      "[ INFO : 2022-01-18 20:04:19,767 ] - Epoch 11: val_loss improved from -25.7469 to -27.1890\n",
      "[ INFO : 2022-01-18 20:04:20,653 ] - Epoch 12: val_loss improved from -27.1890 to -28.5856\n",
      "[ INFO : 2022-01-18 20:04:21,540 ] - Epoch 13: val_loss improved from -28.5856 to -29.8896\n",
      "[ INFO : 2022-01-18 20:04:22,429 ] - Epoch 14: val_loss improved from -29.8896 to -31.2249\n",
      "[ INFO : 2022-01-18 20:04:23,317 ] - Epoch 15: val_loss improved from -31.2249 to -32.6710\n",
      "[ INFO : 2022-01-18 20:04:24,204 ] - Epoch 16: val_loss improved from -32.6710 to -34.1611\n",
      "[ INFO : 2022-01-18 20:04:25,093 ] - Epoch 17: val_loss improved from -34.1611 to -35.6030\n",
      "[ INFO : 2022-01-18 20:04:25,979 ] - Epoch 18: val_loss improved from -35.6030 to -37.3330\n",
      "[ INFO : 2022-01-18 20:04:26,867 ] - Epoch 19: val_loss improved from -37.3330 to -39.3718\n",
      "[ INFO : 2022-01-18 20:04:27,754 ] - Epoch 20: val_loss improved from -39.3718 to -41.5282\n",
      "[ INFO : 2022-01-18 20:04:28,642 ] - Epoch 21: val_loss improved from -41.5282 to -43.8995\n",
      "[ INFO : 2022-01-18 20:04:28,642 ] - Epoch 21/400 - time: 0.89 - training_loss: -97.4464 - val_loss: -43.8995\n",
      "[ INFO : 2022-01-18 20:04:29,532 ] - Epoch 22: val_loss improved from -43.8995 to -47.1034\n",
      "[ INFO : 2022-01-18 20:04:30,420 ] - Epoch 23: val_loss improved from -47.1034 to -50.4289\n",
      "[ INFO : 2022-01-18 20:04:31,311 ] - Epoch 24: val_loss improved from -50.4289 to -54.2849\n",
      "[ INFO : 2022-01-18 20:04:32,199 ] - Epoch 25: val_loss improved from -54.2849 to -58.8187\n",
      "[ INFO : 2022-01-18 20:04:33,088 ] - Epoch 26: val_loss improved from -58.8187 to -63.4094\n",
      "[ INFO : 2022-01-18 20:04:33,978 ] - Epoch 27: val_loss improved from -63.4094 to -68.4702\n",
      "[ INFO : 2022-01-18 20:04:34,867 ] - Epoch 28: val_loss improved from -68.4702 to -73.0537\n",
      "[ INFO : 2022-01-18 20:04:35,756 ] - Epoch 29: val_loss improved from -73.0537 to -77.9225\n",
      "[ INFO : 2022-01-18 20:04:36,645 ] - Epoch 30: val_loss improved from -77.9225 to -82.2871\n",
      "[ INFO : 2022-01-18 20:04:37,534 ] - Epoch 31: val_loss improved from -82.2871 to -86.6975\n",
      "[ INFO : 2022-01-18 20:04:38,423 ] - Epoch 32: val_loss improved from -86.6975 to -90.1598\n",
      "[ INFO : 2022-01-18 20:04:39,313 ] - Epoch 33: val_loss improved from -90.1598 to -93.6612\n",
      "[ INFO : 2022-01-18 20:04:40,202 ] - Epoch 34: val_loss improved from -93.6612 to -96.5007\n",
      "[ INFO : 2022-01-18 20:04:41,092 ] - Epoch 35: val_loss improved from -96.5007 to -99.0531\n",
      "[ INFO : 2022-01-18 20:04:41,984 ] - Epoch 36: val_loss improved from -99.0531 to -101.0988\n",
      "[ INFO : 2022-01-18 20:04:42,874 ] - Epoch 37: val_loss improved from -101.0988 to -102.9315\n",
      "[ INFO : 2022-01-18 20:04:43,765 ] - Epoch 38: val_loss improved from -102.9315 to -104.5041\n",
      "[ INFO : 2022-01-18 20:04:44,654 ] - Epoch 39: val_loss improved from -104.5041 to -105.8922\n",
      "[ INFO : 2022-01-18 20:04:45,544 ] - Epoch 40: val_loss improved from -105.8922 to -106.8265\n",
      "[ INFO : 2022-01-18 20:04:46,438 ] - Epoch 41: val_loss improved from -106.8265 to -107.9407\n",
      "[ INFO : 2022-01-18 20:04:46,438 ] - Epoch 41/400 - time: 0.89 - training_loss: -115.9609 - val_loss: -107.9407\n",
      "[ INFO : 2022-01-18 20:04:47,330 ] - Epoch 42: val_loss improved from -107.9407 to -108.6773\n",
      "[ INFO : 2022-01-18 20:04:48,220 ] - Epoch 43: val_loss improved from -108.6773 to -109.3487\n",
      "[ INFO : 2022-01-18 20:04:49,110 ] - Epoch 44: val_loss improved from -109.3487 to -110.1421\n",
      "[ INFO : 2022-01-18 20:04:50,001 ] - Epoch 45: val_loss improved from -110.1421 to -110.3088\n",
      "[ INFO : 2022-01-18 20:04:50,891 ] - Epoch 46: val_loss improved from -110.3088 to -110.9496\n",
      "[ INFO : 2022-01-18 20:04:51,782 ] - Epoch 47: val_loss improved from -110.9496 to -111.2314\n",
      "[ INFO : 2022-01-18 20:04:52,673 ] - Epoch 48: val_loss improved from -111.2314 to -111.4244\n",
      "[ INFO : 2022-01-18 20:04:53,570 ] - Epoch 49: val_loss improved from -111.4244 to -111.8840\n",
      "[ INFO : 2022-01-18 20:04:54,472 ] - Epoch 50: val_loss improved from -111.8840 to -111.9604\n",
      "[ INFO : 2022-01-18 20:04:55,363 ] - Epoch 51: val_loss improved from -111.9604 to -112.4716\n",
      "[ INFO : 2022-01-18 20:04:57,144 ] - Epoch 53: val_loss improved from -112.4716 to -112.9518\n",
      "[ INFO : 2022-01-18 20:04:58,925 ] - Epoch 55: val_loss improved from -112.9518 to -113.0925\n",
      "[ INFO : 2022-01-18 20:04:59,816 ] - Epoch 56: val_loss improved from -113.0925 to -113.1259\n",
      "[ INFO : 2022-01-18 20:05:00,707 ] - Epoch 57: val_loss improved from -113.1259 to -113.3329\n",
      "[ INFO : 2022-01-18 20:05:02,489 ] - Epoch 59: val_loss improved from -113.3329 to -113.3926\n",
      "[ INFO : 2022-01-18 20:05:04,284 ] - Epoch 61: val_loss improved from -113.3926 to -113.4712\n",
      "[ INFO : 2022-01-18 20:05:04,285 ] - Epoch 61/400 - time: 0.90 - training_loss: -124.0947 - val_loss: -113.4712\n",
      "[ INFO : 2022-01-18 20:05:06,068 ] - Epoch 63: val_loss improved from -113.4712 to -113.5161\n",
      "[ INFO : 2022-01-18 20:05:07,850 ] - Epoch 65: val_loss improved from -113.5161 to -113.6928\n",
      "[ INFO : 2022-01-18 20:05:08,743 ] - Epoch 66: val_loss improved from -113.6928 to -113.7188\n",
      "[ INFO : 2022-01-18 20:05:09,634 ] - Epoch 67: val_loss improved from -113.7188 to -113.8772\n",
      "[ INFO : 2022-01-18 20:05:11,415 ] - Epoch 69: val_loss improved from -113.8772 to -113.9035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2022-01-18 20:05:13,196 ] - Epoch 71: val_loss improved from -113.9035 to -113.9043\n",
      "[ INFO : 2022-01-18 20:05:14,978 ] - Epoch 73: val_loss improved from -113.9043 to -114.0526\n",
      "[ INFO : 2022-01-18 20:05:16,772 ] - Epoch 75: val_loss improved from -114.0526 to -114.0808\n",
      "[ INFO : 2022-01-18 20:05:18,565 ] - Epoch 77: val_loss improved from -114.0808 to -114.2100\n",
      "[ INFO : 2022-01-18 20:05:20,359 ] - Epoch 79: val_loss improved from -114.2100 to -114.2561\n",
      "[ INFO : 2022-01-18 20:05:22,155 ] - Epoch 81: val_loss improved from -114.2561 to -114.2873\n",
      "[ INFO : 2022-01-18 20:05:22,156 ] - Epoch 81/400 - time: 0.90 - training_loss: -128.6093 - val_loss: -114.2873\n",
      "[ INFO : 2022-01-18 20:05:23,939 ] - Epoch 83: val_loss improved from -114.2873 to -114.3051\n",
      "[ INFO : 2022-01-18 20:05:27,522 ] - Epoch 87: val_loss improved from -114.3051 to -114.4227\n",
      "[ INFO : 2022-01-18 20:05:29,312 ] - Epoch 89: val_loss improved from -114.4227 to -114.4490\n",
      "[ INFO : 2022-01-18 20:05:32,916 ] - Epoch 93: val_loss improved from -114.4490 to -114.5340\n",
      "[ INFO : 2022-01-18 20:05:33,808 ] - Epoch 94: val_loss improved from -114.5340 to -114.5342\n",
      "[ INFO : 2022-01-18 20:05:35,588 ] - Epoch 96: val_loss improved from -114.5342 to -114.5769\n",
      "[ INFO : 2022-01-18 20:05:39,147 ] - Epoch 100: val_loss improved from -114.5769 to -114.7806\n",
      "[ INFO : 2022-01-18 20:05:40,039 ] - Epoch 101: val_loss did not improve from -114.7806\n",
      "[ INFO : 2022-01-18 20:05:40,040 ] - Epoch 101/400 - time: 0.89 - training_loss: -131.4570 - val_loss: -114.4076\n",
      "[ INFO : 2022-01-18 20:05:49,010 ] - Epoch 111: val_loss improved from -114.7806 to -114.8529\n",
      "[ INFO : 2022-01-18 20:05:50,789 ] - Epoch 113: val_loss improved from -114.8529 to -114.8854\n",
      "[ INFO : 2022-01-18 20:05:52,590 ] - Epoch 115: val_loss improved from -114.8854 to -114.9108\n",
      "[ INFO : 2022-01-18 20:05:54,402 ] - Epoch 117: val_loss improved from -114.9108 to -114.9503\n",
      "[ INFO : 2022-01-18 20:05:57,990 ] - Epoch 121: val_loss did not improve from -114.9503\n",
      "[ INFO : 2022-01-18 20:05:57,990 ] - Epoch 121/400 - time: 0.90 - training_loss: -133.4252 - val_loss: -114.9139\n",
      "[ INFO : 2022-01-18 20:06:06,063 ] - Epoch 130: val_loss improved from -114.9503 to -114.9541\n",
      "[ INFO : 2022-01-18 20:06:07,853 ] - Epoch 132: val_loss improved from -114.9541 to -114.9874\n",
      "[ INFO : 2022-01-18 20:06:09,664 ] - Epoch 134: val_loss improved from -114.9874 to -115.0018\n",
      "[ INFO : 2022-01-18 20:06:10,569 ] - Epoch 135: val_loss improved from -115.0018 to -115.0452\n",
      "[ INFO : 2022-01-18 20:06:12,351 ] - Epoch 137: val_loss improved from -115.0452 to -115.0747\n",
      "[ INFO : 2022-01-18 20:06:15,910 ] - Epoch 141: val_loss did not improve from -115.0747\n",
      "[ INFO : 2022-01-18 20:06:15,911 ] - Epoch 141/400 - time: 0.89 - training_loss: -134.8426 - val_loss: -115.0572\n",
      "[ INFO : 2022-01-18 20:06:18,593 ] - Epoch 144: val_loss improved from -115.0747 to -115.1064\n",
      "[ INFO : 2022-01-18 20:06:19,485 ] - Epoch 145: val_loss improved from -115.1064 to -115.1380\n",
      "[ INFO : 2022-01-18 20:06:21,290 ] - Epoch 147: val_loss improved from -115.1380 to -115.2102\n",
      "[ INFO : 2022-01-18 20:06:23,072 ] - Epoch 149: val_loss improved from -115.2102 to -115.2982\n",
      "[ INFO : 2022-01-18 20:06:24,855 ] - Epoch 151: val_loss improved from -115.2982 to -115.3658\n",
      "[ INFO : 2022-01-18 20:06:26,644 ] - Epoch 153: val_loss improved from -115.3658 to -115.4125\n",
      "[ INFO : 2022-01-18 20:06:28,431 ] - Epoch 155: val_loss improved from -115.4125 to -115.4411\n",
      "[ INFO : 2022-01-18 20:06:30,218 ] - Epoch 157: val_loss improved from -115.4411 to -115.4464\n",
      "[ INFO : 2022-01-18 20:06:32,022 ] - Epoch 159: val_loss improved from -115.4464 to -115.4531\n",
      "[ INFO : 2022-01-18 20:06:33,822 ] - Epoch 161: val_loss did not improve from -115.4531\n",
      "[ INFO : 2022-01-18 20:06:33,823 ] - Epoch 161/400 - time: 0.90 - training_loss: -135.9142 - val_loss: -115.4511\n",
      "[ INFO : 2022-01-18 20:06:47,264 ] - Epoch 176: val_loss improved from -115.4531 to -115.5538\n",
      "[ INFO : 2022-01-18 20:06:49,950 ] - Epoch 179: val_loss improved from -115.5538 to -115.6171\n",
      "[ INFO : 2022-01-18 20:06:51,746 ] - Epoch 181: val_loss did not improve from -115.6171\n",
      "[ INFO : 2022-01-18 20:06:51,747 ] - Epoch 181/400 - time: 0.89 - training_loss: -136.7631 - val_loss: -115.6154\n",
      "[ INFO : 2022-01-18 20:06:53,539 ] - Epoch 183: val_loss improved from -115.6171 to -115.6372\n",
      "[ INFO : 2022-01-18 20:06:55,319 ] - Epoch 185: val_loss improved from -115.6372 to -115.6531\n",
      "[ INFO : 2022-01-18 20:06:57,100 ] - Epoch 187: val_loss improved from -115.6531 to -115.6761\n",
      "[ INFO : 2022-01-18 20:07:02,439 ] - Epoch 193: val_loss improved from -115.6761 to -115.6907\n",
      "[ INFO : 2022-01-18 20:07:04,219 ] - Epoch 195: val_loss improved from -115.6907 to -115.7529\n",
      "[ INFO : 2022-01-18 20:07:07,778 ] - Epoch 199: val_loss improved from -115.7529 to -115.7928\n",
      "[ INFO : 2022-01-18 20:07:09,559 ] - Epoch 201: val_loss improved from -115.7928 to -115.8133\n",
      "[ INFO : 2022-01-18 20:07:09,560 ] - Epoch 201/400 - time: 0.89 - training_loss: -137.4360 - val_loss: -115.8133\n",
      "[ INFO : 2022-01-18 20:07:13,120 ] - Epoch 205: val_loss improved from -115.8133 to -115.8161\n",
      "[ INFO : 2022-01-18 20:07:14,900 ] - Epoch 207: val_loss improved from -115.8161 to -115.8617\n",
      "[ INFO : 2022-01-18 20:07:20,244 ] - Epoch 213: val_loss improved from -115.8617 to -115.8995\n",
      "[ INFO : 2022-01-18 20:07:27,412 ] - Epoch 221: val_loss did not improve from -115.8995\n",
      "[ INFO : 2022-01-18 20:07:27,412 ] - Epoch 221/400 - time: 0.89 - training_loss: -137.9965 - val_loss: -115.7864\n",
      "[ INFO : 2022-01-18 20:07:45,599 ] - Epoch 241: val_loss did not improve from -115.8995\n",
      "[ INFO : 2022-01-18 20:07:45,600 ] - Epoch 241/400 - time: 0.93 - training_loss: -138.4494 - val_loss: -115.8240\n",
      "[ INFO : 2022-01-18 20:07:47,477 ] - Epoch 243: val_loss improved from -115.8995 to -115.9192\n",
      "[ INFO : 2022-01-18 20:08:01,201 ] - Epoch 258: val_loss improved from -115.9192 to -115.9416\n",
      "[ INFO : 2022-01-18 20:08:03,888 ] - Epoch 261: val_loss did not improve from -115.9416\n",
      "[ INFO : 2022-01-18 20:08:03,888 ] - Epoch 261/400 - time: 0.90 - training_loss: -138.8421 - val_loss: -115.8713\n",
      "[ INFO : 2022-01-18 20:08:04,787 ] - Epoch 262: val_loss improved from -115.9416 to -115.9748\n",
      "[ INFO : 2022-01-18 20:08:06,583 ] - Epoch 264: val_loss improved from -115.9748 to -115.9896\n",
      "[ INFO : 2022-01-18 20:08:11,157 ] - Epoch 269: val_loss improved from -115.9896 to -116.0076\n",
      "[ INFO : 2022-01-18 20:08:12,960 ] - Epoch 271: val_loss improved from -116.0076 to -116.1628\n",
      "[ INFO : 2022-01-18 20:08:14,751 ] - Epoch 273: val_loss improved from -116.1628 to -116.2211\n",
      "[ INFO : 2022-01-18 20:08:18,314 ] - Epoch 277: val_loss improved from -116.2211 to -116.2348\n",
      "[ INFO : 2022-01-18 20:08:21,875 ] - Epoch 281: val_loss did not improve from -116.2348\n",
      "[ INFO : 2022-01-18 20:08:21,875 ] - Epoch 281/400 - time: 0.89 - training_loss: -139.1791 - val_loss: -116.1430\n",
      "[ INFO : 2022-01-18 20:08:39,674 ] - Epoch 301: val_loss did not improve from -116.2348\n",
      "[ INFO : 2022-01-18 20:08:39,675 ] - Epoch 301/400 - time: 0.89 - training_loss: -139.4747 - val_loss: -116.1920\n",
      "[ INFO : 2022-01-18 20:08:43,237 ] - Epoch 305: val_loss improved from -116.2348 to -116.2464\n",
      "[ INFO : 2022-01-18 20:08:45,018 ] - Epoch 307: val_loss improved from -116.2464 to -116.2790\n",
      "[ INFO : 2022-01-18 20:08:46,799 ] - Epoch 309: val_loss improved from -116.2790 to -116.2890\n",
      "[ INFO : 2022-01-18 20:08:48,580 ] - Epoch 311: val_loss improved from -116.2890 to -116.3250\n",
      "[ INFO : 2022-01-18 20:08:50,361 ] - Epoch 313: val_loss improved from -116.3250 to -116.3522\n",
      "[ INFO : 2022-01-18 20:08:57,481 ] - Epoch 321: val_loss did not improve from -116.3522\n",
      "[ INFO : 2022-01-18 20:08:57,481 ] - Epoch 321/400 - time: 0.89 - training_loss: -139.7346 - val_loss: -116.2575\n",
      "[ INFO : 2022-01-18 20:09:07,254 ] - Epoch 332: val_loss improved from -116.3522 to -116.4124\n",
      "[ INFO : 2022-01-18 20:09:15,304 ] - Epoch 341: val_loss did not improve from -116.4124\n",
      "[ INFO : 2022-01-18 20:09:15,304 ] - Epoch 341/400 - time: 0.90 - training_loss: -139.9608 - val_loss: -116.1624\n",
      "[ INFO : 2022-01-18 20:09:33,266 ] - Epoch 361: val_loss did not improve from -116.4124\n",
      "[ INFO : 2022-01-18 20:09:33,267 ] - Epoch 361/400 - time: 0.89 - training_loss: -140.1603 - val_loss: -116.2246\n",
      "[ INFO : 2022-01-18 20:09:35,946 ] - Epoch 364: val_loss improved from -116.4124 to -116.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2022-01-18 20:09:37,728 ] - Epoch 366: val_loss improved from -116.4375 to -116.4543\n",
      "[ INFO : 2022-01-18 20:09:51,073 ] - Epoch 381: val_loss did not improve from -116.4543\n",
      "[ INFO : 2022-01-18 20:09:51,073 ] - Epoch 381/400 - time: 0.89 - training_loss: -140.3389 - val_loss: -115.9003\n",
      "[ INFO : 2022-01-18 20:09:53,745 ] - Epoch 384: val_loss improved from -116.4543 to -116.4888\n",
      "[ INFO : 2022-01-18 20:10:08,337 ] - loss on validation data: -116.0276\n",
      "[ INFO : 2022-01-18 20:10:08,385 ] - loss on test data: -127.4603\n"
     ]
    }
   ],
   "source": [
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "l_cca = None\n",
    "if apply_linear_cca:\n",
    "    l_cca = linear_cca()\n",
    "    \n",
    "    \n",
    "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
    "                learning_rate, reg_par, device=device, epoch_log_freq=20)\n",
    "s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "# Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "# TODO: Save linear_cca model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e11b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-140.629  -90.03 ]\n",
      "-115.3295\n"
     ]
    }
   ],
   "source": [
    "set_size = [0, \n",
    "            train1.size(0), \n",
    "            train1.size(0) + val1.size(0), \n",
    "            train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "\n",
    "losses, outputs = solver._get_outputs(data1, data2)\n",
    "losses = np.round(losses,3)\n",
    "print(losses)\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b361e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1302, 145)\n",
      "<class 'numpy.ndarray'>\n",
      "(1302, 145)\n"
     ]
    }
   ],
   "source": [
    "print(type(outputs[0]))\n",
    "print(outputs[0].shape)\n",
    "print(type(outputs[1]))\n",
    "print(outputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e3e90",
   "metadata": {},
   "source": [
    "### Saving the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e23a5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving new features in a gzip pickled file specified by save_to\n",
    "with open(save_to, 'wb') as f:\n",
    "    pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f517c8f",
   "metadata": {},
   "source": [
    "### Loading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacfa2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = torch.load('checkpoint.model')\n",
    "# solver.model.load_state_dict(d)\n",
    "# solver.model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5022e0f",
   "metadata": {},
   "source": [
    "### Testing the Correlation between inputs and outputs of the deep Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "019cb979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA on input data:\n",
      "-0.4337692736170777\n",
      "CCA on output data:\n",
      "0.24073923583738127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "print(\"CCA on input data:\")\n",
    "X = data1\n",
    "Y = data2\n",
    "cca = CCA(n_components=50)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "print(cca.score(X, Y))\n",
    "\n",
    "print(\"CCA on output data:\")\n",
    "X = outputs[0]\n",
    "Y = outputs[1]\n",
    "cca = CCA(n_components=50,max_iter=10000)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "# The best possible score is 1.0 and it can be negative \n",
    "# (because the model can be arbitrarily worse)\n",
    "print(cca.score(X, Y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16aa69",
   "metadata": {},
   "source": [
    "### Training and testing of SVM with linear kernel on the view 1 with new features vs old features: (Imaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93a074bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 1}\n",
      "Untrained Accuracy:  51.688\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    50.079\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_1, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[0], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84180f5",
   "metadata": {},
   "source": [
    "### Training and testing of SVM with linear kernel on the view 2 with new features vs old features: (Genetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "678964ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.0001}\n",
      "Untrained Accuracy:  48.08\n",
      "Best Parameters for trained data: {'C': 1}\n",
      "Trained Accuracy:    47.464\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_2, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[1], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017fe62",
   "metadata": {},
   "source": [
    "### Training and testing of SVM with linear kernel on both views with new features vs old features: (Imaging + Genetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "461324ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145)\n",
      "(1302, 145)\n",
      "(1302, 290)\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)\n",
    "both = np.concatenate((outputs[0], outputs[1]), axis=1)\n",
    "print(both.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12fd3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.1}\n",
      "Untrained Accuracy:  52.912\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    48.928\n"
     ]
    }
   ],
   "source": [
    "c = list(unique.columns)\n",
    "MRI_columns = c[c.index(\"MUSE_Volume_4\"):c.index(\"MUSE_Volume_207\")+1]\n",
    "genetic_columns = c[c.index(\"rs4575098\"):c.index(\"rs429358\")+1]\n",
    "columns_of_interest = []\n",
    "columns_of_interest += MRI_columns + genetic_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = unique[columns_of_interest] , unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = both, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
