{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97cf239",
   "metadata": {},
   "source": [
    "# Use DeepCCA to transform ADNI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3582a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "from objectives import cca_loss\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08db7d",
   "metadata": {},
   "source": [
    "## Read the database, examine it:\n",
    "\n",
    "Instead of reading the whole database, we read only the data that's useful to us. That is, we read only specific columns of data, and we take only the row containing the first scan for each person. \n",
    "\n",
    "In \"ADNI Regressional Analysis.ipynb\" we have done that exactly, as well as performed linear regression transformation to the imaging data, in order to remove any age, sex, and DLICV_baseline effect. \n",
    "\n",
    "Furthermore, in \"ADNI OPNMF.ipynb\" we have performed dimensionality reduction through the OPNMF method, reducing the number of the ROIs from 145 to just 18. (Hasn't been done so this does not apply)\n",
    "\n",
    "The data is located at \"./DATA/Reduced_Linearly_Transformed_Unique_Dataset.pkl\" \n",
    "\n",
    "(Need to run the RA code if data is not found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009c840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 209)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>MRID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DLICV_baseline</th>\n",
       "      <th>APOE4_Alleles</th>\n",
       "      <th>APOE_Genotype</th>\n",
       "      <th>Diagnosis_nearest_2.0</th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>...</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "      <th>Diagnosis_nearest_2.0_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>002_S_0295_2006-04-18</td>\n",
       "      <td>2006-04-18</td>\n",
       "      <td>84.742466</td>\n",
       "      <td>0</td>\n",
       "      <td>1485405.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>-401.428503</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>002_S_0413_2006-05-02</td>\n",
       "      <td>2006-05-02</td>\n",
       "      <td>76.283562</td>\n",
       "      <td>1</td>\n",
       "      <td>1364116.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>596.355045</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>002_S_0559_2006-05-23</td>\n",
       "      <td>2006-05-23</td>\n",
       "      <td>79.223288</td>\n",
       "      <td>0</td>\n",
       "      <td>1570479.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>224.874560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>002_S_0619</td>\n",
       "      <td>002_S_0619_2006-06-01</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>77.447945</td>\n",
       "      <td>0</td>\n",
       "      <td>1859348.250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>2633.277779</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>002_S_0729_2006-07-17</td>\n",
       "      <td>2006-07-17</td>\n",
       "      <td>65.056164</td>\n",
       "      <td>1</td>\n",
       "      <td>1166961.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>256.289641</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>002_S_0816_2006-08-30</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>70.767123</td>\n",
       "      <td>0</td>\n",
       "      <td>1444128.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-126.260419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>002_S_0938</td>\n",
       "      <td>002_S_0938_2006-10-05</td>\n",
       "      <td>2006-10-05</td>\n",
       "      <td>82.167123</td>\n",
       "      <td>1</td>\n",
       "      <td>1309685.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>200.102369</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>002_S_0954</td>\n",
       "      <td>002_S_0954_2006-10-10</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>69.198630</td>\n",
       "      <td>1</td>\n",
       "      <td>1075661.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-60.539913</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>002_S_0955</td>\n",
       "      <td>002_S_0955_2006-10-11</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>78.161644</td>\n",
       "      <td>1</td>\n",
       "      <td>1363607.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1058.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>002_S_1018</td>\n",
       "      <td>002_S_1018_2006-11-29</td>\n",
       "      <td>2006-11-29</td>\n",
       "      <td>70.658904</td>\n",
       "      <td>1</td>\n",
       "      <td>1355603.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-485.048304</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>002_S_1070</td>\n",
       "      <td>002_S_1070_2006-11-28</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>73.564384</td>\n",
       "      <td>0</td>\n",
       "      <td>1550701.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>266.235891</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>002_S_1261</td>\n",
       "      <td>002_S_1261_2007-02-15</td>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>71.067123</td>\n",
       "      <td>1</td>\n",
       "      <td>1350714.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>-202.715174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>002_S_1268</td>\n",
       "      <td>002_S_1268_2007-02-14</td>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>82.642466</td>\n",
       "      <td>0</td>\n",
       "      <td>1435189.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>246.512659</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>002_S_2043</td>\n",
       "      <td>002_S_2043_2010-08-31</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>72.180822</td>\n",
       "      <td>1</td>\n",
       "      <td>1280567.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-499.901619</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>002_S_4171</td>\n",
       "      <td>002_S_4171_2011-08-08</td>\n",
       "      <td>2011-08-08</td>\n",
       "      <td>69.353425</td>\n",
       "      <td>0</td>\n",
       "      <td>1522107.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>72.675098</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PTID                   MRID        Date        Age  Sex  \\\n",
       "0    002_S_0295  002_S_0295_2006-04-18  2006-04-18  84.742466    0   \n",
       "9    002_S_0413  002_S_0413_2006-05-02  2006-05-02  76.283562    1   \n",
       "24   002_S_0559  002_S_0559_2006-05-23  2006-05-23  79.223288    0   \n",
       "31   002_S_0619  002_S_0619_2006-06-01  2006-06-01  77.447945    0   \n",
       "45   002_S_0729  002_S_0729_2006-07-17  2006-07-17  65.056164    1   \n",
       "64   002_S_0816  002_S_0816_2006-08-30  2006-08-30  70.767123    0   \n",
       "69   002_S_0938  002_S_0938_2006-10-05  2006-10-05  82.167123    1   \n",
       "74   002_S_0954  002_S_0954_2006-10-10  2006-10-10  69.198630    1   \n",
       "81   002_S_0955  002_S_0955_2006-10-11  2006-10-11  78.161644    1   \n",
       "84   002_S_1018  002_S_1018_2006-11-29  2006-11-29  70.658904    1   \n",
       "90   002_S_1070  002_S_1070_2006-11-28  2006-11-28  73.564384    0   \n",
       "113  002_S_1261  002_S_1261_2007-02-15  2007-02-15  71.067123    1   \n",
       "127  002_S_1268  002_S_1268_2007-02-14  2007-02-14  82.642466    0   \n",
       "147  002_S_2043  002_S_2043_2010-08-31  2010-08-31  72.180822    1   \n",
       "163  002_S_4171  002_S_4171_2011-08-08  2011-08-08  69.353425    0   \n",
       "\n",
       "     DLICV_baseline  APOE4_Alleles APOE_Genotype Diagnosis_nearest_2.0  \\\n",
       "0       1485405.375            1.0         E3/E4                    CN   \n",
       "9       1364116.000            0.0         E3/E3                    CN   \n",
       "24      1570479.625            1.0         E3/E4                    CN   \n",
       "31      1859348.250            2.0         E4/E4              Dementia   \n",
       "45      1166961.750            1.0         E3/E4                   MCI   \n",
       "64      1444128.125            2.0         E4/E4              Dementia   \n",
       "69      1309685.000            0.0         E3/E3              Dementia   \n",
       "74      1075661.500            1.0         E3/E4                   MCI   \n",
       "81      1363607.000            1.0         E3/E4              Dementia   \n",
       "84      1355603.000            0.0         E3/E3              Dementia   \n",
       "90      1550701.375            0.0         E3/E3                   MCI   \n",
       "113     1350714.875            0.0         E3/E3                    CN   \n",
       "127     1435189.875            1.0         E3/E4                   MCI   \n",
       "147     1280567.125            1.0         E3/E4                   MCI   \n",
       "163     1522107.375            0.0         E3/E3                   MCI   \n",
       "\n",
       "     MUSE_Volume_4  ...  rs111278892  rs3752246  rs4147929  rs41289512  \\\n",
       "0      -401.428503  ...            1          1          1           0   \n",
       "9       596.355045  ...            0          1          1           0   \n",
       "24      224.874560  ...            0          0          0           0   \n",
       "31     2633.277779  ...            0          0          0           1   \n",
       "45      256.289641  ...            0          0          0           1   \n",
       "64     -126.260419  ...            0          0          0           0   \n",
       "69      200.102369  ...            0          1          1           0   \n",
       "74      -60.539913  ...            2          1          1           0   \n",
       "81     1058.028132  ...            1          0          0           0   \n",
       "84     -485.048304  ...            1          1          1           0   \n",
       "90      266.235891  ...            0          0          0           0   \n",
       "113    -202.715174  ...            0          0          0           0   \n",
       "127     246.512659  ...            0          0          0           0   \n",
       "147    -499.901619  ...            0          0          0           1   \n",
       "163      72.675098  ...            0          0          0           0   \n",
       "\n",
       "     rs3865444  rs6024870  rs6014724  rs7274581  rs429358  \\\n",
       "0            0          0          0          0         1   \n",
       "9            1          0          0          0         0   \n",
       "24           1          0          0          0         0   \n",
       "31           1          0          0          0         2   \n",
       "45           1          0          0          0         1   \n",
       "64           1          0          0          0         2   \n",
       "69           1          0          0          0         0   \n",
       "74           1          0          0          0         1   \n",
       "81           1          0          0          0         1   \n",
       "84           0          0          0          0         0   \n",
       "90           0          0          0          0         0   \n",
       "113          0          1          1          1         0   \n",
       "127          1          1          1          1         1   \n",
       "147          0          0          0          0         1   \n",
       "163          0          0          0          1         0   \n",
       "\n",
       "     Diagnosis_nearest_2.0_cat  \n",
       "0                            0  \n",
       "9                            0  \n",
       "24                           0  \n",
       "31                           1  \n",
       "45                           2  \n",
       "64                           1  \n",
       "69                           1  \n",
       "74                           2  \n",
       "81                           1  \n",
       "84                           1  \n",
       "90                           2  \n",
       "113                          0  \n",
       "127                          2  \n",
       "147                          2  \n",
       "163                          2  \n",
       "\n",
       "[15 rows x 209 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = pd.read_pickle(\"./DATA/Linearly_Transformed_Unique_Dataset.pkl\")\n",
    "print(unique.shape)\n",
    "unique.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e714f1-ad2e-4d18-9b55-265cfbac0509",
   "metadata": {},
   "source": [
    "##  Building, training, and producing the new features by DCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c020f",
   "metadata": {},
   "source": [
    "### Create the 2 views:\n",
    "\n",
    "The first view consists of the imaging data, that are in the form of 145 real numbers. Those numbers are based on a prediction from a Linear Regression estimator trained only on the Cognitive Normal datapoints. The predictions then are subtracted from the actual values, and the remaining value (residual) is the datapoint for each ROI.\n",
    "\n",
    "The second view consists of the 54 SNP (Single Nucleotide Polymorphism, \"snip\"), for each individual. They are either 0 or 1. \n",
    "\n",
    "The 2 views are the most basic views that can be used for the Deep CCA, and in further tests more features will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ded1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afced851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>MUSE_Volume_11</th>\n",
       "      <th>MUSE_Volume_23</th>\n",
       "      <th>MUSE_Volume_30</th>\n",
       "      <th>MUSE_Volume_31</th>\n",
       "      <th>MUSE_Volume_32</th>\n",
       "      <th>MUSE_Volume_35</th>\n",
       "      <th>MUSE_Volume_36</th>\n",
       "      <th>MUSE_Volume_37</th>\n",
       "      <th>MUSE_Volume_38</th>\n",
       "      <th>...</th>\n",
       "      <th>MUSE_Volume_198</th>\n",
       "      <th>MUSE_Volume_199</th>\n",
       "      <th>MUSE_Volume_200</th>\n",
       "      <th>MUSE_Volume_201</th>\n",
       "      <th>MUSE_Volume_202</th>\n",
       "      <th>MUSE_Volume_203</th>\n",
       "      <th>MUSE_Volume_204</th>\n",
       "      <th>MUSE_Volume_205</th>\n",
       "      <th>MUSE_Volume_206</th>\n",
       "      <th>MUSE_Volume_207</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-401.428503</td>\n",
       "      <td>-475.082401</td>\n",
       "      <td>-38.009137</td>\n",
       "      <td>-25.646775</td>\n",
       "      <td>75.669198</td>\n",
       "      <td>126.590353</td>\n",
       "      <td>124.482040</td>\n",
       "      <td>54.813183</td>\n",
       "      <td>29.901574</td>\n",
       "      <td>4088.590752</td>\n",
       "      <td>...</td>\n",
       "      <td>789.359109</td>\n",
       "      <td>-170.422388</td>\n",
       "      <td>-1543.880458</td>\n",
       "      <td>-1674.618225</td>\n",
       "      <td>632.563713</td>\n",
       "      <td>-531.585707</td>\n",
       "      <td>-39.623451</td>\n",
       "      <td>260.649954</td>\n",
       "      <td>-115.085767</td>\n",
       "      <td>-81.954942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>596.355045</td>\n",
       "      <td>-177.499304</td>\n",
       "      <td>34.866428</td>\n",
       "      <td>-42.623326</td>\n",
       "      <td>36.073837</td>\n",
       "      <td>53.399103</td>\n",
       "      <td>-914.581355</td>\n",
       "      <td>-108.931623</td>\n",
       "      <td>124.883198</td>\n",
       "      <td>-972.814733</td>\n",
       "      <td>...</td>\n",
       "      <td>1335.363413</td>\n",
       "      <td>2649.942277</td>\n",
       "      <td>1411.230818</td>\n",
       "      <td>31.346635</td>\n",
       "      <td>-1267.747385</td>\n",
       "      <td>117.940453</td>\n",
       "      <td>-149.481247</td>\n",
       "      <td>-535.823873</td>\n",
       "      <td>-40.431290</td>\n",
       "      <td>-470.993059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>224.874560</td>\n",
       "      <td>1110.220538</td>\n",
       "      <td>134.798531</td>\n",
       "      <td>135.858384</td>\n",
       "      <td>109.271915</td>\n",
       "      <td>29.323465</td>\n",
       "      <td>1704.716715</td>\n",
       "      <td>-284.353318</td>\n",
       "      <td>-15.319536</td>\n",
       "      <td>-1099.592092</td>\n",
       "      <td>...</td>\n",
       "      <td>-1719.736333</td>\n",
       "      <td>-2192.002637</td>\n",
       "      <td>1513.234184</td>\n",
       "      <td>523.058557</td>\n",
       "      <td>1603.211181</td>\n",
       "      <td>2422.347525</td>\n",
       "      <td>218.967561</td>\n",
       "      <td>-66.321636</td>\n",
       "      <td>-200.393450</td>\n",
       "      <td>-107.128517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2633.277779</td>\n",
       "      <td>703.512999</td>\n",
       "      <td>-165.584181</td>\n",
       "      <td>-128.673356</td>\n",
       "      <td>-351.196493</td>\n",
       "      <td>-369.996116</td>\n",
       "      <td>-3669.094187</td>\n",
       "      <td>-871.937556</td>\n",
       "      <td>-752.247876</td>\n",
       "      <td>-503.572274</td>\n",
       "      <td>...</td>\n",
       "      <td>-616.963790</td>\n",
       "      <td>603.136888</td>\n",
       "      <td>-608.460701</td>\n",
       "      <td>-1332.047832</td>\n",
       "      <td>-3012.228200</td>\n",
       "      <td>-2804.914271</td>\n",
       "      <td>-791.597461</td>\n",
       "      <td>-822.562965</td>\n",
       "      <td>-356.240988</td>\n",
       "      <td>-118.945277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>256.289641</td>\n",
       "      <td>599.953746</td>\n",
       "      <td>10.855725</td>\n",
       "      <td>32.230306</td>\n",
       "      <td>-150.404626</td>\n",
       "      <td>-107.055211</td>\n",
       "      <td>472.978958</td>\n",
       "      <td>649.045998</td>\n",
       "      <td>130.401624</td>\n",
       "      <td>-85.434102</td>\n",
       "      <td>...</td>\n",
       "      <td>-317.885924</td>\n",
       "      <td>-670.024556</td>\n",
       "      <td>62.647813</td>\n",
       "      <td>986.709609</td>\n",
       "      <td>-1459.773538</td>\n",
       "      <td>-1367.048968</td>\n",
       "      <td>-141.267965</td>\n",
       "      <td>-197.021311</td>\n",
       "      <td>-217.041629</td>\n",
       "      <td>-277.950585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MUSE_Volume_4  MUSE_Volume_11  MUSE_Volume_23  MUSE_Volume_30  \\\n",
       "0     -401.428503     -475.082401      -38.009137      -25.646775   \n",
       "9      596.355045     -177.499304       34.866428      -42.623326   \n",
       "24     224.874560     1110.220538      134.798531      135.858384   \n",
       "31    2633.277779      703.512999     -165.584181     -128.673356   \n",
       "45     256.289641      599.953746       10.855725       32.230306   \n",
       "\n",
       "    MUSE_Volume_31  MUSE_Volume_32  MUSE_Volume_35  MUSE_Volume_36  \\\n",
       "0        75.669198      126.590353      124.482040       54.813183   \n",
       "9        36.073837       53.399103     -914.581355     -108.931623   \n",
       "24      109.271915       29.323465     1704.716715     -284.353318   \n",
       "31     -351.196493     -369.996116    -3669.094187     -871.937556   \n",
       "45     -150.404626     -107.055211      472.978958      649.045998   \n",
       "\n",
       "    MUSE_Volume_37  MUSE_Volume_38  ...  MUSE_Volume_198  MUSE_Volume_199  \\\n",
       "0        29.901574     4088.590752  ...       789.359109      -170.422388   \n",
       "9       124.883198     -972.814733  ...      1335.363413      2649.942277   \n",
       "24      -15.319536    -1099.592092  ...     -1719.736333     -2192.002637   \n",
       "31     -752.247876     -503.572274  ...      -616.963790       603.136888   \n",
       "45      130.401624      -85.434102  ...      -317.885924      -670.024556   \n",
       "\n",
       "    MUSE_Volume_200  MUSE_Volume_201  MUSE_Volume_202  MUSE_Volume_203  \\\n",
       "0      -1543.880458     -1674.618225       632.563713      -531.585707   \n",
       "9       1411.230818        31.346635     -1267.747385       117.940453   \n",
       "24      1513.234184       523.058557      1603.211181      2422.347525   \n",
       "31      -608.460701     -1332.047832     -3012.228200     -2804.914271   \n",
       "45        62.647813       986.709609     -1459.773538     -1367.048968   \n",
       "\n",
       "    MUSE_Volume_204  MUSE_Volume_205  MUSE_Volume_206  MUSE_Volume_207  \n",
       "0        -39.623451       260.649954      -115.085767       -81.954942  \n",
       "9       -149.481247      -535.823873       -40.431290      -470.993059  \n",
       "24       218.967561       -66.321636      -200.393450      -107.128517  \n",
       "31      -791.597461      -822.562965      -356.240988      -118.945277  \n",
       "45      -141.267965      -197.021311      -217.041629      -277.950585  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs4575098</th>\n",
       "      <th>rs6656401</th>\n",
       "      <th>rs2093760</th>\n",
       "      <th>rs4844610</th>\n",
       "      <th>rs4663105</th>\n",
       "      <th>rs6733839</th>\n",
       "      <th>rs10933431</th>\n",
       "      <th>rs35349669</th>\n",
       "      <th>rs6448453</th>\n",
       "      <th>rs190982</th>\n",
       "      <th>...</th>\n",
       "      <th>rs28394864</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs4575098  rs6656401  rs2093760  rs4844610  rs4663105  rs6733839  \\\n",
       "0           0          0          0          0          1          1   \n",
       "9           1          0          0          0          0          0   \n",
       "24          0          0          0          0          1          0   \n",
       "31          0          1          1          1          0          0   \n",
       "45          0          0          0          0          1          1   \n",
       "\n",
       "    rs10933431  rs35349669  rs6448453  rs190982  ...  rs28394864  rs111278892  \\\n",
       "0            1           0          0         1  ...           0            1   \n",
       "9            0           1          0         0  ...           1            0   \n",
       "24           1           0          0         1  ...           2            0   \n",
       "31           0           2          1         1  ...           1            0   \n",
       "45           0           1          0         0  ...           1            0   \n",
       "\n",
       "    rs3752246  rs4147929  rs41289512  rs3865444  rs6024870  rs6014724  \\\n",
       "0           1          1           0          0          0          0   \n",
       "9           1          1           0          1          0          0   \n",
       "24          0          0           0          1          0          0   \n",
       "31          0          0           1          1          0          0   \n",
       "45          0          0           1          1          0          0   \n",
       "\n",
       "    rs7274581  rs429358  \n",
       "0           0         1  \n",
       "9           0         0  \n",
       "24          0         0  \n",
       "31          0         2  \n",
       "45          0         1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"View 1:\")\n",
    "display(view_1.head())\n",
    "print(\"View 2:\")\n",
    "display(view_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8102d",
   "metadata": {},
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2abc22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a gpu exists, torch.device should be 'gpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 145\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 145 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "# this apparently can be different for each network, some experimentation is needed!\n",
    "layer_sizes1 = [256, 1024, 1024, outdim_size]\n",
    "layer_sizes2 = [256, 1024, 1024, outdim_size]\n",
    "# layer_sizes1 = [64, 128, outdim_size]\n",
    "# layer_sizes2 = [64, 128, outdim_size]\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-4\n",
    "epoch_num = 150\n",
    "epoch_log_freq = 50\n",
    "batch_size = 1000\n",
    "\n",
    "# the path to save the final learned features, as DCCA-o-d.\n",
    "save_to = './DATA/ADNI_DCCA_features_'+str(outdim_size)+'_'+str(len(layer_sizes1)-1)+'.pkl'\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-3\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top \n",
    "# outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = False\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32dded",
   "metadata": {},
   "source": [
    "###  Training the DCCA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f4ebdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "18e14d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145) <class 'numpy.ndarray'> float64\n",
      "(1302, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1302, 145]) <class 'torch.Tensor'>\n",
      "torch.Size([1302, 54]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]\n",
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()\n",
    "# Scramble the datapoints for randomness:\n",
    "indices = np.arange(view_1_n.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "view_1_n = view_1_n[indices]\n",
    "view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))\n",
    "\n",
    "data1 = view_1_t\n",
    "data2 = view_2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f516e24f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation data: -107.6490\n",
      "loss on test data: -114.0847\n"
     ]
    }
   ],
   "source": [
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "l_cca = None\n",
    "if apply_linear_cca:\n",
    "    l_cca = linear_cca()\n",
    "    \n",
    "    \n",
    "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
    "                learning_rate, reg_par, device=device, epoch_log_freq=epoch_log_freq, log=False)\n",
    "s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "# Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "loss = solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "training_losses, val_losses = solver.get_losses()\n",
    "# TODO: Save linear_cca model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e11b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-137.345  -86.334]\n"
     ]
    }
   ],
   "source": [
    "set_size = [0, \n",
    "            train1.size(0), \n",
    "            train1.size(0) + val1.size(0), \n",
    "            train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "\n",
    "losses, outputs = solver._get_outputs(data1, data2)\n",
    "losses = np.round(losses,3)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b361e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1302, 145)\n",
      "<class 'numpy.ndarray'>\n",
      "(1302, 145)\n"
     ]
    }
   ],
   "source": [
    "print(type(outputs[0]))\n",
    "print(outputs[0].shape)\n",
    "print(type(outputs[1]))\n",
    "print(outputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0e965-1757-4085-857b-ffe541adb8db",
   "metadata": {},
   "source": [
    "### Plotting the Losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f371c9de-f4b6-40db-9545-493b85b720be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(epoch_num)\n",
    "plt.figure(figsize=(10, 8), dpi=90)\n",
    "plt.plot(x, training_losses, color='blue', label=\"Training Loss\")\n",
    "plt.plot(x, val_losses, color='orange', label=\"Validation Loss\")\n",
    "plt.title(\"Losses for the training of the model\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (lower is better)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c952c-d01e-4a42-80c2-29395c1361b7",
   "metadata": {},
   "source": [
    "### Using GridSearch Cross with Validation to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ede527bd-4bc2-47d9-aadb-c8532e8e5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145) <class 'numpy.ndarray'> float64\n",
      "(1302, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1302, 145]) <class 'torch.Tensor'>\n",
      "torch.Size([1302, 54]) <class 'torch.Tensor'>\n",
      "Variation  1 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9715\n",
      "loss on test data: -2.5014\n",
      "-2.5014420119575527\n",
      "Variation  2 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9246\n",
      "loss on test data: -2.4206\n",
      "-2.420571479866891\n",
      "Variation  3 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.8827\n",
      "loss on test data: -2.4031\n",
      "-2.4031040545542988\n",
      "Variation  4 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0825\n",
      "loss on test data: -2.4707\n",
      "-2.4706761325444035\n",
      "Variation  5 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.7397\n",
      "loss on test data: -2.4837\n",
      "-2.4837428343236394\n",
      "Variation  6 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.0752\n",
      "loss on test data: -2.1727\n",
      "-2.172700749211693\n",
      "Variation  7 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.7188\n",
      "loss on test data: -2.3808\n",
      "-2.380829214556371\n",
      "Variation  8 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9871\n",
      "loss on test data: -2.4656\n",
      "-2.4655511627406996\n",
      "Variation  9 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.7560\n",
      "loss on test data: -2.4256\n",
      "-2.425550149856158\n",
      "Variation  10 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9019\n",
      "loss on test data: -2.4386\n",
      "-2.438594525264215\n",
      "Variation  11 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -2.0548\n",
      "loss on test data: -2.3912\n",
      "-2.3912473555611786\n",
      "Variation  12 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.2218\n",
      "loss on test data: -2.4085\n",
      "-2.4085149239993506\n",
      "Variation  13 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9304\n",
      "loss on test data: -2.4261\n",
      "-2.426076880845039\n",
      "Variation  14 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.7989\n",
      "loss on test data: -2.3644\n",
      "-2.3644211511377815\n",
      "Variation  15 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.0205\n",
      "loss on test data: -2.2918\n",
      "-2.291774648487095\n",
      "Variation  16 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9791\n",
      "loss on test data: -2.0394\n",
      "-2.039371960465259\n",
      "Variation  17 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.7801\n",
      "loss on test data: -2.3440\n",
      "-2.3440497535602685\n",
      "Variation  18 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.8628\n",
      "loss on test data: -2.5026\n",
      "-2.5026229859739457\n",
      "Variation  19 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.2951\n",
      "loss on test data: -2.3513\n",
      "-2.351346787826806\n",
      "Variation  20 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -2.1178\n",
      "loss on test data: -2.4017\n",
      "-2.401719861920058\n",
      "Variation  21 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9877\n",
      "loss on test data: -2.2358\n",
      "-2.235816811412166\n",
      "Variation  22 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m val1, val2 \u001b[38;5;241m=\u001b[39m data1[\u001b[38;5;28mint\u001b[39m(s_1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.75\u001b[39m):\u001b[38;5;28mint\u001b[39m(s_1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.9\u001b[39m)], data2[\u001b[38;5;28mint\u001b[39m(s_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.75\u001b[39m):\u001b[38;5;28mint\u001b[39m(s_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.9\u001b[39m)]\n\u001b[1;32m     76\u001b[0m test1, test2 \u001b[38;5;241m=\u001b[39m data1[\u001b[38;5;28mint\u001b[39m(s_1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.9\u001b[39m):], data2[\u001b[38;5;28mint\u001b[39m(s_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.9\u001b[39m):]\n\u001b[0;32m---> 78\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_loss)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_loss \u001b[38;5;241m<\u001b[39m best_test_loss[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/Important Stuff/Dissertation/DeepCCA Model/main.py:87\u001b[0m, in \u001b[0;36mSolver.fit\u001b[0;34m(self, x1, x2, vx1, vx2, tx1, tx2, checkpoint, no_print)\u001b[0m\n\u001b[1;32m     85\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(o1, o2)\n\u001b[1;32m     86\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 87\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# def closure():\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#     self.optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#     o1, o2 = self.model(batch_x1, batch_x2)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#     return loss\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# self.optimizer.step(closure)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Testing/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Testing/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]\n",
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()\n",
    "# Scramble the datapoints for randomness:\n",
    "indices = np.arange(view_1_n.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "view_1_n = view_1_n[indices]\n",
    "view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))\n",
    "\n",
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "# Standard parameters that shouldn't be changed:\n",
    "input_shape1 = 145 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "epoch_log_freq = 50\n",
    "use_all_singular_values = False\n",
    "apply_linear_cca = True\n",
    "epoch_num = 100\n",
    "# Parameters that should be explored, example values:\n",
    "outdim_sizes = [10,50,100,150]\n",
    "hidden_layer_sizes = [[256,256,256],\n",
    "                      [1024,1024,1024],\n",
    "                      [256,256,256,256],\n",
    "                      [1024,1024,1024,1024]]\n",
    "learning_rates = [1e-2,1e-3,1e-4]\n",
    "batch_sizes = [500,1000]\n",
    "reg_pars = [1e-2,1e-3,1e-4]\n",
    "\n",
    "results = []\n",
    "best_test_loss = (1000,None)\n",
    "count=0\n",
    "\n",
    "for outdim_size in outdim_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        hidden_layer_size1 = hidden_layer_size\n",
    "        hidden_layer_size2 = hidden_layer_size\n",
    "        for learning_rate in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                for reg_par in reg_pars:\n",
    "                    count += 1\n",
    "                    parameters = {\"outdim\": outdim_size,\n",
    "                                  \"hidden_layer_size1\": hidden_layer_size1,\n",
    "                                  \"hidden_layer_size2\": hidden_layer_size2,\n",
    "                                  \"learning_rate\": learning_rate,\n",
    "                                  \"batch_sz\": batch_size,\n",
    "                                  \"reg_par\": reg_par}\n",
    "                    print(\"Variation \", count, \":\", parameters)\n",
    "                    layer_sizes1 = hidden_layer_size1 + [outdim_size]\n",
    "                    layer_sizes2 = hidden_layer_size2 + [outdim_size]\n",
    "\n",
    "                    model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1, input_shape2, outdim_size, \n",
    "                                    use_all_singular_values, device=device).double()\n",
    "\n",
    "                    solver = Solver(model, linear_cca(), outdim_size, epoch_num, batch_size,\n",
    "                                    learning_rate, reg_par, device=device, epoch_log_freq=epoch_log_freq, log=False)\n",
    "                    s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "                    # Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "                    train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "                    val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "                    test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "                    test_loss = solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "                    print(test_loss)\n",
    "                    if test_loss < best_test_loss[0]:\n",
    "                        best_test_loss = (test_loss, parameters)\n",
    "                    training_losses, val_losses = solver.get_losses()\n",
    "                    results.append((training_losses, val_losses, test_loss, parameters))\n",
    "\n",
    "print(\"With a loss of \" + str(best_test_loss[0]) + \", the configuration with the best Test loss was:\")\n",
    "pprint.pprint(best_test_loss[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e3e90",
   "metadata": {},
   "source": [
    "### Saving the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e23a5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving new features in a gzip pickled file specified by save_to\n",
    "with open(save_to, 'wb') as f:\n",
    "    pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f517c8f",
   "metadata": {},
   "source": [
    "### Loading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bacfa2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = torch.load('checkpoint.model')\n",
    "# solver.model.load_state_dict(d)\n",
    "# solver.model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d09c7-c1b5-4c68-bf8f-d1d96b320925",
   "metadata": {},
   "source": [
    "## Testing the Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5022e0f",
   "metadata": {},
   "source": [
    "### Testing the Correlation between inputs and outputs of the deep Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "019cb979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA on input data:\n",
      "-0.42426306714130085\n",
      "CCA on output data:\n",
      "0.27795515365866535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "print(\"CCA on input data:\")\n",
    "X = data1\n",
    "Y = data2\n",
    "cca = CCA(n_components=50)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "print(cca.score(X, Y))\n",
    "\n",
    "print(\"CCA on output data:\")\n",
    "X = outputs[0]\n",
    "Y = outputs[1]\n",
    "cca = CCA(n_components=50,max_iter=10000)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "# The best possible score is 1.0 and it can be negative \n",
    "# (because the model can be arbitrarily worse)\n",
    "print(cca.score(X, Y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16aa69",
   "metadata": {},
   "source": [
    "### (Imaging) Training and testing of SVM with linear kernel on the view 1 with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a074bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 10}\n",
      "Untrained Accuracy:  51.381\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    48.849\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_1, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[0], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84180f5",
   "metadata": {},
   "source": [
    "### (Genetic) Training and testing of SVM with linear kernel on the view 2 with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678964ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.0001}\n",
      "Untrained Accuracy:  48.08\n",
      "Best Parameters for trained data: {'C': 0.01}\n",
      "Trained Accuracy:    46.929\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_2, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[1], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017fe62",
   "metadata": {},
   "source": [
    "### (Imaging + Genetic) Training and testing of SVM with linear kernel on both views with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461324ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145)\n",
      "(1302, 145)\n",
      "(1302, 290)\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)\n",
    "both = np.concatenate((outputs[0], outputs[1]), axis=1)\n",
    "print(both.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12fd3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.1}\n",
      "Untrained Accuracy:  52.988\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    48.695\n"
     ]
    }
   ],
   "source": [
    "c = list(unique.columns)\n",
    "MRI_columns = c[c.index(\"MUSE_Volume_4\"):c.index(\"MUSE_Volume_207\")+1]\n",
    "genetic_columns = c[c.index(\"rs4575098\"):c.index(\"rs429358\")+1]\n",
    "columns_of_interest = []\n",
    "columns_of_interest += MRI_columns + genetic_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = unique[columns_of_interest] , unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = both, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
