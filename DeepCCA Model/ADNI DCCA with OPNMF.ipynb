{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e2b5a4f-25d6-449d-a822-177cca6a1658",
   "metadata": {},
   "source": [
    "# Use DeepCCA to transform ADNI features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d7a5c-d913-430a-bc2e-81dff49609b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Importing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7800e8a-263d-4c4d-805a-fc602548dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "from objectives import cca_loss\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ba5b6-28de-46c6-bf7f-ad56e5b518fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read the database, examine it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a0654-9340-4be9-9525-50520ee0408f",
   "metadata": {},
   "source": [
    "The data is located at \"./DATA/Reduced_Linearly_Transformed_Unique_Dataset.pkl\" \n",
    "\n",
    "We also need to read the OPNMF Loading Coefficients, and those are going to be our imaging data. \n",
    "The coefficients are located at \"./DATA/loading_coefficients_30components.tsv\". They are reduced to \n",
    "a dimension of 30 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10dbfd12-90c9-4558-a28e-1ac98391bd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 209)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>MRID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DLICV_baseline</th>\n",
       "      <th>APOE4_Alleles</th>\n",
       "      <th>APOE_Genotype</th>\n",
       "      <th>Diagnosis_nearest_2.0</th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>...</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "      <th>Diagnosis_nearest_2.0_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>002_S_0295_2006-04-18</td>\n",
       "      <td>2006-04-18</td>\n",
       "      <td>84.742466</td>\n",
       "      <td>0</td>\n",
       "      <td>1485405.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>-401.428503</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>002_S_0413_2006-05-02</td>\n",
       "      <td>2006-05-02</td>\n",
       "      <td>76.283562</td>\n",
       "      <td>1</td>\n",
       "      <td>1364116.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>596.355045</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>002_S_0559_2006-05-23</td>\n",
       "      <td>2006-05-23</td>\n",
       "      <td>79.223288</td>\n",
       "      <td>0</td>\n",
       "      <td>1570479.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>224.874560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_S_0619</td>\n",
       "      <td>002_S_0619_2006-06-01</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>77.447945</td>\n",
       "      <td>0</td>\n",
       "      <td>1859348.250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>2633.277779</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>002_S_0729_2006-07-17</td>\n",
       "      <td>2006-07-17</td>\n",
       "      <td>65.056164</td>\n",
       "      <td>1</td>\n",
       "      <td>1166961.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>256.289641</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>002_S_0816_2006-08-30</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>70.767123</td>\n",
       "      <td>0</td>\n",
       "      <td>1444128.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-126.260419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002_S_0938</td>\n",
       "      <td>002_S_0938_2006-10-05</td>\n",
       "      <td>2006-10-05</td>\n",
       "      <td>82.167123</td>\n",
       "      <td>1</td>\n",
       "      <td>1309685.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>200.102369</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002_S_0954</td>\n",
       "      <td>002_S_0954_2006-10-10</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>69.198630</td>\n",
       "      <td>1</td>\n",
       "      <td>1075661.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-60.539913</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002_S_0955</td>\n",
       "      <td>002_S_0955_2006-10-11</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>78.161644</td>\n",
       "      <td>1</td>\n",
       "      <td>1363607.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1058.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_1018</td>\n",
       "      <td>002_S_1018_2006-11-29</td>\n",
       "      <td>2006-11-29</td>\n",
       "      <td>70.658904</td>\n",
       "      <td>1</td>\n",
       "      <td>1355603.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-485.048304</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>002_S_1070</td>\n",
       "      <td>002_S_1070_2006-11-28</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>73.564384</td>\n",
       "      <td>0</td>\n",
       "      <td>1550701.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>266.235891</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002_S_1261</td>\n",
       "      <td>002_S_1261_2007-02-15</td>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>71.067123</td>\n",
       "      <td>1</td>\n",
       "      <td>1350714.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>-202.715174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002_S_1268</td>\n",
       "      <td>002_S_1268_2007-02-14</td>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>82.642466</td>\n",
       "      <td>0</td>\n",
       "      <td>1435189.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>246.512659</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>002_S_2043</td>\n",
       "      <td>002_S_2043_2010-08-31</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>72.180822</td>\n",
       "      <td>1</td>\n",
       "      <td>1280567.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-499.901619</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>002_S_4171</td>\n",
       "      <td>002_S_4171_2011-08-08</td>\n",
       "      <td>2011-08-08</td>\n",
       "      <td>69.353425</td>\n",
       "      <td>0</td>\n",
       "      <td>1522107.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>72.675098</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PTID                   MRID        Date        Age  Sex  \\\n",
       "0   002_S_0295  002_S_0295_2006-04-18  2006-04-18  84.742466    0   \n",
       "1   002_S_0413  002_S_0413_2006-05-02  2006-05-02  76.283562    1   \n",
       "2   002_S_0559  002_S_0559_2006-05-23  2006-05-23  79.223288    0   \n",
       "3   002_S_0619  002_S_0619_2006-06-01  2006-06-01  77.447945    0   \n",
       "4   002_S_0729  002_S_0729_2006-07-17  2006-07-17  65.056164    1   \n",
       "5   002_S_0816  002_S_0816_2006-08-30  2006-08-30  70.767123    0   \n",
       "6   002_S_0938  002_S_0938_2006-10-05  2006-10-05  82.167123    1   \n",
       "7   002_S_0954  002_S_0954_2006-10-10  2006-10-10  69.198630    1   \n",
       "8   002_S_0955  002_S_0955_2006-10-11  2006-10-11  78.161644    1   \n",
       "9   002_S_1018  002_S_1018_2006-11-29  2006-11-29  70.658904    1   \n",
       "10  002_S_1070  002_S_1070_2006-11-28  2006-11-28  73.564384    0   \n",
       "11  002_S_1261  002_S_1261_2007-02-15  2007-02-15  71.067123    1   \n",
       "12  002_S_1268  002_S_1268_2007-02-14  2007-02-14  82.642466    0   \n",
       "13  002_S_2043  002_S_2043_2010-08-31  2010-08-31  72.180822    1   \n",
       "14  002_S_4171  002_S_4171_2011-08-08  2011-08-08  69.353425    0   \n",
       "\n",
       "    DLICV_baseline  APOE4_Alleles APOE_Genotype Diagnosis_nearest_2.0  \\\n",
       "0      1485405.375            1.0         E3/E4                    CN   \n",
       "1      1364116.000            0.0         E3/E3                    CN   \n",
       "2      1570479.625            1.0         E3/E4                    CN   \n",
       "3      1859348.250            2.0         E4/E4              Dementia   \n",
       "4      1166961.750            1.0         E3/E4                   MCI   \n",
       "5      1444128.125            2.0         E4/E4              Dementia   \n",
       "6      1309685.000            0.0         E3/E3              Dementia   \n",
       "7      1075661.500            1.0         E3/E4                   MCI   \n",
       "8      1363607.000            1.0         E3/E4              Dementia   \n",
       "9      1355603.000            0.0         E3/E3              Dementia   \n",
       "10     1550701.375            0.0         E3/E3                   MCI   \n",
       "11     1350714.875            0.0         E3/E3                    CN   \n",
       "12     1435189.875            1.0         E3/E4                   MCI   \n",
       "13     1280567.125            1.0         E3/E4                   MCI   \n",
       "14     1522107.375            0.0         E3/E3                   MCI   \n",
       "\n",
       "    MUSE_Volume_4  ...  rs111278892  rs3752246  rs4147929  rs41289512  \\\n",
       "0     -401.428503  ...            1          1          1           0   \n",
       "1      596.355045  ...            0          1          1           0   \n",
       "2      224.874560  ...            0          0          0           0   \n",
       "3     2633.277779  ...            0          0          0           1   \n",
       "4      256.289641  ...            0          0          0           1   \n",
       "5     -126.260419  ...            0          0          0           0   \n",
       "6      200.102369  ...            0          1          1           0   \n",
       "7      -60.539913  ...            2          1          1           0   \n",
       "8     1058.028132  ...            1          0          0           0   \n",
       "9     -485.048304  ...            1          1          1           0   \n",
       "10     266.235891  ...            0          0          0           0   \n",
       "11    -202.715174  ...            0          0          0           0   \n",
       "12     246.512659  ...            0          0          0           0   \n",
       "13    -499.901619  ...            0          0          0           1   \n",
       "14      72.675098  ...            0          0          0           0   \n",
       "\n",
       "    rs3865444  rs6024870  rs6014724  rs7274581  rs429358  \\\n",
       "0           0          0          0          0         1   \n",
       "1           1          0          0          0         0   \n",
       "2           1          0          0          0         0   \n",
       "3           1          0          0          0         2   \n",
       "4           1          0          0          0         1   \n",
       "5           1          0          0          0         2   \n",
       "6           1          0          0          0         0   \n",
       "7           1          0          0          0         1   \n",
       "8           1          0          0          0         1   \n",
       "9           0          0          0          0         0   \n",
       "10          0          0          0          0         0   \n",
       "11          0          1          1          1         0   \n",
       "12          1          1          1          1         1   \n",
       "13          0          0          0          0         1   \n",
       "14          0          0          0          1         0   \n",
       "\n",
       "    Diagnosis_nearest_2.0_cat  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           1  \n",
       "4                           2  \n",
       "5                           1  \n",
       "6                           1  \n",
       "7                           2  \n",
       "8                           1  \n",
       "9                           1  \n",
       "10                          2  \n",
       "11                          0  \n",
       "12                          2  \n",
       "13                          2  \n",
       "14                          2  \n",
       "\n",
       "[15 rows x 209 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = pd.read_pickle(\"./DATA/Linearly_Transformed_Unique_Dataset.pkl\")\n",
    "unique.reset_index(drop=True, inplace=True)\n",
    "print(unique.shape)\n",
    "unique.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9061ebda-528f-4373-a43f-c9f7303a7a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>path</th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "      <th>component_7</th>\n",
       "      <th>...</th>\n",
       "      <th>component_21</th>\n",
       "      <th>component_22</th>\n",
       "      <th>component_23</th>\n",
       "      <th>component_24</th>\n",
       "      <th>component_25</th>\n",
       "      <th>component_26</th>\n",
       "      <th>component_27</th>\n",
       "      <th>component_28</th>\n",
       "      <th>component_29</th>\n",
       "      <th>component_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>912.99866</td>\n",
       "      <td>842.33325</td>\n",
       "      <td>831.71893</td>\n",
       "      <td>1042.49220</td>\n",
       "      <td>1083.90710</td>\n",
       "      <td>670.48160</td>\n",
       "      <td>784.81110</td>\n",
       "      <td>...</td>\n",
       "      <td>839.09924</td>\n",
       "      <td>619.73230</td>\n",
       "      <td>681.45100</td>\n",
       "      <td>832.04670</td>\n",
       "      <td>659.40180</td>\n",
       "      <td>598.43787</td>\n",
       "      <td>737.67930</td>\n",
       "      <td>849.03940</td>\n",
       "      <td>653.38510</td>\n",
       "      <td>529.58984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>823.07510</td>\n",
       "      <td>780.51350</td>\n",
       "      <td>770.62060</td>\n",
       "      <td>901.71234</td>\n",
       "      <td>917.71313</td>\n",
       "      <td>618.90840</td>\n",
       "      <td>828.32007</td>\n",
       "      <td>...</td>\n",
       "      <td>765.77704</td>\n",
       "      <td>861.15450</td>\n",
       "      <td>674.06160</td>\n",
       "      <td>755.78380</td>\n",
       "      <td>719.56067</td>\n",
       "      <td>937.99410</td>\n",
       "      <td>694.54680</td>\n",
       "      <td>825.40790</td>\n",
       "      <td>766.40090</td>\n",
       "      <td>773.84576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>896.78010</td>\n",
       "      <td>931.24915</td>\n",
       "      <td>1173.90540</td>\n",
       "      <td>911.99170</td>\n",
       "      <td>908.41504</td>\n",
       "      <td>749.03250</td>\n",
       "      <td>988.38477</td>\n",
       "      <td>...</td>\n",
       "      <td>1046.81020</td>\n",
       "      <td>843.50710</td>\n",
       "      <td>877.13410</td>\n",
       "      <td>885.02180</td>\n",
       "      <td>911.55505</td>\n",
       "      <td>906.45730</td>\n",
       "      <td>701.53510</td>\n",
       "      <td>894.42840</td>\n",
       "      <td>837.21240</td>\n",
       "      <td>713.27203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_S_0619</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>872.89777</td>\n",
       "      <td>1011.12885</td>\n",
       "      <td>952.32367</td>\n",
       "      <td>1081.24560</td>\n",
       "      <td>1135.83150</td>\n",
       "      <td>764.39440</td>\n",
       "      <td>823.27960</td>\n",
       "      <td>...</td>\n",
       "      <td>857.98660</td>\n",
       "      <td>813.39230</td>\n",
       "      <td>913.79160</td>\n",
       "      <td>875.58560</td>\n",
       "      <td>1001.27344</td>\n",
       "      <td>827.59820</td>\n",
       "      <td>686.68600</td>\n",
       "      <td>651.28410</td>\n",
       "      <td>764.98206</td>\n",
       "      <td>742.52910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>799.76800</td>\n",
       "      <td>702.03735</td>\n",
       "      <td>825.50490</td>\n",
       "      <td>819.52435</td>\n",
       "      <td>871.45575</td>\n",
       "      <td>642.43066</td>\n",
       "      <td>679.25323</td>\n",
       "      <td>...</td>\n",
       "      <td>600.88570</td>\n",
       "      <td>702.83550</td>\n",
       "      <td>673.74255</td>\n",
       "      <td>764.65850</td>\n",
       "      <td>650.25160</td>\n",
       "      <td>685.98645</td>\n",
       "      <td>587.51636</td>\n",
       "      <td>666.16100</td>\n",
       "      <td>624.62510</td>\n",
       "      <td>647.47455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>935.90173</td>\n",
       "      <td>904.85030</td>\n",
       "      <td>1068.48660</td>\n",
       "      <td>833.15295</td>\n",
       "      <td>869.03230</td>\n",
       "      <td>722.40670</td>\n",
       "      <td>900.58360</td>\n",
       "      <td>...</td>\n",
       "      <td>941.39685</td>\n",
       "      <td>749.70526</td>\n",
       "      <td>827.75200</td>\n",
       "      <td>856.35065</td>\n",
       "      <td>678.61640</td>\n",
       "      <td>729.16160</td>\n",
       "      <td>626.40590</td>\n",
       "      <td>774.68340</td>\n",
       "      <td>857.99414</td>\n",
       "      <td>617.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002_S_0938</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>763.87410</td>\n",
       "      <td>666.19420</td>\n",
       "      <td>751.04395</td>\n",
       "      <td>787.73254</td>\n",
       "      <td>902.59890</td>\n",
       "      <td>555.30945</td>\n",
       "      <td>702.55975</td>\n",
       "      <td>...</td>\n",
       "      <td>619.10270</td>\n",
       "      <td>741.98724</td>\n",
       "      <td>691.55440</td>\n",
       "      <td>546.40186</td>\n",
       "      <td>702.20953</td>\n",
       "      <td>802.19720</td>\n",
       "      <td>676.04670</td>\n",
       "      <td>507.42386</td>\n",
       "      <td>834.45514</td>\n",
       "      <td>660.77460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002_S_0954</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>799.99390</td>\n",
       "      <td>604.88116</td>\n",
       "      <td>1058.69450</td>\n",
       "      <td>753.52400</td>\n",
       "      <td>828.36145</td>\n",
       "      <td>563.47675</td>\n",
       "      <td>639.34045</td>\n",
       "      <td>...</td>\n",
       "      <td>598.07935</td>\n",
       "      <td>479.03888</td>\n",
       "      <td>507.04572</td>\n",
       "      <td>489.14060</td>\n",
       "      <td>491.81630</td>\n",
       "      <td>603.75930</td>\n",
       "      <td>520.15784</td>\n",
       "      <td>588.56950</td>\n",
       "      <td>572.01660</td>\n",
       "      <td>503.36550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002_S_0955</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>828.01070</td>\n",
       "      <td>809.28253</td>\n",
       "      <td>850.39040</td>\n",
       "      <td>821.97160</td>\n",
       "      <td>978.87480</td>\n",
       "      <td>612.34015</td>\n",
       "      <td>724.43760</td>\n",
       "      <td>...</td>\n",
       "      <td>843.48520</td>\n",
       "      <td>656.23420</td>\n",
       "      <td>706.19210</td>\n",
       "      <td>609.48890</td>\n",
       "      <td>808.98870</td>\n",
       "      <td>701.59686</td>\n",
       "      <td>659.30005</td>\n",
       "      <td>588.45310</td>\n",
       "      <td>586.52386</td>\n",
       "      <td>661.83734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_1018</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>877.81720</td>\n",
       "      <td>746.37020</td>\n",
       "      <td>979.36390</td>\n",
       "      <td>1023.07086</td>\n",
       "      <td>1095.75070</td>\n",
       "      <td>606.95306</td>\n",
       "      <td>652.39770</td>\n",
       "      <td>...</td>\n",
       "      <td>862.20703</td>\n",
       "      <td>825.19970</td>\n",
       "      <td>696.64390</td>\n",
       "      <td>778.52200</td>\n",
       "      <td>674.44110</td>\n",
       "      <td>578.46576</td>\n",
       "      <td>703.68823</td>\n",
       "      <td>793.19147</td>\n",
       "      <td>721.19824</td>\n",
       "      <td>666.04390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>002_S_1070</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>939.74810</td>\n",
       "      <td>869.93164</td>\n",
       "      <td>1153.62430</td>\n",
       "      <td>1120.60790</td>\n",
       "      <td>1141.11410</td>\n",
       "      <td>613.00256</td>\n",
       "      <td>775.76780</td>\n",
       "      <td>...</td>\n",
       "      <td>987.11536</td>\n",
       "      <td>986.87195</td>\n",
       "      <td>840.52110</td>\n",
       "      <td>571.26306</td>\n",
       "      <td>908.27924</td>\n",
       "      <td>710.94650</td>\n",
       "      <td>684.20404</td>\n",
       "      <td>905.53450</td>\n",
       "      <td>665.81260</td>\n",
       "      <td>642.79360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002_S_1261</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>798.93567</td>\n",
       "      <td>774.09320</td>\n",
       "      <td>1002.97150</td>\n",
       "      <td>867.62780</td>\n",
       "      <td>1196.45970</td>\n",
       "      <td>783.28235</td>\n",
       "      <td>889.45050</td>\n",
       "      <td>...</td>\n",
       "      <td>790.93830</td>\n",
       "      <td>704.54450</td>\n",
       "      <td>789.02660</td>\n",
       "      <td>725.43700</td>\n",
       "      <td>806.42444</td>\n",
       "      <td>799.59470</td>\n",
       "      <td>783.26276</td>\n",
       "      <td>677.44244</td>\n",
       "      <td>833.62400</td>\n",
       "      <td>883.13340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002_S_2043</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>835.68445</td>\n",
       "      <td>682.47626</td>\n",
       "      <td>1022.22687</td>\n",
       "      <td>855.15400</td>\n",
       "      <td>724.56120</td>\n",
       "      <td>661.45860</td>\n",
       "      <td>766.36680</td>\n",
       "      <td>...</td>\n",
       "      <td>779.71630</td>\n",
       "      <td>849.08746</td>\n",
       "      <td>721.63470</td>\n",
       "      <td>724.61150</td>\n",
       "      <td>731.88730</td>\n",
       "      <td>773.20825</td>\n",
       "      <td>816.50146</td>\n",
       "      <td>862.53705</td>\n",
       "      <td>912.75490</td>\n",
       "      <td>809.73236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>002_S_4171</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>879.29553</td>\n",
       "      <td>774.50665</td>\n",
       "      <td>700.09534</td>\n",
       "      <td>744.25946</td>\n",
       "      <td>889.93524</td>\n",
       "      <td>612.84845</td>\n",
       "      <td>793.81550</td>\n",
       "      <td>...</td>\n",
       "      <td>897.14480</td>\n",
       "      <td>668.08130</td>\n",
       "      <td>664.98820</td>\n",
       "      <td>479.71442</td>\n",
       "      <td>653.03390</td>\n",
       "      <td>660.88200</td>\n",
       "      <td>680.15765</td>\n",
       "      <td>750.05080</td>\n",
       "      <td>752.68207</td>\n",
       "      <td>712.94850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>002_S_4213</td>\n",
       "      <td>ses-M0</td>\n",
       "      <td>/cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...</td>\n",
       "      <td>804.13586</td>\n",
       "      <td>739.42523</td>\n",
       "      <td>773.10376</td>\n",
       "      <td>881.81976</td>\n",
       "      <td>756.04456</td>\n",
       "      <td>660.41943</td>\n",
       "      <td>850.67957</td>\n",
       "      <td>...</td>\n",
       "      <td>808.27185</td>\n",
       "      <td>776.25446</td>\n",
       "      <td>717.07623</td>\n",
       "      <td>632.61127</td>\n",
       "      <td>815.23940</td>\n",
       "      <td>724.66455</td>\n",
       "      <td>715.16100</td>\n",
       "      <td>852.00340</td>\n",
       "      <td>791.08260</td>\n",
       "      <td>585.96060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id session_id  \\\n",
       "0      002_S_0295     ses-M0   \n",
       "1      002_S_0413     ses-M0   \n",
       "2      002_S_0559     ses-M0   \n",
       "3      002_S_0619     ses-M0   \n",
       "4      002_S_0729     ses-M0   \n",
       "5      002_S_0816     ses-M0   \n",
       "6      002_S_0938     ses-M0   \n",
       "7      002_S_0954     ses-M0   \n",
       "8      002_S_0955     ses-M0   \n",
       "9      002_S_1018     ses-M0   \n",
       "10     002_S_1070     ses-M0   \n",
       "11     002_S_1261     ses-M0   \n",
       "12     002_S_2043     ses-M0   \n",
       "13     002_S_4171     ses-M0   \n",
       "14     002_S_4213     ses-M0   \n",
       "\n",
       "                                                 path  component_1  \\\n",
       "0   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    912.99866   \n",
       "1   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    823.07510   \n",
       "2   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    896.78010   \n",
       "3   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    872.89777   \n",
       "4   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    799.76800   \n",
       "5   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    935.90173   \n",
       "6   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    763.87410   \n",
       "7   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    799.99390   \n",
       "8   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    828.01070   \n",
       "9   /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    877.81720   \n",
       "10  /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    939.74810   \n",
       "11  /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    798.93567   \n",
       "12  /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    835.68445   \n",
       "13  /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    879.29553   \n",
       "14  /cbica/projects/ISTAGING/Pipelines/ISTAGING_Da...    804.13586   \n",
       "\n",
       "    component_2  component_3  component_4  component_5  component_6  \\\n",
       "0     842.33325    831.71893   1042.49220   1083.90710    670.48160   \n",
       "1     780.51350    770.62060    901.71234    917.71313    618.90840   \n",
       "2     931.24915   1173.90540    911.99170    908.41504    749.03250   \n",
       "3    1011.12885    952.32367   1081.24560   1135.83150    764.39440   \n",
       "4     702.03735    825.50490    819.52435    871.45575    642.43066   \n",
       "5     904.85030   1068.48660    833.15295    869.03230    722.40670   \n",
       "6     666.19420    751.04395    787.73254    902.59890    555.30945   \n",
       "7     604.88116   1058.69450    753.52400    828.36145    563.47675   \n",
       "8     809.28253    850.39040    821.97160    978.87480    612.34015   \n",
       "9     746.37020    979.36390   1023.07086   1095.75070    606.95306   \n",
       "10    869.93164   1153.62430   1120.60790   1141.11410    613.00256   \n",
       "11    774.09320   1002.97150    867.62780   1196.45970    783.28235   \n",
       "12    682.47626   1022.22687    855.15400    724.56120    661.45860   \n",
       "13    774.50665    700.09534    744.25946    889.93524    612.84845   \n",
       "14    739.42523    773.10376    881.81976    756.04456    660.41943   \n",
       "\n",
       "    component_7  ...  component_21  component_22  component_23  component_24  \\\n",
       "0     784.81110  ...     839.09924     619.73230     681.45100     832.04670   \n",
       "1     828.32007  ...     765.77704     861.15450     674.06160     755.78380   \n",
       "2     988.38477  ...    1046.81020     843.50710     877.13410     885.02180   \n",
       "3     823.27960  ...     857.98660     813.39230     913.79160     875.58560   \n",
       "4     679.25323  ...     600.88570     702.83550     673.74255     764.65850   \n",
       "5     900.58360  ...     941.39685     749.70526     827.75200     856.35065   \n",
       "6     702.55975  ...     619.10270     741.98724     691.55440     546.40186   \n",
       "7     639.34045  ...     598.07935     479.03888     507.04572     489.14060   \n",
       "8     724.43760  ...     843.48520     656.23420     706.19210     609.48890   \n",
       "9     652.39770  ...     862.20703     825.19970     696.64390     778.52200   \n",
       "10    775.76780  ...     987.11536     986.87195     840.52110     571.26306   \n",
       "11    889.45050  ...     790.93830     704.54450     789.02660     725.43700   \n",
       "12    766.36680  ...     779.71630     849.08746     721.63470     724.61150   \n",
       "13    793.81550  ...     897.14480     668.08130     664.98820     479.71442   \n",
       "14    850.67957  ...     808.27185     776.25446     717.07623     632.61127   \n",
       "\n",
       "    component_25  component_26  component_27  component_28  component_29  \\\n",
       "0      659.40180     598.43787     737.67930     849.03940     653.38510   \n",
       "1      719.56067     937.99410     694.54680     825.40790     766.40090   \n",
       "2      911.55505     906.45730     701.53510     894.42840     837.21240   \n",
       "3     1001.27344     827.59820     686.68600     651.28410     764.98206   \n",
       "4      650.25160     685.98645     587.51636     666.16100     624.62510   \n",
       "5      678.61640     729.16160     626.40590     774.68340     857.99414   \n",
       "6      702.20953     802.19720     676.04670     507.42386     834.45514   \n",
       "7      491.81630     603.75930     520.15784     588.56950     572.01660   \n",
       "8      808.98870     701.59686     659.30005     588.45310     586.52386   \n",
       "9      674.44110     578.46576     703.68823     793.19147     721.19824   \n",
       "10     908.27924     710.94650     684.20404     905.53450     665.81260   \n",
       "11     806.42444     799.59470     783.26276     677.44244     833.62400   \n",
       "12     731.88730     773.20825     816.50146     862.53705     912.75490   \n",
       "13     653.03390     660.88200     680.15765     750.05080     752.68207   \n",
       "14     815.23940     724.66455     715.16100     852.00340     791.08260   \n",
       "\n",
       "    component_30  \n",
       "0      529.58984  \n",
       "1      773.84576  \n",
       "2      713.27203  \n",
       "3      742.52910  \n",
       "4      647.47455  \n",
       "5      617.07587  \n",
       "6      660.77460  \n",
       "7      503.36550  \n",
       "8      661.83734  \n",
       "9      666.04390  \n",
       "10     642.79360  \n",
       "11     883.13340  \n",
       "12     809.73236  \n",
       "13     712.94850  \n",
       "14     585.96060  \n",
       "\n",
       "[15 rows x 33 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnmf_coeffs = pd.read_csv(\"./DATA/loading_coefficients_30components.tsv\", sep='\\t')\n",
    "print(opnmf_coeffs.shape)\n",
    "opnmf_coeffs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9beba3e1-6906-4b02-b2d5-52031a127633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "      <th>component_7</th>\n",
       "      <th>component_8</th>\n",
       "      <th>component_9</th>\n",
       "      <th>component_10</th>\n",
       "      <th>...</th>\n",
       "      <th>component_21</th>\n",
       "      <th>component_22</th>\n",
       "      <th>component_23</th>\n",
       "      <th>component_24</th>\n",
       "      <th>component_25</th>\n",
       "      <th>component_26</th>\n",
       "      <th>component_27</th>\n",
       "      <th>component_28</th>\n",
       "      <th>component_29</th>\n",
       "      <th>component_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>863.777507</td>\n",
       "      <td>781.904471</td>\n",
       "      <td>905.140011</td>\n",
       "      <td>909.370950</td>\n",
       "      <td>915.027364</td>\n",
       "      <td>669.806835</td>\n",
       "      <td>823.367620</td>\n",
       "      <td>706.792204</td>\n",
       "      <td>892.493370</td>\n",
       "      <td>732.315230</td>\n",
       "      <td>...</td>\n",
       "      <td>832.377176</td>\n",
       "      <td>785.466661</td>\n",
       "      <td>743.112438</td>\n",
       "      <td>751.624929</td>\n",
       "      <td>739.858197</td>\n",
       "      <td>744.528792</td>\n",
       "      <td>719.829262</td>\n",
       "      <td>774.191859</td>\n",
       "      <td>751.537933</td>\n",
       "      <td>686.830767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>78.371161</td>\n",
       "      <td>82.182798</td>\n",
       "      <td>128.865778</td>\n",
       "      <td>111.816722</td>\n",
       "      <td>137.583178</td>\n",
       "      <td>76.249792</td>\n",
       "      <td>129.473465</td>\n",
       "      <td>110.927316</td>\n",
       "      <td>139.243792</td>\n",
       "      <td>106.202669</td>\n",
       "      <td>...</td>\n",
       "      <td>137.544145</td>\n",
       "      <td>119.337638</td>\n",
       "      <td>109.436300</td>\n",
       "      <td>119.358767</td>\n",
       "      <td>118.147490</td>\n",
       "      <td>120.946548</td>\n",
       "      <td>108.284309</td>\n",
       "      <td>120.942445</td>\n",
       "      <td>111.793852</td>\n",
       "      <td>99.958751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>602.786130</td>\n",
       "      <td>599.079960</td>\n",
       "      <td>599.223450</td>\n",
       "      <td>568.550350</td>\n",
       "      <td>589.073400</td>\n",
       "      <td>399.038060</td>\n",
       "      <td>441.559050</td>\n",
       "      <td>385.688750</td>\n",
       "      <td>457.316200</td>\n",
       "      <td>404.042200</td>\n",
       "      <td>...</td>\n",
       "      <td>460.988160</td>\n",
       "      <td>353.536130</td>\n",
       "      <td>464.752350</td>\n",
       "      <td>413.940160</td>\n",
       "      <td>364.682860</td>\n",
       "      <td>453.444370</td>\n",
       "      <td>353.239440</td>\n",
       "      <td>400.764280</td>\n",
       "      <td>420.010400</td>\n",
       "      <td>388.626100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>810.117043</td>\n",
       "      <td>722.402055</td>\n",
       "      <td>816.202600</td>\n",
       "      <td>831.624082</td>\n",
       "      <td>821.333647</td>\n",
       "      <td>617.629613</td>\n",
       "      <td>732.665600</td>\n",
       "      <td>634.250387</td>\n",
       "      <td>791.039260</td>\n",
       "      <td>660.080187</td>\n",
       "      <td>...</td>\n",
       "      <td>735.486650</td>\n",
       "      <td>705.654567</td>\n",
       "      <td>669.527582</td>\n",
       "      <td>671.791912</td>\n",
       "      <td>657.370375</td>\n",
       "      <td>656.151563</td>\n",
       "      <td>646.184825</td>\n",
       "      <td>696.866845</td>\n",
       "      <td>672.129320</td>\n",
       "      <td>619.188275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>862.579650</td>\n",
       "      <td>778.983400</td>\n",
       "      <td>891.914365</td>\n",
       "      <td>906.916450</td>\n",
       "      <td>904.696870</td>\n",
       "      <td>664.257080</td>\n",
       "      <td>813.917550</td>\n",
       "      <td>703.791320</td>\n",
       "      <td>886.171125</td>\n",
       "      <td>720.097100</td>\n",
       "      <td>...</td>\n",
       "      <td>829.508780</td>\n",
       "      <td>780.940705</td>\n",
       "      <td>734.538470</td>\n",
       "      <td>749.446330</td>\n",
       "      <td>731.065555</td>\n",
       "      <td>737.287950</td>\n",
       "      <td>712.069420</td>\n",
       "      <td>779.084045</td>\n",
       "      <td>741.242580</td>\n",
       "      <td>677.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>913.483925</td>\n",
       "      <td>835.919130</td>\n",
       "      <td>986.971632</td>\n",
       "      <td>981.082065</td>\n",
       "      <td>998.064525</td>\n",
       "      <td>713.938953</td>\n",
       "      <td>903.165055</td>\n",
       "      <td>777.107850</td>\n",
       "      <td>985.469943</td>\n",
       "      <td>799.073865</td>\n",
       "      <td>...</td>\n",
       "      <td>919.835075</td>\n",
       "      <td>857.195625</td>\n",
       "      <td>808.003338</td>\n",
       "      <td>825.998950</td>\n",
       "      <td>811.361300</td>\n",
       "      <td>823.273120</td>\n",
       "      <td>788.066862</td>\n",
       "      <td>856.068262</td>\n",
       "      <td>821.149250</td>\n",
       "      <td>744.988095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1178.071200</td>\n",
       "      <td>1087.235100</td>\n",
       "      <td>1420.445700</td>\n",
       "      <td>1297.013800</td>\n",
       "      <td>1518.281000</td>\n",
       "      <td>1084.396600</td>\n",
       "      <td>1396.545000</td>\n",
       "      <td>1114.828100</td>\n",
       "      <td>1429.093100</td>\n",
       "      <td>1217.897600</td>\n",
       "      <td>...</td>\n",
       "      <td>1380.400300</td>\n",
       "      <td>1266.960700</td>\n",
       "      <td>1147.821000</td>\n",
       "      <td>1351.282800</td>\n",
       "      <td>1272.634200</td>\n",
       "      <td>1244.540300</td>\n",
       "      <td>1150.189600</td>\n",
       "      <td>1161.774700</td>\n",
       "      <td>1223.262200</td>\n",
       "      <td>1024.356800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       component_1  component_2  component_3  component_4  component_5  \\\n",
       "count  1294.000000  1294.000000  1294.000000  1294.000000  1294.000000   \n",
       "mean    863.777507   781.904471   905.140011   909.370950   915.027364   \n",
       "std      78.371161    82.182798   128.865778   111.816722   137.583178   \n",
       "min     602.786130   599.079960   599.223450   568.550350   589.073400   \n",
       "25%     810.117043   722.402055   816.202600   831.624082   821.333647   \n",
       "50%     862.579650   778.983400   891.914365   906.916450   904.696870   \n",
       "75%     913.483925   835.919130   986.971632   981.082065   998.064525   \n",
       "max    1178.071200  1087.235100  1420.445700  1297.013800  1518.281000   \n",
       "\n",
       "       component_6  component_7  component_8  component_9  component_10  ...  \\\n",
       "count  1294.000000  1294.000000  1294.000000  1294.000000   1294.000000  ...   \n",
       "mean    669.806835   823.367620   706.792204   892.493370    732.315230  ...   \n",
       "std      76.249792   129.473465   110.927316   139.243792    106.202669  ...   \n",
       "min     399.038060   441.559050   385.688750   457.316200    404.042200  ...   \n",
       "25%     617.629613   732.665600   634.250387   791.039260    660.080187  ...   \n",
       "50%     664.257080   813.917550   703.791320   886.171125    720.097100  ...   \n",
       "75%     713.938953   903.165055   777.107850   985.469943    799.073865  ...   \n",
       "max    1084.396600  1396.545000  1114.828100  1429.093100   1217.897600  ...   \n",
       "\n",
       "       component_21  component_22  component_23  component_24  component_25  \\\n",
       "count   1294.000000   1294.000000   1294.000000   1294.000000   1294.000000   \n",
       "mean     832.377176    785.466661    743.112438    751.624929    739.858197   \n",
       "std      137.544145    119.337638    109.436300    119.358767    118.147490   \n",
       "min      460.988160    353.536130    464.752350    413.940160    364.682860   \n",
       "25%      735.486650    705.654567    669.527582    671.791912    657.370375   \n",
       "50%      829.508780    780.940705    734.538470    749.446330    731.065555   \n",
       "75%      919.835075    857.195625    808.003338    825.998950    811.361300   \n",
       "max     1380.400300   1266.960700   1147.821000   1351.282800   1272.634200   \n",
       "\n",
       "       component_26  component_27  component_28  component_29  component_30  \n",
       "count   1294.000000   1294.000000   1294.000000   1294.000000   1294.000000  \n",
       "mean     744.528792    719.829262    774.191859    751.537933    686.830767  \n",
       "std      120.946548    108.284309    120.942445    111.793852     99.958751  \n",
       "min      453.444370    353.239440    400.764280    420.010400    388.626100  \n",
       "25%      656.151563    646.184825    696.866845    672.129320    619.188275  \n",
       "50%      737.287950    712.069420    779.084045    741.242580    677.992400  \n",
       "75%      823.273120    788.066862    856.068262    821.149250    744.988095  \n",
       "max     1244.540300   1150.189600   1161.774700   1223.262200   1024.356800  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnmf_coeffs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e95d9d77-1fa1-420b-bab8-4845f16a6730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 209)\n",
      "(1294, 33)\n",
      "(1294, 209)\n",
      "(1294, 33)\n"
     ]
    }
   ],
   "source": [
    "print(unique.shape)\n",
    "print(opnmf_coeffs.shape)\n",
    "unique = unique[unique['PTID'].isin(opnmf_coeffs['participant_id'])]\n",
    "print(unique.shape)\n",
    "print(opnmf_coeffs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c65a9-4a40-4f10-bb33-64afa6c8b7e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Building, training the DCCA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffbd919-bf97-4fb1-bc80-06a3b2d7aa0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create the 2 views:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5800ba3-ccce-46f0-b1d1-b48033265c37",
   "metadata": {},
   "source": [
    "The first view consists of the imaging data, that are in the form of 30 real numbers. Those numbers are the outcome of Orthogonal Projection Non-Negative Matrix Factorization (OPNMF) on the RAVENS data.\n",
    "\n",
    "The second view consists of the 54 SNP (Single Nucleotide Polymorphism, \"snip\"), for each individual. They are either 0 or 1. \n",
    "\n",
    "The 2 views are the most basic views that can be used for the Deep CCA, and in further tests more features will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac59eef-0e59-4b79-b9d4-b39f6654f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 1:\n",
    "view_1 = opnmf_coeffs.loc[:,\"component_1\":\"component_30\"]\n",
    "\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de15f5b-f1df-4007-9421-19e545f0bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "      <th>component_7</th>\n",
       "      <th>component_8</th>\n",
       "      <th>component_9</th>\n",
       "      <th>component_10</th>\n",
       "      <th>...</th>\n",
       "      <th>component_21</th>\n",
       "      <th>component_22</th>\n",
       "      <th>component_23</th>\n",
       "      <th>component_24</th>\n",
       "      <th>component_25</th>\n",
       "      <th>component_26</th>\n",
       "      <th>component_27</th>\n",
       "      <th>component_28</th>\n",
       "      <th>component_29</th>\n",
       "      <th>component_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>912.99866</td>\n",
       "      <td>842.33325</td>\n",
       "      <td>831.71893</td>\n",
       "      <td>1042.49220</td>\n",
       "      <td>1083.90710</td>\n",
       "      <td>670.48160</td>\n",
       "      <td>784.81110</td>\n",
       "      <td>784.83930</td>\n",
       "      <td>1107.9929</td>\n",
       "      <td>742.97406</td>\n",
       "      <td>...</td>\n",
       "      <td>839.09924</td>\n",
       "      <td>619.7323</td>\n",
       "      <td>681.45100</td>\n",
       "      <td>832.0467</td>\n",
       "      <td>659.40180</td>\n",
       "      <td>598.43787</td>\n",
       "      <td>737.67930</td>\n",
       "      <td>849.0394</td>\n",
       "      <td>653.38510</td>\n",
       "      <td>529.58984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823.07510</td>\n",
       "      <td>780.51350</td>\n",
       "      <td>770.62060</td>\n",
       "      <td>901.71234</td>\n",
       "      <td>917.71313</td>\n",
       "      <td>618.90840</td>\n",
       "      <td>828.32007</td>\n",
       "      <td>758.25574</td>\n",
       "      <td>722.0375</td>\n",
       "      <td>975.20610</td>\n",
       "      <td>...</td>\n",
       "      <td>765.77704</td>\n",
       "      <td>861.1545</td>\n",
       "      <td>674.06160</td>\n",
       "      <td>755.7838</td>\n",
       "      <td>719.56067</td>\n",
       "      <td>937.99410</td>\n",
       "      <td>694.54680</td>\n",
       "      <td>825.4079</td>\n",
       "      <td>766.40090</td>\n",
       "      <td>773.84576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>896.78010</td>\n",
       "      <td>931.24915</td>\n",
       "      <td>1173.90540</td>\n",
       "      <td>911.99170</td>\n",
       "      <td>908.41504</td>\n",
       "      <td>749.03250</td>\n",
       "      <td>988.38477</td>\n",
       "      <td>787.45593</td>\n",
       "      <td>840.4178</td>\n",
       "      <td>765.08220</td>\n",
       "      <td>...</td>\n",
       "      <td>1046.81020</td>\n",
       "      <td>843.5071</td>\n",
       "      <td>877.13410</td>\n",
       "      <td>885.0218</td>\n",
       "      <td>911.55505</td>\n",
       "      <td>906.45730</td>\n",
       "      <td>701.53510</td>\n",
       "      <td>894.4284</td>\n",
       "      <td>837.21240</td>\n",
       "      <td>713.27203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>872.89777</td>\n",
       "      <td>1011.12885</td>\n",
       "      <td>952.32367</td>\n",
       "      <td>1081.24560</td>\n",
       "      <td>1135.83150</td>\n",
       "      <td>764.39440</td>\n",
       "      <td>823.27960</td>\n",
       "      <td>975.41766</td>\n",
       "      <td>1100.7651</td>\n",
       "      <td>826.42750</td>\n",
       "      <td>...</td>\n",
       "      <td>857.98660</td>\n",
       "      <td>813.3923</td>\n",
       "      <td>913.79160</td>\n",
       "      <td>875.5856</td>\n",
       "      <td>1001.27344</td>\n",
       "      <td>827.59820</td>\n",
       "      <td>686.68600</td>\n",
       "      <td>651.2841</td>\n",
       "      <td>764.98206</td>\n",
       "      <td>742.52910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>799.76800</td>\n",
       "      <td>702.03735</td>\n",
       "      <td>825.50490</td>\n",
       "      <td>819.52435</td>\n",
       "      <td>871.45575</td>\n",
       "      <td>642.43066</td>\n",
       "      <td>679.25323</td>\n",
       "      <td>712.70260</td>\n",
       "      <td>805.9348</td>\n",
       "      <td>589.86010</td>\n",
       "      <td>...</td>\n",
       "      <td>600.88570</td>\n",
       "      <td>702.8355</td>\n",
       "      <td>673.74255</td>\n",
       "      <td>764.6585</td>\n",
       "      <td>650.25160</td>\n",
       "      <td>685.98645</td>\n",
       "      <td>587.51636</td>\n",
       "      <td>666.1610</td>\n",
       "      <td>624.62510</td>\n",
       "      <td>647.47455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   component_1  component_2  component_3  component_4  component_5  \\\n",
       "0    912.99866    842.33325    831.71893   1042.49220   1083.90710   \n",
       "1    823.07510    780.51350    770.62060    901.71234    917.71313   \n",
       "2    896.78010    931.24915   1173.90540    911.99170    908.41504   \n",
       "3    872.89777   1011.12885    952.32367   1081.24560   1135.83150   \n",
       "4    799.76800    702.03735    825.50490    819.52435    871.45575   \n",
       "\n",
       "   component_6  component_7  component_8  component_9  component_10  ...  \\\n",
       "0    670.48160    784.81110    784.83930    1107.9929     742.97406  ...   \n",
       "1    618.90840    828.32007    758.25574     722.0375     975.20610  ...   \n",
       "2    749.03250    988.38477    787.45593     840.4178     765.08220  ...   \n",
       "3    764.39440    823.27960    975.41766    1100.7651     826.42750  ...   \n",
       "4    642.43066    679.25323    712.70260     805.9348     589.86010  ...   \n",
       "\n",
       "   component_21  component_22  component_23  component_24  component_25  \\\n",
       "0     839.09924      619.7323     681.45100      832.0467     659.40180   \n",
       "1     765.77704      861.1545     674.06160      755.7838     719.56067   \n",
       "2    1046.81020      843.5071     877.13410      885.0218     911.55505   \n",
       "3     857.98660      813.3923     913.79160      875.5856    1001.27344   \n",
       "4     600.88570      702.8355     673.74255      764.6585     650.25160   \n",
       "\n",
       "   component_26  component_27  component_28  component_29  component_30  \n",
       "0     598.43787     737.67930      849.0394     653.38510     529.58984  \n",
       "1     937.99410     694.54680      825.4079     766.40090     773.84576  \n",
       "2     906.45730     701.53510      894.4284     837.21240     713.27203  \n",
       "3     827.59820     686.68600      651.2841     764.98206     742.52910  \n",
       "4     685.98645     587.51636      666.1610     624.62510     647.47455  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs4575098</th>\n",
       "      <th>rs6656401</th>\n",
       "      <th>rs2093760</th>\n",
       "      <th>rs4844610</th>\n",
       "      <th>rs4663105</th>\n",
       "      <th>rs6733839</th>\n",
       "      <th>rs10933431</th>\n",
       "      <th>rs35349669</th>\n",
       "      <th>rs6448453</th>\n",
       "      <th>rs190982</th>\n",
       "      <th>...</th>\n",
       "      <th>rs28394864</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rs4575098  rs6656401  rs2093760  rs4844610  rs4663105  rs6733839  \\\n",
       "0          0          0          0          0          1          1   \n",
       "1          1          0          0          0          0          0   \n",
       "2          0          0          0          0          1          0   \n",
       "3          0          1          1          1          0          0   \n",
       "4          0          0          0          0          1          1   \n",
       "\n",
       "   rs10933431  rs35349669  rs6448453  rs190982  ...  rs28394864  rs111278892  \\\n",
       "0           1           0          0         1  ...           0            1   \n",
       "1           0           1          0         0  ...           1            0   \n",
       "2           1           0          0         1  ...           2            0   \n",
       "3           0           2          1         1  ...           1            0   \n",
       "4           0           1          0         0  ...           1            0   \n",
       "\n",
       "   rs3752246  rs4147929  rs41289512  rs3865444  rs6024870  rs6014724  \\\n",
       "0          1          1           0          0          0          0   \n",
       "1          1          1           0          1          0          0   \n",
       "2          0          0           0          1          0          0   \n",
       "3          0          0           1          1          0          0   \n",
       "4          0          0           1          1          0          0   \n",
       "\n",
       "   rs7274581  rs429358  \n",
       "0          0         1  \n",
       "1          0         0  \n",
       "2          0         0  \n",
       "3          0         2  \n",
       "4          0         1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"View 1:\")\n",
    "display(view_1.head())\n",
    "print(\"View 2:\")\n",
    "display(view_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb1ff5-15b4-4674-9fd9-19d55d1aa4b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7078ec77-fd5f-4997-ab3f-acb92b1552da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a gpu exists, torch.device should be 'gpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 100\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 30 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "# this apparently can be different for each network, some experimentation is needed!\n",
    "layer_sizes1 = [256, 1024, 1024, outdim_size]\n",
    "layer_sizes2 = [256, 1024, 1024, outdim_size]\n",
    "# layer_sizes1 = [64, 128, outdim_size]\n",
    "# layer_sizes2 = [64, 128, outdim_size]\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-4\n",
    "epoch_num = 150\n",
    "epoch_log_freq = 50\n",
    "batch_size = 1000\n",
    "\n",
    "# the path to save the final learned features, as DCCA-o-d.\n",
    "save_to = './DATA/ADNI_OPNMF_DCCA_features_'+str(outdim_size)+'_'+str(len(layer_sizes1)-1)+'.pkl'\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-3\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top \n",
    "# outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = False\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7192ec-6eb7-423f-baa4-d26bde928774",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training the DCCA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d1edd5-3a26-48a0-817e-3222d6629dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "007e949f-1225-44a5-a41b-9a6aa3a34719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 30) <class 'numpy.ndarray'> float64\n",
      "(1294, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1294, 30]) <class 'torch.Tensor'>\n",
      "torch.Size([1294, 54]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# View 1:\n",
    "view_1 = opnmf_coeffs.loc[:,\"component_1\":\"component_30\"]\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]\n",
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()\n",
    "# Scramble the datapoints for randomness:\n",
    "indices = np.arange(view_1_n.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "view_1_n = view_1_n[indices]\n",
    "view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))\n",
    "\n",
    "data1 = view_1_t\n",
    "data2 = view_2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959d51b8-d5b8-46d0-b00f-0e5102d8367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2022-03-15 19:04:42,603 ] - DataParallel(\n",
      "  (module): DeepCCA(\n",
      "    (model1): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=30, out_features=256, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=100, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model2): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=54, out_features=256, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=100, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[ INFO : 2022-03-15 19:04:42,604 ] - RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    momentum: 0\n",
      "    weight_decay: 0.001\n",
      ")\n",
      "[ INFO : 2022-03-15 19:04:42,948 ] - Epoch 1: val_loss improved from 0.0000 to -3.1709\n",
      "[ INFO : 2022-03-15 19:04:42,949 ] - Epoch 1/150 - time: 0.34 - training_loss: -22.9603 - val_loss: -3.1709\n",
      "[ INFO : 2022-03-15 19:04:43,211 ] - Epoch 2: val_loss improved from -3.1709 to -3.1830\n",
      "[ INFO : 2022-03-15 19:04:43,472 ] - Epoch 3: val_loss improved from -3.1830 to -3.2019\n",
      "[ INFO : 2022-03-15 19:04:43,754 ] - Epoch 4: val_loss improved from -3.2019 to -3.2362\n",
      "[ INFO : 2022-03-15 19:04:44,015 ] - Epoch 5: val_loss improved from -3.2362 to -3.2926\n",
      "[ INFO : 2022-03-15 19:04:44,275 ] - Epoch 6: val_loss improved from -3.2926 to -3.3705\n",
      "[ INFO : 2022-03-15 19:04:44,534 ] - Epoch 7: val_loss improved from -3.3705 to -3.5128\n",
      "[ INFO : 2022-03-15 19:04:44,790 ] - Epoch 8: val_loss improved from -3.5128 to -3.6770\n",
      "[ INFO : 2022-03-15 19:04:45,064 ] - Epoch 9: val_loss improved from -3.6770 to -3.9439\n",
      "[ INFO : 2022-03-15 19:04:45,340 ] - Epoch 10: val_loss improved from -3.9439 to -4.2577\n",
      "[ INFO : 2022-03-15 19:04:45,707 ] - Epoch 11: val_loss improved from -4.2577 to -4.6960\n",
      "[ INFO : 2022-03-15 19:04:46,073 ] - Epoch 12: val_loss improved from -4.6960 to -5.1780\n",
      "[ INFO : 2022-03-15 19:04:46,393 ] - Epoch 13: val_loss improved from -5.1780 to -5.7920\n",
      "[ INFO : 2022-03-15 19:04:46,647 ] - Epoch 14: val_loss improved from -5.7920 to -6.4677\n",
      "[ INFO : 2022-03-15 19:04:46,907 ] - Epoch 15: val_loss improved from -6.4677 to -7.2381\n",
      "[ INFO : 2022-03-15 19:04:47,164 ] - Epoch 16: val_loss improved from -7.2381 to -8.1463\n",
      "[ INFO : 2022-03-15 19:04:47,439 ] - Epoch 17: val_loss improved from -8.1463 to -8.9786\n",
      "[ INFO : 2022-03-15 19:04:47,698 ] - Epoch 18: val_loss improved from -8.9786 to -9.9810\n",
      "[ INFO : 2022-03-15 19:04:47,997 ] - Epoch 19: val_loss improved from -9.9810 to -10.8934\n",
      "[ INFO : 2022-03-15 19:04:48,261 ] - Epoch 20: val_loss improved from -10.8934 to -12.0026\n",
      "[ INFO : 2022-03-15 19:04:48,879 ] - Epoch 21: val_loss improved from -12.0026 to -12.9790\n",
      "[ INFO : 2022-03-15 19:04:49,282 ] - Epoch 22: val_loss improved from -12.9790 to -13.7774\n",
      "[ INFO : 2022-03-15 19:04:49,556 ] - Epoch 23: val_loss improved from -13.7774 to -14.9134\n",
      "[ INFO : 2022-03-15 19:04:49,828 ] - Epoch 24: val_loss improved from -14.9134 to -15.6764\n",
      "[ INFO : 2022-03-15 19:04:50,096 ] - Epoch 25: val_loss improved from -15.6764 to -16.5967\n",
      "[ INFO : 2022-03-15 19:04:50,461 ] - Epoch 26: val_loss improved from -16.5967 to -17.4006\n",
      "[ INFO : 2022-03-15 19:04:50,792 ] - Epoch 27: val_loss improved from -17.4006 to -18.2774\n",
      "[ INFO : 2022-03-15 19:04:51,047 ] - Epoch 28: val_loss improved from -18.2774 to -19.0912\n",
      "[ INFO : 2022-03-15 19:04:51,374 ] - Epoch 29: val_loss improved from -19.0912 to -19.8057\n",
      "[ INFO : 2022-03-15 19:04:51,670 ] - Epoch 30: val_loss improved from -19.8057 to -20.5897\n",
      "[ INFO : 2022-03-15 19:04:51,935 ] - Epoch 31: val_loss improved from -20.5897 to -21.2233\n",
      "[ INFO : 2022-03-15 19:04:52,229 ] - Epoch 32: val_loss improved from -21.2233 to -22.1069\n",
      "[ INFO : 2022-03-15 19:04:52,530 ] - Epoch 33: val_loss improved from -22.1069 to -22.7352\n",
      "[ INFO : 2022-03-15 19:04:52,797 ] - Epoch 34: val_loss improved from -22.7352 to -23.6154\n",
      "[ INFO : 2022-03-15 19:04:53,061 ] - Epoch 35: val_loss improved from -23.6154 to -24.4145\n",
      "[ INFO : 2022-03-15 19:04:53,345 ] - Epoch 36: val_loss improved from -24.4145 to -25.2076\n",
      "[ INFO : 2022-03-15 19:04:53,627 ] - Epoch 37: val_loss improved from -25.2076 to -26.4172\n",
      "[ INFO : 2022-03-15 19:04:53,891 ] - Epoch 38: val_loss improved from -26.4172 to -27.1085\n",
      "[ INFO : 2022-03-15 19:04:54,323 ] - Epoch 39: val_loss improved from -27.1085 to -28.5063\n",
      "[ INFO : 2022-03-15 19:04:54,744 ] - Epoch 40: val_loss improved from -28.5063 to -29.5309\n",
      "[ INFO : 2022-03-15 19:04:55,020 ] - Epoch 41: val_loss improved from -29.5309 to -30.9450\n",
      "[ INFO : 2022-03-15 19:04:55,292 ] - Epoch 42: val_loss improved from -30.9450 to -32.0140\n",
      "[ INFO : 2022-03-15 19:04:55,584 ] - Epoch 43: val_loss improved from -32.0140 to -33.8315\n",
      "[ INFO : 2022-03-15 19:04:55,883 ] - Epoch 44: val_loss improved from -33.8315 to -34.9068\n",
      "[ INFO : 2022-03-15 19:04:56,146 ] - Epoch 45: val_loss improved from -34.9068 to -36.7809\n",
      "[ INFO : 2022-03-15 19:04:56,422 ] - Epoch 46: val_loss improved from -36.7809 to -37.9713\n",
      "[ INFO : 2022-03-15 19:04:56,688 ] - Epoch 47: val_loss improved from -37.9713 to -39.8112\n",
      "[ INFO : 2022-03-15 19:04:56,954 ] - Epoch 48: val_loss improved from -39.8112 to -40.8520\n",
      "[ INFO : 2022-03-15 19:04:57,235 ] - Epoch 49: val_loss improved from -40.8520 to -42.6101\n",
      "[ INFO : 2022-03-15 19:04:57,508 ] - Epoch 50: val_loss improved from -42.6101 to -43.6551\n",
      "[ INFO : 2022-03-15 19:04:57,782 ] - Epoch 51: val_loss improved from -43.6551 to -45.0654\n",
      "[ INFO : 2022-03-15 19:04:57,783 ] - Epoch 51/150 - time: 0.27 - training_loss: -67.0566 - val_loss: -45.0654\n",
      "[ INFO : 2022-03-15 19:04:58,051 ] - Epoch 52: val_loss improved from -45.0654 to -46.0002\n",
      "[ INFO : 2022-03-15 19:04:58,331 ] - Epoch 53: val_loss improved from -46.0002 to -47.3047\n",
      "[ INFO : 2022-03-15 19:04:58,593 ] - Epoch 54: val_loss improved from -47.3047 to -47.9621\n",
      "[ INFO : 2022-03-15 19:04:58,864 ] - Epoch 55: val_loss improved from -47.9621 to -49.0360\n",
      "[ INFO : 2022-03-15 19:04:59,134 ] - Epoch 56: val_loss improved from -49.0360 to -49.7239\n",
      "[ INFO : 2022-03-15 19:04:59,439 ] - Epoch 57: val_loss improved from -49.7239 to -50.6484\n",
      "[ INFO : 2022-03-15 19:04:59,738 ] - Epoch 58: val_loss improved from -50.6484 to -51.0637\n",
      "[ INFO : 2022-03-15 19:05:00,076 ] - Epoch 59: val_loss improved from -51.0637 to -51.7859\n",
      "[ INFO : 2022-03-15 19:05:00,407 ] - Epoch 60: val_loss improved from -51.7859 to -52.0429\n",
      "[ INFO : 2022-03-15 19:05:00,725 ] - Epoch 61: val_loss improved from -52.0429 to -52.9428\n",
      "[ INFO : 2022-03-15 19:05:01,062 ] - Epoch 62: val_loss improved from -52.9428 to -53.0153\n",
      "[ INFO : 2022-03-15 19:05:01,345 ] - Epoch 63: val_loss improved from -53.0153 to -53.6768\n",
      "[ INFO : 2022-03-15 19:05:01,685 ] - Epoch 64: val_loss improved from -53.6768 to -53.7367\n",
      "[ INFO : 2022-03-15 19:05:02,024 ] - Epoch 65: val_loss improved from -53.7367 to -54.4163\n",
      "[ INFO : 2022-03-15 19:05:02,340 ] - Epoch 66: val_loss improved from -54.4163 to -54.4649\n",
      "[ INFO : 2022-03-15 19:05:02,645 ] - Epoch 67: val_loss improved from -54.4649 to -55.0286\n",
      "[ INFO : 2022-03-15 19:05:03,409 ] - Epoch 69: val_loss improved from -55.0286 to -55.5611\n",
      "[ INFO : 2022-03-15 19:05:04,016 ] - Epoch 71: val_loss improved from -55.5611 to -56.1954\n",
      "[ INFO : 2022-03-15 19:05:04,551 ] - Epoch 73: val_loss improved from -56.1954 to -56.2307\n",
      "[ INFO : 2022-03-15 19:05:05,130 ] - Epoch 75: val_loss improved from -56.2307 to -56.4451\n",
      "[ INFO : 2022-03-15 19:05:05,794 ] - Epoch 77: val_loss improved from -56.4451 to -56.6534\n",
      "[ INFO : 2022-03-15 19:05:06,404 ] - Epoch 79: val_loss improved from -56.6534 to -56.9462\n",
      "[ INFO : 2022-03-15 19:05:08,246 ] - Epoch 83: val_loss improved from -56.9462 to -57.1257\n",
      "[ INFO : 2022-03-15 19:05:08,847 ] - Epoch 85: val_loss improved from -57.1257 to -57.3029\n",
      "[ INFO : 2022-03-15 19:05:09,402 ] - Epoch 87: val_loss improved from -57.3029 to -57.4385\n",
      "[ INFO : 2022-03-15 19:05:10,106 ] - Epoch 89: val_loss improved from -57.4385 to -57.5607\n",
      "[ INFO : 2022-03-15 19:05:10,773 ] - Epoch 91: val_loss improved from -57.5607 to -57.7445\n",
      "[ INFO : 2022-03-15 19:05:11,652 ] - Epoch 93: val_loss improved from -57.7445 to -57.8337\n",
      "[ INFO : 2022-03-15 19:05:13,216 ] - Epoch 97: val_loss improved from -57.8337 to -57.8932\n",
      "[ INFO : 2022-03-15 19:05:14,366 ] - Epoch 101: val_loss did not improve from -57.8932\n",
      "[ INFO : 2022-03-15 19:05:14,367 ] - Epoch 101/150 - time: 0.27 - training_loss: -75.9308 - val_loss: -57.8005\n",
      "[ INFO : 2022-03-15 19:05:17,720 ] - Epoch 112: val_loss improved from -57.8932 to -57.9334\n",
      "[ INFO : 2022-03-15 19:05:18,287 ] - Epoch 114: val_loss improved from -57.9334 to -58.0063\n",
      "[ INFO : 2022-03-15 19:05:18,607 ] - Epoch 115: val_loss improved from -58.0063 to -58.0324\n",
      "[ INFO : 2022-03-15 19:05:19,833 ] - Epoch 119: val_loss improved from -58.0324 to -58.0821\n",
      "[ INFO : 2022-03-15 19:05:20,478 ] - Epoch 121: val_loss improved from -58.0821 to -58.1637\n",
      "[ INFO : 2022-03-15 19:05:21,054 ] - Epoch 123: val_loss improved from -58.1637 to -58.2851\n",
      "[ INFO : 2022-03-15 19:05:21,691 ] - Epoch 125: val_loss improved from -58.2851 to -58.3754\n",
      "[ INFO : 2022-03-15 19:05:22,709 ] - Epoch 129: val_loss improved from -58.3754 to -58.3759\n",
      "[ INFO : 2022-03-15 19:05:23,250 ] - Epoch 131: val_loss improved from -58.3759 to -58.4082\n",
      "[ INFO : 2022-03-15 19:05:23,838 ] - Epoch 133: val_loss improved from -58.4082 to -58.4669\n",
      "[ INFO : 2022-03-15 19:05:27,647 ] - Epoch 146: val_loss improved from -58.4669 to -58.4748\n",
      "[ INFO : 2022-03-15 19:05:28,533 ] - Epoch 149: val_loss improved from -58.4748 to -58.5250\n",
      "[ INFO : 2022-03-15 19:05:29,085 ] - loss on validation data: -58.4660\n",
      "[ INFO : 2022-03-15 19:05:29,228 ] - loss on test data: -68.8026\n"
     ]
    }
   ],
   "source": [
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "l_cca = None\n",
    "if apply_linear_cca:\n",
    "    l_cca = linear_cca()\n",
    "    \n",
    "    \n",
    "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
    "                learning_rate, reg_par, device=device, epoch_log_freq=epoch_log_freq, log=True)\n",
    "s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "# Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "loss = solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "training_losses, val_losses = solver.get_losses()\n",
    "# TODO: Save linear_cca model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8593e45-1b71-4e90-a67d-cf099f115d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-88.73  -47.925]\n"
     ]
    }
   ],
   "source": [
    "set_size = [0, \n",
    "            train1.size(0), \n",
    "            train1.size(0) + val1.size(0), \n",
    "            train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "\n",
    "losses, outputs = solver._get_outputs(data1, data2)\n",
    "losses = np.round(losses,3)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "828b37b3-fd54-4de7-a0ab-14dc85ed2b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1294, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "(1294, 100)\n"
     ]
    }
   ],
   "source": [
    "print(type(outputs[0]))\n",
    "print(outputs[0].shape)\n",
    "print(type(outputs[1]))\n",
    "print(outputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddd3d2-cf20-4cf4-8e3a-302bf2e220fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plotting the Losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9b27eff-6323-4a7b-8248-875cd22b1d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(training_losses))\n",
    "plt.figure(figsize=(10, 8), dpi=90)\n",
    "plt.plot(x, training_losses, color='blue', label=\"Training Loss\")\n",
    "plt.plot(x, val_losses, color='orange', label=\"Validation Loss\")\n",
    "plt.title(\"Losses for the training of the model\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (lower is better)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68899f-be7a-464d-b59c-83ae0a6a1f81",
   "metadata": {},
   "source": [
    "## Producing the best new features by DCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6921c6-c8f3-4293-9a19-c354d8166963",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using GridSearch Cross with Validation to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6916c55-f0c4-472e-bc9f-bddd24028ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 30) <class 'numpy.ndarray'> float64\n",
      "(1294, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1294, 30]) <class 'torch.Tensor'>\n",
      "torch.Size([1294, 54]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# View 1:\n",
    "normalized_opnmf_coeffs=(opnmf_coeffs.loc[:,\"component_1\":\"component_30\"]-\n",
    "                         opnmf_coeffs.loc[:,\"component_1\":\"component_30\"].min())/(opnmf_coeffs.loc[:,\"component_1\":\"component_30\"].max()-\n",
    "                                                                                  opnmf_coeffs.loc[:,\"component_1\":\"component_30\"].min())\n",
    "view_1 = normalized_opnmf_coeffs.loc[:,\"component_1\":\"component_30\"]\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]\n",
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy().astype(np.float64)\n",
    "# # Scramble the datapoints for randomness:\n",
    "# indices = np.arange(view_1_n.shape[0])\n",
    "# # np.random.shuffle(indices)\n",
    "# view_1_n = view_1_n[indices]\n",
    "# view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))\n",
    "\n",
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "# Standard parameters that shouldn't be changed:\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "input_shape1 = 30 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "epoch_log_freq = 50\n",
    "use_all_singular_values = False\n",
    "apply_linear_cca = True\n",
    "epoch_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02f8e7f-ef07-4788-844c-8b9e1fe2102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variation  1 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.4707037092424953\n",
      "Variation  2 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.537820699097604\n",
      "Variation  3 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.3931262673267604\n",
      "Variation  4 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.440311402328304\n",
      "Variation  5 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.324578657897362\n",
      "Variation  6 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.445807145039283\n",
      "Variation  7 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.1056298356246637\n",
      "Variation  8 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.4128028837232707\n",
      "Variation  9 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.2511606988926096\n",
      "Variation  10 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.342394382773765\n",
      "Variation  11 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.4861471592960713\n",
      "Variation  12 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.4046538421303856\n",
      "Variation  13 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.5583097091282365\n",
      "Variation  14 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.378218812174411\n",
      "Variation  15 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.3745953132418784\n",
      "Variation  16 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.282300570776222\n",
      "Variation  17 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.2877904331993157\n",
      "Variation  18 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.3952800260599787\n",
      "Variation  19 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.374837447821306\n",
      "Variation  20 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.3655771355123187\n",
      "Variation  21 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.395169619911123\n",
      "Variation  22 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.2727757963432373\n",
      "Variation  23 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.3110236452774213\n",
      "Variation  24 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.264177879972743\n",
      "Variation  25 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.2787099202502032\n",
      "Variation  26 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.4393973530693174\n",
      "Variation  27 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.4814470660749453\n",
      "Variation  28 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.5375154255679275\n",
      "Variation  29 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.402039288823819\n",
      "Variation  30 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.359440599716505\n",
      "Variation  31 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.3036014271364027\n",
      "Variation  32 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.6415088361355425\n",
      "Variation  33 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.3271516554476737\n",
      "Variation  34 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.202174636134067\n",
      "Variation  35 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.1994698658992795\n",
      "Variation  36 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.420643609658204\n",
      "Variation  37 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.6906250905842377\n",
      "Variation  38 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.5968490160815945\n",
      "Variation  39 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.7605982236222117\n",
      "Variation  40 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.3457959253624994\n",
      "Variation  41 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.4779350890600416\n",
      "Variation  42 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.515223313182984\n",
      "Variation  43 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.0255808945860396\n",
      "Variation  44 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.326860961150391\n",
      "Variation  45 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.340994870825159\n",
      "Variation  46 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.366486028289481\n",
      "Variation  47 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.1832375123989687\n",
      "Variation  48 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.3342871140871844\n",
      "Variation  49 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.4564577391694766\n",
      "Variation  50 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.4552919679893055\n",
      "Variation  51 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.215070294480656\n",
      "Variation  52 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.230906021345091\n",
      "Variation  53 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.3498852063633784\n",
      "Variation  54 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.1419025561585965\n",
      "Variation  55 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-1.9999593002946066\n",
      "Variation  56 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.2993442144663896\n",
      "Variation  57 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.508592081957346\n",
      "Variation  58 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.2326945834933802\n",
      "Variation  59 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.7543143020491887\n",
      "Variation  60 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.5414725339631827\n",
      "Variation  61 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.3718517400137187\n",
      "Variation  62 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.5252322934150166\n",
      "Variation  63 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.274821252932322\n",
      "Variation  64 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.417194275284168\n",
      "Variation  65 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.4204059075940956\n",
      "Variation  66 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.313657875986829\n",
      "Variation  67 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-2.412121196824231\n",
      "Variation  68 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-2.263526218287603\n",
      "Variation  69 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-2.2405780472995915\n",
      "Variation  70 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-2.2909535152246936\n",
      "Variation  71 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-2.5235517090193724\n",
      "Variation  72 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-2.595187212751525\n",
      "Variation  73 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-27.088907892775495\n",
      "Variation  74 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-27.244013738880195\n",
      "Variation  75 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-27.47488611297188\n",
      "Variation  76 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-27.495226126045246\n",
      "Variation  77 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-27.367953512085705\n",
      "Variation  78 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-27.857964103466802\n",
      "Variation  79 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-27.024333215825628\n",
      "Variation  80 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-27.600951808892148\n",
      "Variation  81 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-27.500027702948564\n",
      "Variation  82 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-27.25732819886651\n",
      "Variation  83 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-26.703556376311177\n",
      "Variation  84 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-26.8371145761908\n",
      "Variation  85 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-24.560124233940325\n",
      "Variation  86 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-24.713107474091274\n",
      "Variation  87 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-24.866232108487193\n",
      "Variation  88 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-23.87067971243831\n",
      "Variation  89 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-23.488221575382646\n",
      "Variation  90 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-24.213014004601636\n",
      "Variation  91 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-24.48409811091353\n",
      "Variation  92 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-27.491693253469073\n",
      "Variation  93 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-27.518683053305296\n",
      "Variation  94 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-23.79205116524915\n",
      "Variation  95 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-27.842772473509033\n",
      "Variation  96 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-27.752798942981492\n",
      "Variation  97 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-27.340303576798384\n",
      "Variation  98 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-27.684690363063318\n",
      "Variation  99 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-28.046365259770194\n",
      "Variation  100 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-27.586673193756408\n",
      "Variation  101 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-27.44003057861292\n",
      "Variation  102 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-27.464588135632756\n",
      "Variation  103 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-26.404906329009506\n",
      "Variation  104 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-25.570198454278383\n",
      "Variation  105 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-26.07513209377884\n",
      "Variation  106 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-26.205244539356528\n",
      "Variation  107 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-26.105857038794067\n",
      "Variation  108 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-26.36543937375157\n",
      "Variation  109 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-11.14929340973622\n",
      "Variation  110 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-10.889689934495761\n",
      "Variation  111 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-10.735093153643978\n",
      "Variation  112 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-20.53438565036347\n",
      "Variation  113 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-26.510610819093714\n",
      "Variation  114 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-27.578121459931364\n",
      "Variation  115 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-27.038627647414785\n",
      "Variation  116 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-26.6236836221814\n",
      "Variation  117 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-27.5966904290069\n",
      "Variation  118 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-26.92648022233255\n",
      "Variation  119 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-27.167439818041952\n",
      "Variation  120 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-27.603960964790776\n",
      "Variation  121 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-25.21834957458674\n",
      "Variation  122 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-25.34551922406771\n",
      "Variation  123 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-24.617764529522866\n",
      "Variation  124 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-24.871506052020756\n",
      "Variation  125 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-25.228725593096677\n",
      "Variation  126 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-24.541531484590386\n",
      "Variation  127 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-27.324729046779822\n",
      "Variation  128 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-26.779877739336015\n",
      "Variation  129 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-12.59929796011784\n",
      "Variation  130 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-22.991335171545977\n",
      "Variation  131 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-14.883428205672429\n",
      "Variation  132 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-11.5420432510406\n",
      "Variation  133 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-27.37481065088953\n",
      "Variation  134 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-27.186819460285626\n",
      "Variation  135 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-27.09952317313441\n",
      "Variation  136 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-27.274895478376788\n",
      "Variation  137 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-27.615578104826692\n",
      "Variation  138 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-27.82781551712229\n",
      "Variation  139 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-26.330349402964373\n",
      "Variation  140 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-26.27203882942848\n",
      "Variation  141 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-26.41383084065961\n",
      "Variation  142 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-26.210683778325286\n",
      "Variation  143 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-25.923388699819455\n",
      "Variation  144 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-26.289206908322484\n",
      "Variation  145 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-26.277476313496365\n",
      "Variation  146 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-26.102192898643423\n",
      "Variation  147 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-26.317401362831895\n",
      "Variation  148 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-79.65538449167659\n",
      "Variation  149 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-80.19079730916826\n",
      "Variation  150 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-81.97019601210648\n",
      "Variation  151 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-78.10345429847273\n",
      "Variation  152 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-79.05781100414929\n",
      "Variation  153 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-79.06473021048367\n",
      "Variation  154 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-77.39143570202609\n",
      "Variation  155 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-77.88774751548392\n",
      "Variation  156 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-78.5836706583473\n",
      "Variation  157 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-67.029443209307\n",
      "Variation  158 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-66.66404524549564\n",
      "Variation  159 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-67.70621456421668\n",
      "Variation  160 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-64.67112739890669\n",
      "Variation  161 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-64.56800200380701\n",
      "Variation  162 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-65.97063799282384\n",
      "Variation  163 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-65.74888446523448\n",
      "Variation  164 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-41.55236200556925\n",
      "Variation  165 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-49.468467505499156\n",
      "Variation  166 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-40.0431311548074\n",
      "Variation  167 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-81.64682315082968\n",
      "Variation  168 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-81.53746620591994\n",
      "Variation  169 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-80.19249949363886\n",
      "Variation  170 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-81.9024449715691\n",
      "Variation  171 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-81.59893056245846\n",
      "Variation  172 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-80.35352994068418\n",
      "Variation  173 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-81.7873615742404\n",
      "Variation  174 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-81.18778980092189\n",
      "Variation  175 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-76.01566272253889\n",
      "Variation  176 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-76.01343401217595\n",
      "Variation  177 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-76.71777583949996\n",
      "Variation  178 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-73.0364959595963\n",
      "Variation  179 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-74.32892363519005\n",
      "Variation  180 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-73.3133783520161\n",
      "Variation  181 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-21.189714366085187\n",
      "Variation  182 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-23.63103556698351\n",
      "Variation  183 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-16.88322202752978\n",
      "Variation  184 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-20.412401591891626\n",
      "Variation  185 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-11.222490550759119\n",
      "Variation  186 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-12.68706514499097\n",
      "Variation  187 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-79.3689481258824\n",
      "Variation  188 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-79.85219691447692\n",
      "Variation  189 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-80.18771763839153\n",
      "Variation  190 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-78.81584116263642\n",
      "Variation  191 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-78.89425099681215\n",
      "Variation  192 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-78.84100850833264\n",
      "Variation  193 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-70.94426495369842\n",
      "Variation  194 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-71.81174406124455\n",
      "Variation  195 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-71.43177549979703\n",
      "Variation  196 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-68.57618904567526\n",
      "Variation  197 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-68.29217118747471\n",
      "Variation  198 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-68.76734765167302\n",
      "Variation  199 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-76.06844140753631\n",
      "Variation  200 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-60.330195409950235\n",
      "Variation  201 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-21.404950268920068\n",
      "Variation  202 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-35.592875775180026\n",
      "Variation  203 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-18.49869104295689\n",
      "Variation  204 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-12.211738079173607\n",
      "Variation  205 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-80.91321333776364\n",
      "Variation  206 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-81.74570468771218\n",
      "Variation  207 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-82.28848232382305\n",
      "Variation  208 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-81.04347842649821\n",
      "Variation  209 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-81.97014197120333\n",
      "Variation  210 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-82.41242903862359\n",
      "Variation  211 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-79.6057095728545\n",
      "Variation  212 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-79.36203581908475\n",
      "Variation  213 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-79.51167233921957\n",
      "Variation  214 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-76.79583029859869\n",
      "Variation  215 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-77.35487415685854\n",
      "Variation  216 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-76.90355781763242\n",
      "Variation  217 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-40.067720593477425\n",
      "Variation  218 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-57.6928215773186\n",
      "Variation  219 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-48.04356280246894\n",
      "Variation  220 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-38.37414588738377\n",
      "Variation  221 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-112.52080471259927\n",
      "Variation  222 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-97.53399573260808\n",
      "Variation  223 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-120.6075141602231\n",
      "Variation  224 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-121.92675605198248\n",
      "Variation  225 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-121.76456807292112\n",
      "Variation  226 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-118.70119789595933\n",
      "Variation  227 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-119.72436395199738\n",
      "Variation  228 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-120.33864778895379\n",
      "Variation  229 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-104.7991472978214\n",
      "Variation  230 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-104.63706508382668\n",
      "Variation  231 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-104.36803483673279\n",
      "Variation  232 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-100.29623322045714\n",
      "Variation  233 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-100.05986697078976\n",
      "Variation  234 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-99.6673437059932\n",
      "Variation  235 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-65.33510193893909\n",
      "Variation  236 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-72.23590160350665\n",
      "Variation  237 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-61.27950247879613\n",
      "Variation  238 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-20.132656198303387\n",
      "Variation  239 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-73.3882545148127\n",
      "Variation  240 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-86.95262119840363\n",
      "Variation  241 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-123.71250817964354\n",
      "Variation  242 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-126.35914258712492\n",
      "Variation  243 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-126.05255879644179\n",
      "Variation  244 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-124.17946323721418\n",
      "Variation  245 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-126.07334879369374\n",
      "Variation  246 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-126.44447798199731\n",
      "Variation  247 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-118.32206281681249\n",
      "Variation  248 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-118.7124092116207\n",
      "Variation  249 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-118.33757259542324\n",
      "Variation  250 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-114.23280508806488\n",
      "Variation  251 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-114.7474526789041\n",
      "Variation  252 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-115.03998349504232\n",
      "Variation  253 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-35.67767164816049\n",
      "Variation  254 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-36.06274201437982\n",
      "Variation  255 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-39.35797814145684\n",
      "Variation  256 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-24.950453810365428\n",
      "Variation  257 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-16.589288244809254\n",
      "Variation  258 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-16.07661600723472\n",
      "Variation  259 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-121.69993264380851\n",
      "Variation  260 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-122.94389758499614\n",
      "Variation  261 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-123.24420994347484\n",
      "Variation  262 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-119.52324820813428\n",
      "Variation  263 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-120.85750759938031\n",
      "Variation  264 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-120.60073469915646\n",
      "Variation  265 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-110.40929978993648\n",
      "Variation  266 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-110.36506169058532\n",
      "Variation  267 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-108.90512414057778\n",
      "Variation  268 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-105.1083741611093\n",
      "Variation  269 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-104.36704232430317\n",
      "Variation  270 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-105.21764304283758\n",
      "Variation  271 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-88.55497492865204\n",
      "Variation  272 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-61.63277130897304\n",
      "Variation  273 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-72.1886653101432\n",
      "Variation  274 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-30.631487587733247\n",
      "Variation  275 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-22.00206657707628\n",
      "Variation  276 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-21.07975579603271\n",
      "Variation  277 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-125.25557675052286\n",
      "Variation  278 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-126.96900246796116\n",
      "Variation  279 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-126.88191965452589\n",
      "Variation  280 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-125.6063335936528\n",
      "Variation  281 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-127.29038593209472\n",
      "Variation  282 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-127.45859941709844\n",
      "Variation  283 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "-122.84841042398362\n",
      "Variation  284 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "-123.18461737937\n",
      "Variation  285 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "-122.87312453192717\n",
      "Variation  286 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "-119.44558433095597\n",
      "Variation  287 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "-120.08255987496517\n",
      "Variation  288 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "-119.9133622946022\n",
      "With a loss of -127.45859941709844, the configuration with the best Test loss was:\n",
      "{'batch_sz': 1000,\n",
      " 'hidden_layer_size1': [1024, 1024, 1024, 1024],\n",
      " 'hidden_layer_size2': [1024, 1024, 1024, 1024],\n",
      " 'learning_rate': 0.001,\n",
      " 'outdim': 150,\n",
      " 'reg_par': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Parameters that should be explored, example values:\n",
    "outdim_sizes = [10,50,100,150]\n",
    "hidden_layer_sizes = [[256,256,256],\n",
    "                      [1024,1024,1024],\n",
    "                      [256,256,256,256],\n",
    "                      [1024,1024,1024,1024]]\n",
    "learning_rates = [1e-2,1e-3,1e-4]\n",
    "batch_sizes = [500,1000]\n",
    "reg_pars = [1e-2,1e-3,1e-4]\n",
    "\n",
    "results = []\n",
    "best_test_loss = (1000,None)\n",
    "count=0\n",
    "\n",
    "for outdim_size in outdim_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        hidden_layer_size1 = hidden_layer_size\n",
    "        hidden_layer_size2 = hidden_layer_size\n",
    "        for learning_rate in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                for reg_par in reg_pars:\n",
    "                    count += 1\n",
    "                    parameters = {\"outdim\": outdim_size,\n",
    "                                  \"hidden_layer_size1\": hidden_layer_size1,\n",
    "                                  \"hidden_layer_size2\": hidden_layer_size2,\n",
    "                                  \"learning_rate\": learning_rate,\n",
    "                                  \"batch_sz\": batch_size,\n",
    "                                  \"reg_par\": reg_par}\n",
    "                    print(\"Variation \", count, \":\", parameters)\n",
    "                    layer_sizes1 = hidden_layer_size1 + [outdim_size]\n",
    "                    layer_sizes2 = hidden_layer_size2 + [outdim_size]\n",
    "\n",
    "                    model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1, input_shape2, outdim_size, \n",
    "                                    use_all_singular_values, device=device).double()\n",
    "\n",
    "                    solver = Solver(model, linear_cca(), outdim_size, epoch_num, batch_size,\n",
    "                                    learning_rate, reg_par, device=device, epoch_log_freq=epoch_log_freq, log=False)\n",
    "                    s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "                    # Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "                    train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "                    val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "                    test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "                    test_loss = solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "                    print(test_loss)\n",
    "                    if test_loss < best_test_loss[0]:\n",
    "                        best_test_loss = (test_loss, parameters)\n",
    "                    training_losses, val_losses = solver.get_losses()\n",
    "                    results.append((training_losses, val_losses, test_loss, parameters))\n",
    "\n",
    "print(\"With a loss of \" + str(best_test_loss[0]) + \", the configuration with the best Test loss was:\")\n",
    "pprint.pprint(best_test_loss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8cde66-4594-4e3a-adbf-bb7eaee970df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"OPNMFGridSearch_Results.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c038d80a-0349-4397-8ba7-a27892c47c7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using the model with the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc4b39-46ec-4609-b718-76cde6c3cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"OPNMFGridSearch_Results.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    results = pickle.load(fp)\n",
    "\n",
    "print(\"The nunmber of different results are: \", len(results))\n",
    "print()\n",
    "# each result is in the format ([training_losses], [validation_losses], test_loss, parameters):\n",
    "from operator import itemgetter\n",
    "\n",
    "best_test_loss = min(results, key=itemgetter(2))\n",
    "print(\"The best test loss that was managed is: \", best_test_loss[2])\n",
    "print(\"The test loss was managed with the following parameters:\")\n",
    "pprint.pprint(best_test_loss[3])\n",
    "print()\n",
    "\n",
    "x = np.arange(len(best_test_loss[0])) # number of epochs in training, also in validation\n",
    "plt.figure(figsize=(10, 8), dpi=90)\n",
    "training_losses = best_test_loss[0]\n",
    "val_losses = best_test_loss[1]\n",
    "plt.plot(x, training_losses, color='blue', label=\"Training Loss\")\n",
    "plt.plot(x, val_losses, color='orange', label=\"Validation Loss\")\n",
    "plt.plot(x, [best_test_loss[2]]*len(best_test_loss[0]), marker='.', color='red', label=\"Test Loss Achieved\")\n",
    "plt.title(\"Losses for the training of the model\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (lower is better)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47d2271-9ffa-4e6a-9d2e-9701b58d688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2022-03-15 23:02:00,223 ] - DataParallel(\n",
      "  (module): DeepCCA(\n",
      "    (model1): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=30, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=150, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model2): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=54, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=150, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[ INFO : 2022-03-15 23:02:00,224 ] - RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "[ INFO : 2022-03-15 23:02:01,062 ] - Epoch 1: val_loss improved from 0.0000 to -4.7523\n",
      "[ INFO : 2022-03-15 23:02:01,063 ] - Epoch 1/300 - time: 0.83 - training_loss: -38.6507 - val_loss: -4.7523\n",
      "[ INFO : 2022-03-15 23:02:01,788 ] - Epoch 2: val_loss improved from -4.7523 to -4.9166\n",
      "[ INFO : 2022-03-15 23:02:02,557 ] - Epoch 3: val_loss improved from -4.9166 to -5.2009\n",
      "[ INFO : 2022-03-15 23:02:03,281 ] - Epoch 4: val_loss improved from -5.2009 to -5.5676\n",
      "[ INFO : 2022-03-15 23:02:03,945 ] - Epoch 5: val_loss improved from -5.5676 to -6.0184\n",
      "[ INFO : 2022-03-15 23:02:05,577 ] - Epoch 6: val_loss improved from -6.0184 to -6.5431\n",
      "[ INFO : 2022-03-15 23:02:06,630 ] - Epoch 7: val_loss improved from -6.5431 to -7.0735\n",
      "[ INFO : 2022-03-15 23:02:07,347 ] - Epoch 8: val_loss improved from -7.0735 to -7.7004\n",
      "[ INFO : 2022-03-15 23:02:07,992 ] - Epoch 9: val_loss improved from -7.7004 to -8.3793\n",
      "[ INFO : 2022-03-15 23:02:08,736 ] - Epoch 10: val_loss improved from -8.3793 to -9.0390\n",
      "[ INFO : 2022-03-15 23:02:09,429 ] - Epoch 11: val_loss improved from -9.0390 to -9.6839\n",
      "[ INFO : 2022-03-15 23:02:10,092 ] - Epoch 12: val_loss improved from -9.6839 to -10.3706\n",
      "[ INFO : 2022-03-15 23:02:10,897 ] - Epoch 13: val_loss improved from -10.3706 to -11.0950\n",
      "[ INFO : 2022-03-15 23:02:12,776 ] - Epoch 14: val_loss improved from -11.0950 to -11.8716\n",
      "[ INFO : 2022-03-15 23:02:13,388 ] - Epoch 15: val_loss improved from -11.8716 to -12.6774\n",
      "[ INFO : 2022-03-15 23:02:13,987 ] - Epoch 16: val_loss improved from -12.6774 to -13.5499\n",
      "[ INFO : 2022-03-15 23:02:14,831 ] - Epoch 17: val_loss improved from -13.5499 to -14.4671\n",
      "[ INFO : 2022-03-15 23:02:15,445 ] - Epoch 18: val_loss improved from -14.4671 to -15.5515\n",
      "[ INFO : 2022-03-15 23:02:16,030 ] - Epoch 19: val_loss improved from -15.5515 to -16.6824\n",
      "[ INFO : 2022-03-15 23:02:16,633 ] - Epoch 20: val_loss improved from -16.6824 to -18.1730\n",
      "[ INFO : 2022-03-15 23:02:17,249 ] - Epoch 21: val_loss improved from -18.1730 to -19.5949\n",
      "[ INFO : 2022-03-15 23:02:18,134 ] - Epoch 22: val_loss improved from -19.5949 to -21.6716\n",
      "[ INFO : 2022-03-15 23:02:18,740 ] - Epoch 23: val_loss improved from -21.6716 to -23.3903\n",
      "[ INFO : 2022-03-15 23:02:19,352 ] - Epoch 24: val_loss improved from -23.3903 to -25.9094\n",
      "[ INFO : 2022-03-15 23:02:19,964 ] - Epoch 25: val_loss improved from -25.9094 to -28.1009\n",
      "[ INFO : 2022-03-15 23:02:20,871 ] - Epoch 26: val_loss improved from -28.1009 to -30.7240\n",
      "[ INFO : 2022-03-15 23:02:21,471 ] - Epoch 27: val_loss improved from -30.7240 to -33.6313\n",
      "[ INFO : 2022-03-15 23:02:22,119 ] - Epoch 28: val_loss improved from -33.6313 to -36.1240\n",
      "[ INFO : 2022-03-15 23:02:23,147 ] - Epoch 29: val_loss improved from -36.1240 to -39.7133\n",
      "[ INFO : 2022-03-15 23:02:23,961 ] - Epoch 30: val_loss improved from -39.7133 to -42.2715\n",
      "[ INFO : 2022-03-15 23:02:24,803 ] - Epoch 31: val_loss improved from -42.2715 to -46.4150\n",
      "[ INFO : 2022-03-15 23:02:25,577 ] - Epoch 32: val_loss improved from -46.4150 to -49.1648\n",
      "[ INFO : 2022-03-15 23:02:26,328 ] - Epoch 33: val_loss improved from -49.1648 to -53.5692\n",
      "[ INFO : 2022-03-15 23:02:27,054 ] - Epoch 34: val_loss improved from -53.5692 to -56.6583\n",
      "[ INFO : 2022-03-15 23:02:27,783 ] - Epoch 35: val_loss improved from -56.6583 to -60.9755\n",
      "[ INFO : 2022-03-15 23:02:28,457 ] - Epoch 36: val_loss improved from -60.9755 to -64.4193\n",
      "[ INFO : 2022-03-15 23:02:29,113 ] - Epoch 37: val_loss improved from -64.4193 to -68.5924\n",
      "[ INFO : 2022-03-15 23:02:29,804 ] - Epoch 38: val_loss improved from -68.5924 to -72.1153\n",
      "[ INFO : 2022-03-15 23:02:30,454 ] - Epoch 39: val_loss improved from -72.1153 to -76.0928\n",
      "[ INFO : 2022-03-15 23:02:31,142 ] - Epoch 40: val_loss improved from -76.0928 to -79.3785\n",
      "[ INFO : 2022-03-15 23:02:31,762 ] - Epoch 41: val_loss improved from -79.3785 to -83.1153\n",
      "[ INFO : 2022-03-15 23:02:32,388 ] - Epoch 42: val_loss improved from -83.1153 to -86.1431\n",
      "[ INFO : 2022-03-15 23:02:33,018 ] - Epoch 43: val_loss improved from -86.1431 to -89.6843\n",
      "[ INFO : 2022-03-15 23:02:33,643 ] - Epoch 44: val_loss improved from -89.6843 to -92.4487\n",
      "[ INFO : 2022-03-15 23:02:34,272 ] - Epoch 45: val_loss improved from -92.4487 to -95.7519\n",
      "[ INFO : 2022-03-15 23:02:34,906 ] - Epoch 46: val_loss improved from -95.7519 to -98.0576\n",
      "[ INFO : 2022-03-15 23:02:35,555 ] - Epoch 47: val_loss improved from -98.0576 to -100.9751\n",
      "[ INFO : 2022-03-15 23:02:36,200 ] - Epoch 48: val_loss improved from -100.9751 to -102.7466\n",
      "[ INFO : 2022-03-15 23:02:36,856 ] - Epoch 49: val_loss improved from -102.7466 to -105.2540\n",
      "[ INFO : 2022-03-15 23:02:37,505 ] - Epoch 50: val_loss improved from -105.2540 to -106.6523\n",
      "[ INFO : 2022-03-15 23:02:38,142 ] - Epoch 51: val_loss improved from -106.6523 to -108.8686\n",
      "[ INFO : 2022-03-15 23:02:38,142 ] - Epoch 51/300 - time: 0.64 - training_loss: -130.8018 - val_loss: -108.8686\n",
      "[ INFO : 2022-03-15 23:02:38,893 ] - Epoch 52: val_loss improved from -108.8686 to -109.9351\n",
      "[ INFO : 2022-03-15 23:02:39,548 ] - Epoch 53: val_loss improved from -109.9351 to -111.9675\n",
      "[ INFO : 2022-03-15 23:02:40,164 ] - Epoch 54: val_loss improved from -111.9675 to -112.6008\n",
      "[ INFO : 2022-03-15 23:02:40,790 ] - Epoch 55: val_loss improved from -112.6008 to -114.4240\n",
      "[ INFO : 2022-03-15 23:02:41,470 ] - Epoch 56: val_loss improved from -114.4240 to -114.7889\n",
      "[ INFO : 2022-03-15 23:02:42,184 ] - Epoch 57: val_loss improved from -114.7889 to -116.3404\n",
      "[ INFO : 2022-03-15 23:02:42,808 ] - Epoch 58: val_loss improved from -116.3404 to -116.4347\n",
      "[ INFO : 2022-03-15 23:02:43,451 ] - Epoch 59: val_loss improved from -116.4347 to -117.7507\n",
      "[ INFO : 2022-03-15 23:02:44,673 ] - Epoch 61: val_loss improved from -117.7507 to -118.7472\n",
      "[ INFO : 2022-03-15 23:02:45,918 ] - Epoch 63: val_loss improved from -118.7472 to -119.5253\n",
      "[ INFO : 2022-03-15 23:02:47,158 ] - Epoch 65: val_loss improved from -119.5253 to -120.1088\n",
      "[ INFO : 2022-03-15 23:02:48,443 ] - Epoch 67: val_loss improved from -120.1088 to -120.5702\n",
      "[ INFO : 2022-03-15 23:02:49,677 ] - Epoch 69: val_loss improved from -120.5702 to -120.9540\n",
      "[ INFO : 2022-03-15 23:02:50,910 ] - Epoch 71: val_loss improved from -120.9540 to -121.2290\n",
      "[ INFO : 2022-03-15 23:02:52,185 ] - Epoch 73: val_loss improved from -121.2290 to -121.4284\n",
      "[ INFO : 2022-03-15 23:02:53,453 ] - Epoch 75: val_loss improved from -121.4284 to -121.5941\n",
      "[ INFO : 2022-03-15 23:02:54,073 ] - Epoch 76: val_loss improved from -121.5941 to -121.6183\n",
      "[ INFO : 2022-03-15 23:02:54,746 ] - Epoch 77: val_loss improved from -121.6183 to -121.7386\n",
      "[ INFO : 2022-03-15 23:02:55,396 ] - Epoch 78: val_loss improved from -121.7386 to -121.7705\n",
      "[ INFO : 2022-03-15 23:02:56,033 ] - Epoch 79: val_loss improved from -121.7705 to -121.8981\n",
      "[ INFO : 2022-03-15 23:02:57,295 ] - Epoch 81: val_loss improved from -121.8981 to -122.0518\n",
      "[ INFO : 2022-03-15 23:02:58,552 ] - Epoch 83: val_loss improved from -122.0518 to -122.1910\n",
      "[ INFO : 2022-03-15 23:02:59,810 ] - Epoch 85: val_loss improved from -122.1910 to -122.2976\n",
      "[ INFO : 2022-03-15 23:03:01,106 ] - Epoch 87: val_loss improved from -122.2976 to -122.4242\n",
      "[ INFO : 2022-03-15 23:03:02,373 ] - Epoch 89: val_loss improved from -122.4242 to -122.5174\n",
      "[ INFO : 2022-03-15 23:03:03,619 ] - Epoch 91: val_loss improved from -122.5174 to -122.5728\n",
      "[ INFO : 2022-03-15 23:03:04,899 ] - Epoch 93: val_loss improved from -122.5728 to -122.5930\n",
      "[ INFO : 2022-03-15 23:03:06,356 ] - Epoch 95: val_loss improved from -122.5930 to -122.6010\n",
      "[ INFO : 2022-03-15 23:03:08,650 ] - Epoch 98: val_loss improved from -122.6010 to -122.6215\n",
      "[ INFO : 2022-03-15 23:03:10,147 ] - Epoch 100: val_loss improved from -122.6215 to -122.6975\n",
      "[ INFO : 2022-03-15 23:03:10,807 ] - Epoch 101: val_loss did not improve from -122.6975\n",
      "[ INFO : 2022-03-15 23:03:10,807 ] - Epoch 101/300 - time: 0.66 - training_loss: -139.6590 - val_loss: -122.5904\n",
      "[ INFO : 2022-03-15 23:03:11,568 ] - Epoch 102: val_loss improved from -122.6975 to -122.7788\n",
      "[ INFO : 2022-03-15 23:03:12,842 ] - Epoch 104: val_loss improved from -122.7788 to -122.8433\n",
      "[ INFO : 2022-03-15 23:03:14,133 ] - Epoch 106: val_loss improved from -122.8433 to -122.9074\n",
      "[ INFO : 2022-03-15 23:03:15,389 ] - Epoch 108: val_loss improved from -122.9074 to -122.9856\n",
      "[ INFO : 2022-03-15 23:03:16,655 ] - Epoch 110: val_loss improved from -122.9856 to -123.0584\n",
      "[ INFO : 2022-03-15 23:03:17,915 ] - Epoch 112: val_loss improved from -123.0584 to -123.0796\n",
      "[ INFO : 2022-03-15 23:03:23,478 ] - Epoch 121: val_loss improved from -123.0796 to -123.1070\n",
      "[ INFO : 2022-03-15 23:03:24,744 ] - Epoch 123: val_loss improved from -123.1070 to -123.1387\n",
      "[ INFO : 2022-03-15 23:03:26,034 ] - Epoch 125: val_loss improved from -123.1387 to -123.1439\n",
      "[ INFO : 2022-03-15 23:03:27,551 ] - Epoch 127: val_loss improved from -123.1439 to -123.1478\n",
      "[ INFO : 2022-03-15 23:03:29,181 ] - Epoch 129: val_loss improved from -123.1478 to -123.1620\n",
      "[ INFO : 2022-03-15 23:03:30,710 ] - Epoch 131: val_loss improved from -123.1620 to -123.1686\n",
      "[ INFO : 2022-03-15 23:03:31,911 ] - Epoch 133: val_loss improved from -123.1686 to -123.1789\n",
      "[ INFO : 2022-03-15 23:03:33,064 ] - Epoch 135: val_loss improved from -123.1789 to -123.2012\n",
      "[ INFO : 2022-03-15 23:03:38,498 ] - Epoch 144: val_loss improved from -123.2012 to -123.2831\n",
      "[ INFO : 2022-03-15 23:03:39,664 ] - Epoch 146: val_loss improved from -123.2831 to -123.3842\n",
      "[ INFO : 2022-03-15 23:03:41,024 ] - Epoch 148: val_loss improved from -123.3842 to -123.4361\n",
      "[ INFO : 2022-03-15 23:03:42,691 ] - Epoch 150: val_loss improved from -123.4361 to -123.4876\n",
      "[ INFO : 2022-03-15 23:03:43,473 ] - Epoch 151: val_loss did not improve from -123.4876\n",
      "[ INFO : 2022-03-15 23:03:43,474 ] - Epoch 151/300 - time: 0.78 - training_loss: -142.7245 - val_loss: -123.1870\n",
      "[ INFO : 2022-03-15 23:03:44,270 ] - Epoch 152: val_loss improved from -123.4876 to -123.5205\n",
      "[ INFO : 2022-03-15 23:03:45,867 ] - Epoch 154: val_loss improved from -123.5205 to -123.5299\n",
      "[ INFO : 2022-03-15 23:03:57,527 ] - Epoch 171: val_loss improved from -123.5299 to -123.5452\n",
      "[ INFO : 2022-03-15 23:03:59,075 ] - Epoch 173: val_loss improved from -123.5452 to -123.5841\n",
      "[ INFO : 2022-03-15 23:04:06,294 ] - Epoch 184: val_loss improved from -123.5841 to -123.6137\n",
      "[ INFO : 2022-03-15 23:04:07,517 ] - Epoch 186: val_loss improved from -123.6137 to -123.6842\n",
      "[ INFO : 2022-03-15 23:04:08,907 ] - Epoch 188: val_loss improved from -123.6842 to -123.7217\n",
      "[ INFO : 2022-03-15 23:04:17,577 ] - Epoch 201: val_loss did not improve from -123.7217\n",
      "[ INFO : 2022-03-15 23:04:17,577 ] - Epoch 201/300 - time: 0.62 - training_loss: -144.2843 - val_loss: -123.5437\n",
      "[ INFO : 2022-03-15 23:04:37,463 ] - Epoch 233: val_loss improved from -123.7217 to -123.7795\n",
      "[ INFO : 2022-03-15 23:04:38,802 ] - Epoch 235: val_loss improved from -123.7795 to -123.8135\n",
      "[ INFO : 2022-03-15 23:04:40,077 ] - Epoch 237: val_loss improved from -123.8135 to -123.8245\n",
      "[ INFO : 2022-03-15 23:04:48,626 ] - Epoch 251: val_loss did not improve from -123.8245\n",
      "[ INFO : 2022-03-15 23:04:48,626 ] - Epoch 251/300 - time: 0.63 - training_loss: -145.2383 - val_loss: -123.7130\n",
      "[ INFO : 2022-03-15 23:05:03,480 ] - Epoch 275: val_loss improved from -123.8245 to -123.8577\n",
      "[ INFO : 2022-03-15 23:05:04,667 ] - Epoch 277: val_loss improved from -123.8577 to -123.8805\n",
      "[ INFO : 2022-03-15 23:05:06,285 ] - Epoch 279: val_loss improved from -123.8805 to -123.8842\n",
      "[ INFO : 2022-03-15 23:05:20,167 ] - loss on validation data: -123.8716\n",
      "[ INFO : 2022-03-15 23:05:20,262 ] - loss on test data: -128.6520\n"
     ]
    }
   ],
   "source": [
    "# Standard parameters that shouldn't be changed:\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "input_shape1 = 30 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "epoch_log_freq = 50\n",
    "use_all_singular_values = False\n",
    "apply_linear_cca = True\n",
    "epoch_num = 300\n",
    "\n",
    "parameters=best_test_loss[3]\n",
    "\n",
    "batch_size=parameters['batch_sz']\n",
    "hidden_layer_size1 = parameters['hidden_layer_size1']\n",
    "hidden_layer_size2 = parameters['hidden_layer_size2']\n",
    "learning_rate = parameters['learning_rate']\n",
    "outdim_size = parameters['outdim']\n",
    "reg_par = parameters['reg_par']\n",
    "layer_sizes1 = hidden_layer_size1 + [outdim_size]\n",
    "layer_sizes2 = hidden_layer_size2 + [outdim_size]\n",
    "\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1, input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "solver = Solver(model, linear_cca(), outdim_size, epoch_num, batch_size, learning_rate, reg_par, device=device, epoch_log_freq=epoch_log_freq, log=True)\n",
    "\n",
    "s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "# Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "loss = solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "training_losses, val_losses = solver.get_losses()\n",
    "\n",
    "# TODO: Save linear_cca model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a9652a-5e85-4194-852d-b80a4cb3b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-145.388  -96.4  ]\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "(1294, 150)\n",
      "<class 'numpy.ndarray'>\n",
      "(1294, 150)\n"
     ]
    }
   ],
   "source": [
    "set_size = [0, \n",
    "            train1.size(0), \n",
    "            train1.size(0) + val1.size(0), \n",
    "            train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "\n",
    "losses, outputs = solver._get_outputs(data1, data2)\n",
    "losses = np.round(losses,3)\n",
    "print(losses)\n",
    "\n",
    "print()\n",
    "\n",
    "print(type(outputs[0]))\n",
    "print(outputs[0].shape)\n",
    "print(type(outputs[1]))\n",
    "print(outputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27df39af-3b63-4d14-ad89-9652bf3eb7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(epoch_num)\n",
    "plt.figure(figsize=(10, 8), dpi=90)\n",
    "plt.plot(x, training_losses, color='blue', label=\"Training Loss\")\n",
    "plt.plot(x, val_losses, color='orange', label=\"Validation Loss\")\n",
    "plt.title(\"Losses for the training of the model\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (lower is better)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ebd5a-9747-46db-b766-25a0beade7b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing the Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d239b7a-1bd6-4a97-8a27-6ada827f7aa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing the Correlation between inputs and outputs of the deep Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f890537-e09b-47d3-8794-d9a9b68bcf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA on input data:\n",
      "-1.225506029776847\n",
      "CCA on output data:\n",
      "0.13911466589467103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "print(\"CCA on input data:\")\n",
    "X = data1\n",
    "Y = data2\n",
    "cca = CCA(n_components=30)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "print(cca.score(X, Y))\n",
    "\n",
    "print(\"CCA on output data:\")\n",
    "X = outputs[0]\n",
    "Y = outputs[1]\n",
    "cca = CCA(n_components=30,max_iter=10000)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "# The best possible score is 1.0 and it can be negative \n",
    "# (because the model can be arbitrarily worse)\n",
    "print(cca.score(X, Y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4836c2-46f2-412b-a59d-8235892cfed9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Imaging) Training and testing of SVM with linear kernel on the view 1 with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c506613e-370e-42e3-8025-0db6116a8a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.1}\n",
      "Untrained Accuracy:  54.63\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    49.924\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_1, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[0], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b09517-5cae-42a2-8ce3-976df20dc5cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Genetic) Training and testing of SVM with linear kernel on the view 2 with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9037268-61e0-4129-8972-b4ef7499fdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.0001}\n",
      "Untrained Accuracy:  48.068\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    49.685\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_2, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[1], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f709170-6606-4f28-8fe8-fa04189da9bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Imaging + Genetic) Training and testing of SVM with linear kernel on both views with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0a4b6b9-c843-4945-8fda-7e4f89f37a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 150)\n",
      "(1294, 150)\n",
      "(1294, 300)\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)\n",
    "both = np.concatenate((outputs[0], outputs[1]), axis=1)\n",
    "print(both.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6a4bea4-84b7-44d9-91e3-b5ea85eb8e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 54)\n",
      "(1294, 30)\n",
      "(1294, 84)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411253</td>\n",
       "      <td>0.291427</td>\n",
       "      <td>0.317243</td>\n",
       "      <td>0.446055</td>\n",
       "      <td>0.324598</td>\n",
       "      <td>0.183282</td>\n",
       "      <td>0.482389</td>\n",
       "      <td>0.589053</td>\n",
       "      <td>0.290537</td>\n",
       "      <td>0.221735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331504</td>\n",
       "      <td>0.555731</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.364694</td>\n",
       "      <td>0.390856</td>\n",
       "      <td>0.612504</td>\n",
       "      <td>0.428267</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>0.431235</td>\n",
       "      <td>0.605948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637170</td>\n",
       "      <td>0.536411</td>\n",
       "      <td>0.603719</td>\n",
       "      <td>0.502571</td>\n",
       "      <td>0.602314</td>\n",
       "      <td>0.572640</td>\n",
       "      <td>0.437036</td>\n",
       "      <td>0.648696</td>\n",
       "      <td>0.519391</td>\n",
       "      <td>0.510666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431796</td>\n",
       "      <td>0.503442</td>\n",
       "      <td>0.657385</td>\n",
       "      <td>0.492504</td>\n",
       "      <td>0.701129</td>\n",
       "      <td>0.472956</td>\n",
       "      <td>0.418403</td>\n",
       "      <td>0.329194</td>\n",
       "      <td>0.429469</td>\n",
       "      <td>0.556687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152160</td>\n",
       "      <td>0.382406</td>\n",
       "      <td>0.305958</td>\n",
       "      <td>0.374162</td>\n",
       "      <td>0.314520</td>\n",
       "      <td>0.293949</td>\n",
       "      <td>0.293967</td>\n",
       "      <td>0.348743</td>\n",
       "      <td>0.254733</td>\n",
       "      <td>0.407167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...        74        75        76  \\\n",
       "0   0   0   0   0   1   1   1   0   0   1  ...  0.411253  0.291427  0.317243   \n",
       "1   1   0   0   0   0   0   0   1   0   0  ...  0.331504  0.555731  0.306425   \n",
       "2   0   0   0   0   1   0   1   0   0   1  ...  0.637170  0.536411  0.603719   \n",
       "3   0   1   1   1   0   0   0   2   1   1  ...  0.431796  0.503442  0.657385   \n",
       "4   0   0   0   0   1   1   0   1   0   0  ...  0.152160  0.382406  0.305958   \n",
       "\n",
       "         77        78        79        80        81        82        83  \n",
       "0  0.446055  0.324598  0.183282  0.482389  0.589053  0.290537  0.221735  \n",
       "1  0.364694  0.390856  0.612504  0.428267  0.558000  0.431235  0.605948  \n",
       "2  0.502571  0.602314  0.572640  0.437036  0.648696  0.519391  0.510666  \n",
       "3  0.492504  0.701129  0.472956  0.418403  0.329194  0.429469  0.556687  \n",
       "4  0.374162  0.314520  0.293949  0.293967  0.348743  0.254733  0.407167  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique.reset_index(drop=True, inplace=True)\n",
    "normalized_opnmf_coeffs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(unique.loc[:,\"rs4575098\":\"rs429358\"].shape)\n",
    "print(normalized_opnmf_coeffs.shape)\n",
    "combined = pd.concat([unique.loc[:,\"rs4575098\":\"rs429358\"], normalized_opnmf_coeffs], axis=1, ignore_index=True, join='outer')\n",
    "print(combined.shape)\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "801a6433-ec3a-47d1-b7a4-0dd1cff5a502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 10}\n",
      "Untrained Accuracy:  53.398\n",
      "Best Parameters for trained data: {'C': 0.01}\n",
      "Trained Accuracy:    51.701\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = combined , unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = both, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
