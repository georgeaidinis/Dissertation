{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97cf239",
   "metadata": {},
   "source": [
    "# Use DeepCCA to transform ADNI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3582a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "from objectives import cca_loss\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08db7d",
   "metadata": {},
   "source": [
    "### Read the database, examine it:\n",
    "\n",
    "Instead of reading the whole database, we read only the data that's useful to us. That is, we read only specific columns of data, and we take only the row containing the first scan for each person. \n",
    "\n",
    "In \"ADNI Regressional Analysis.ipynb\" we have done that exactly, as well as performed linear regression transformation to the imaging data, in order to remove any age, sex, and DLICV_baseline effect. \n",
    "\n",
    "Furthermore, in \"ADNI OPNMF.ipynb\" we have performed dimensionality reduction through the OPNMF method, reducing the number of the ROIs from 145 to just 18. (Hasn't been done so this does not apply)\n",
    "\n",
    "The data is located at \"./DATA/Reduced_Linearly_Transformed_Unique_Dataset.pkl\" \n",
    "\n",
    "(Need to run the RA code if data is not found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009c840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 208)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DLICV_baseline</th>\n",
       "      <th>APOE4_Alleles</th>\n",
       "      <th>APOE_Genotype</th>\n",
       "      <th>Diagnosis_nearest_2.0</th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>MUSE_Volume_11</th>\n",
       "      <th>...</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "      <th>Diagnosis_nearest_2.0_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>2006-04-18</td>\n",
       "      <td>84.742466</td>\n",
       "      <td>0</td>\n",
       "      <td>1485405.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>-440.777069</td>\n",
       "      <td>-507.297168</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>2006-05-02</td>\n",
       "      <td>76.283562</td>\n",
       "      <td>1</td>\n",
       "      <td>1364116.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>577.755137</td>\n",
       "      <td>-188.813792</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>2006-05-23</td>\n",
       "      <td>79.223288</td>\n",
       "      <td>0</td>\n",
       "      <td>1570479.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>198.499249</td>\n",
       "      <td>1080.290951</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>002_S_0619</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>77.447945</td>\n",
       "      <td>0</td>\n",
       "      <td>1859348.250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>2623.687012</td>\n",
       "      <td>649.558822</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>2006-07-17</td>\n",
       "      <td>65.056164</td>\n",
       "      <td>1</td>\n",
       "      <td>1166961.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>246.226215</td>\n",
       "      <td>628.340793</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>70.767123</td>\n",
       "      <td>0</td>\n",
       "      <td>1444128.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-145.138564</td>\n",
       "      <td>-193.593195</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>002_S_0938</td>\n",
       "      <td>2006-10-05</td>\n",
       "      <td>82.167123</td>\n",
       "      <td>1</td>\n",
       "      <td>1309685.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>169.421397</td>\n",
       "      <td>-610.085153</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>002_S_0954</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>69.198630</td>\n",
       "      <td>1</td>\n",
       "      <td>1075661.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-81.664210</td>\n",
       "      <td>1343.833768</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>002_S_0955</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>78.161644</td>\n",
       "      <td>1</td>\n",
       "      <td>1363607.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1036.385233</td>\n",
       "      <td>-353.324662</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>002_S_1018</td>\n",
       "      <td>2006-11-29</td>\n",
       "      <td>70.658904</td>\n",
       "      <td>1</td>\n",
       "      <td>1355603.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-495.018850</td>\n",
       "      <td>486.447691</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>002_S_1070</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>73.564384</td>\n",
       "      <td>0</td>\n",
       "      <td>1550701.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>248.001697</td>\n",
       "      <td>515.447841</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>002_S_1261</td>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>71.067123</td>\n",
       "      <td>1</td>\n",
       "      <td>1350714.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>-213.577546</td>\n",
       "      <td>489.130696</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>002_S_1268</td>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>82.642466</td>\n",
       "      <td>0</td>\n",
       "      <td>1435189.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>208.117466</td>\n",
       "      <td>-496.119467</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>002_S_2043</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>72.180822</td>\n",
       "      <td>1</td>\n",
       "      <td>1280567.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-515.936926</td>\n",
       "      <td>-240.054535</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>002_S_4171</td>\n",
       "      <td>2011-08-08</td>\n",
       "      <td>69.353425</td>\n",
       "      <td>0</td>\n",
       "      <td>1522107.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>59.829735</td>\n",
       "      <td>-941.052654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PTID        Date        Age  Sex  DLICV_baseline  APOE4_Alleles  \\\n",
       "0    002_S_0295  2006-04-18  84.742466    0     1485405.375            1.0   \n",
       "9    002_S_0413  2006-05-02  76.283562    1     1364116.000            0.0   \n",
       "24   002_S_0559  2006-05-23  79.223288    0     1570479.625            1.0   \n",
       "31   002_S_0619  2006-06-01  77.447945    0     1859348.250            2.0   \n",
       "45   002_S_0729  2006-07-17  65.056164    1     1166961.750            1.0   \n",
       "64   002_S_0816  2006-08-30  70.767123    0     1444128.125            2.0   \n",
       "69   002_S_0938  2006-10-05  82.167123    1     1309685.000            0.0   \n",
       "74   002_S_0954  2006-10-10  69.198630    1     1075661.500            1.0   \n",
       "81   002_S_0955  2006-10-11  78.161644    1     1363607.000            1.0   \n",
       "84   002_S_1018  2006-11-29  70.658904    1     1355603.000            0.0   \n",
       "90   002_S_1070  2006-11-28  73.564384    0     1550701.375            0.0   \n",
       "113  002_S_1261  2007-02-15  71.067123    1     1350714.875            0.0   \n",
       "127  002_S_1268  2007-02-14  82.642466    0     1435189.875            1.0   \n",
       "147  002_S_2043  2010-08-31  72.180822    1     1280567.125            1.0   \n",
       "163  002_S_4171  2011-08-08  69.353425    0     1522107.375            0.0   \n",
       "\n",
       "    APOE_Genotype Diagnosis_nearest_2.0  MUSE_Volume_4  MUSE_Volume_11  ...  \\\n",
       "0           E3/E4                    CN    -440.777069     -507.297168  ...   \n",
       "9           E3/E3                    CN     577.755137     -188.813792  ...   \n",
       "24          E3/E4                    CN     198.499249     1080.290951  ...   \n",
       "31          E4/E4              Dementia    2623.687012      649.558822  ...   \n",
       "45          E3/E4                   MCI     246.226215      628.340793  ...   \n",
       "64          E4/E4              Dementia    -145.138564     -193.593195  ...   \n",
       "69          E3/E3              Dementia     169.421397     -610.085153  ...   \n",
       "74          E3/E4                   MCI     -81.664210     1343.833768  ...   \n",
       "81          E3/E4              Dementia    1036.385233     -353.324662  ...   \n",
       "84          E3/E3              Dementia    -495.018850      486.447691  ...   \n",
       "90          E3/E3                   MCI     248.001697      515.447841  ...   \n",
       "113         E3/E3                    CN    -213.577546      489.130696  ...   \n",
       "127         E3/E4                   MCI     208.117466     -496.119467  ...   \n",
       "147         E3/E4                   MCI    -515.936926     -240.054535  ...   \n",
       "163         E3/E3                   MCI      59.829735     -941.052654  ...   \n",
       "\n",
       "     rs111278892  rs3752246  rs4147929  rs41289512  rs3865444  rs6024870  \\\n",
       "0              1          1          1           0          0          0   \n",
       "9              0          1          1           0          1          0   \n",
       "24             0          0          0           0          1          0   \n",
       "31             0          0          0           1          1          0   \n",
       "45             0          0          0           1          1          0   \n",
       "64             0          0          0           0          1          0   \n",
       "69             0          1          1           0          1          0   \n",
       "74             2          1          1           0          1          0   \n",
       "81             1          0          0           0          1          0   \n",
       "84             1          1          1           0          0          0   \n",
       "90             0          0          0           0          0          0   \n",
       "113            0          0          0           0          0          1   \n",
       "127            0          0          0           0          1          1   \n",
       "147            0          0          0           1          0          0   \n",
       "163            0          0          0           0          0          0   \n",
       "\n",
       "     rs6014724  rs7274581  rs429358  Diagnosis_nearest_2.0_cat  \n",
       "0            0          0         1                          0  \n",
       "9            0          0         0                          0  \n",
       "24           0          0         0                          0  \n",
       "31           0          0         2                          1  \n",
       "45           0          0         1                          2  \n",
       "64           0          0         2                          1  \n",
       "69           0          0         0                          1  \n",
       "74           0          0         1                          2  \n",
       "81           0          0         1                          1  \n",
       "84           0          0         0                          1  \n",
       "90           0          0         0                          2  \n",
       "113          1          1         0                          0  \n",
       "127          1          1         1                          2  \n",
       "147          0          0         1                          2  \n",
       "163          0          1         0                          2  \n",
       "\n",
       "[15 rows x 208 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = pd.read_pickle(\"./DATA/Linearly_Transformed_Unique_Dataset.pkl\")\n",
    "print(unique.shape)\n",
    "unique.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c020f",
   "metadata": {},
   "source": [
    "### Create the 2 views:\n",
    "\n",
    "The first view consists of the imaging data, that are in the form of 145 real numbers. Those numbers are based on a prediction from a Linear Regression estimator trained only on the Cognitive Normal datapoints. The predictions then are subtracted from the actual values, and the remaining value (residual) is the datapoint for each ROI.\n",
    "\n",
    "The second view consists of the 54 SNP (Single Nucleotide Polymorphism, \"snip\"), for each individual. They are either 0 or 1. \n",
    "\n",
    "The 2 views are the most basic views that can be used for the Deep CCA, and in further tests more features will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ded1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afced851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>MUSE_Volume_11</th>\n",
       "      <th>MUSE_Volume_23</th>\n",
       "      <th>MUSE_Volume_30</th>\n",
       "      <th>MUSE_Volume_31</th>\n",
       "      <th>MUSE_Volume_32</th>\n",
       "      <th>MUSE_Volume_35</th>\n",
       "      <th>MUSE_Volume_36</th>\n",
       "      <th>MUSE_Volume_37</th>\n",
       "      <th>MUSE_Volume_38</th>\n",
       "      <th>...</th>\n",
       "      <th>MUSE_Volume_198</th>\n",
       "      <th>MUSE_Volume_199</th>\n",
       "      <th>MUSE_Volume_200</th>\n",
       "      <th>MUSE_Volume_201</th>\n",
       "      <th>MUSE_Volume_202</th>\n",
       "      <th>MUSE_Volume_203</th>\n",
       "      <th>MUSE_Volume_204</th>\n",
       "      <th>MUSE_Volume_205</th>\n",
       "      <th>MUSE_Volume_206</th>\n",
       "      <th>MUSE_Volume_207</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-440.777069</td>\n",
       "      <td>-507.297168</td>\n",
       "      <td>-35.171797</td>\n",
       "      <td>-14.510211</td>\n",
       "      <td>90.244138</td>\n",
       "      <td>140.075639</td>\n",
       "      <td>299.828133</td>\n",
       "      <td>63.889680</td>\n",
       "      <td>56.259492</td>\n",
       "      <td>4434.963481</td>\n",
       "      <td>...</td>\n",
       "      <td>745.557312</td>\n",
       "      <td>-188.954470</td>\n",
       "      <td>-1594.432454</td>\n",
       "      <td>-1648.308374</td>\n",
       "      <td>798.003198</td>\n",
       "      <td>-468.672456</td>\n",
       "      <td>-81.798945</td>\n",
       "      <td>283.990527</td>\n",
       "      <td>-134.708868</td>\n",
       "      <td>-102.291612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>577.755137</td>\n",
       "      <td>-188.813792</td>\n",
       "      <td>35.574764</td>\n",
       "      <td>-39.881572</td>\n",
       "      <td>40.161648</td>\n",
       "      <td>58.255314</td>\n",
       "      <td>-909.956510</td>\n",
       "      <td>-107.325098</td>\n",
       "      <td>118.445748</td>\n",
       "      <td>-932.590538</td>\n",
       "      <td>...</td>\n",
       "      <td>1336.384182</td>\n",
       "      <td>2631.004114</td>\n",
       "      <td>1410.754665</td>\n",
       "      <td>30.295558</td>\n",
       "      <td>-1258.071206</td>\n",
       "      <td>115.187177</td>\n",
       "      <td>-175.177715</td>\n",
       "      <td>-533.517736</td>\n",
       "      <td>-37.990106</td>\n",
       "      <td>-475.586534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>198.499249</td>\n",
       "      <td>1080.290951</td>\n",
       "      <td>137.416288</td>\n",
       "      <td>142.586830</td>\n",
       "      <td>121.231074</td>\n",
       "      <td>41.449232</td>\n",
       "      <td>1825.886437</td>\n",
       "      <td>-267.694901</td>\n",
       "      <td>6.605333</td>\n",
       "      <td>-947.176391</td>\n",
       "      <td>...</td>\n",
       "      <td>-1764.158370</td>\n",
       "      <td>-2206.292278</td>\n",
       "      <td>1473.087979</td>\n",
       "      <td>532.054466</td>\n",
       "      <td>1714.763199</td>\n",
       "      <td>2469.640085</td>\n",
       "      <td>209.533224</td>\n",
       "      <td>-49.858132</td>\n",
       "      <td>-206.268764</td>\n",
       "      <td>-117.520261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2623.687012</td>\n",
       "      <td>649.558822</td>\n",
       "      <td>-162.939446</td>\n",
       "      <td>-122.191780</td>\n",
       "      <td>-329.934406</td>\n",
       "      <td>-351.510297</td>\n",
       "      <td>-3426.992838</td>\n",
       "      <td>-826.297201</td>\n",
       "      <td>-713.213854</td>\n",
       "      <td>-355.750507</td>\n",
       "      <td>...</td>\n",
       "      <td>-641.454806</td>\n",
       "      <td>583.322773</td>\n",
       "      <td>-701.560285</td>\n",
       "      <td>-1369.412583</td>\n",
       "      <td>-2919.253412</td>\n",
       "      <td>-2766.270514</td>\n",
       "      <td>-757.912814</td>\n",
       "      <td>-822.771500</td>\n",
       "      <td>-347.672981</td>\n",
       "      <td>-131.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>246.226215</td>\n",
       "      <td>628.340793</td>\n",
       "      <td>10.979183</td>\n",
       "      <td>24.346908</td>\n",
       "      <td>-165.999584</td>\n",
       "      <td>-114.587813</td>\n",
       "      <td>171.517739</td>\n",
       "      <td>628.498317</td>\n",
       "      <td>88.705570</td>\n",
       "      <td>-521.590388</td>\n",
       "      <td>...</td>\n",
       "      <td>-346.626209</td>\n",
       "      <td>-670.579403</td>\n",
       "      <td>163.045892</td>\n",
       "      <td>1008.186971</td>\n",
       "      <td>-1557.957769</td>\n",
       "      <td>-1396.447884</td>\n",
       "      <td>-146.495250</td>\n",
       "      <td>-188.233592</td>\n",
       "      <td>-200.821122</td>\n",
       "      <td>-254.208574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MUSE_Volume_4  MUSE_Volume_11  MUSE_Volume_23  MUSE_Volume_30  \\\n",
       "0     -440.777069     -507.297168      -35.171797      -14.510211   \n",
       "9      577.755137     -188.813792       35.574764      -39.881572   \n",
       "24     198.499249     1080.290951      137.416288      142.586830   \n",
       "31    2623.687012      649.558822     -162.939446     -122.191780   \n",
       "45     246.226215      628.340793       10.979183       24.346908   \n",
       "\n",
       "    MUSE_Volume_31  MUSE_Volume_32  MUSE_Volume_35  MUSE_Volume_36  \\\n",
       "0        90.244138      140.075639      299.828133       63.889680   \n",
       "9        40.161648       58.255314     -909.956510     -107.325098   \n",
       "24      121.231074       41.449232     1825.886437     -267.694901   \n",
       "31     -329.934406     -351.510297    -3426.992838     -826.297201   \n",
       "45     -165.999584     -114.587813      171.517739      628.498317   \n",
       "\n",
       "    MUSE_Volume_37  MUSE_Volume_38  ...  MUSE_Volume_198  MUSE_Volume_199  \\\n",
       "0        56.259492     4434.963481  ...       745.557312      -188.954470   \n",
       "9       118.445748     -932.590538  ...      1336.384182      2631.004114   \n",
       "24        6.605333     -947.176391  ...     -1764.158370     -2206.292278   \n",
       "31     -713.213854     -355.750507  ...      -641.454806       583.322773   \n",
       "45       88.705570     -521.590388  ...      -346.626209      -670.579403   \n",
       "\n",
       "    MUSE_Volume_200  MUSE_Volume_201  MUSE_Volume_202  MUSE_Volume_203  \\\n",
       "0      -1594.432454     -1648.308374       798.003198      -468.672456   \n",
       "9       1410.754665        30.295558     -1258.071206       115.187177   \n",
       "24      1473.087979       532.054466      1714.763199      2469.640085   \n",
       "31      -701.560285     -1369.412583     -2919.253412     -2766.270514   \n",
       "45       163.045892      1008.186971     -1557.957769     -1396.447884   \n",
       "\n",
       "    MUSE_Volume_204  MUSE_Volume_205  MUSE_Volume_206  MUSE_Volume_207  \n",
       "0        -81.798945       283.990527      -134.708868      -102.291612  \n",
       "9       -175.177715      -533.517736       -37.990106      -475.586534  \n",
       "24       209.533224       -49.858132      -206.268764      -117.520261  \n",
       "31      -757.912814      -822.771500      -347.672981      -131.863034  \n",
       "45      -146.495250      -188.233592      -200.821122      -254.208574  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs4575098</th>\n",
       "      <th>rs6656401</th>\n",
       "      <th>rs2093760</th>\n",
       "      <th>rs4844610</th>\n",
       "      <th>rs4663105</th>\n",
       "      <th>rs6733839</th>\n",
       "      <th>rs10933431</th>\n",
       "      <th>rs35349669</th>\n",
       "      <th>rs6448453</th>\n",
       "      <th>rs190982</th>\n",
       "      <th>...</th>\n",
       "      <th>rs28394864</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs4575098  rs6656401  rs2093760  rs4844610  rs4663105  rs6733839  \\\n",
       "0           0          0          0          0          1          1   \n",
       "9           1          0          0          0          0          0   \n",
       "24          0          0          0          0          1          0   \n",
       "31          0          1          1          1          0          0   \n",
       "45          0          0          0          0          1          1   \n",
       "\n",
       "    rs10933431  rs35349669  rs6448453  rs190982  ...  rs28394864  rs111278892  \\\n",
       "0            1           0          0         1  ...           0            1   \n",
       "9            0           1          0         0  ...           1            0   \n",
       "24           1           0          0         1  ...           2            0   \n",
       "31           0           2          1         1  ...           1            0   \n",
       "45           0           1          0         0  ...           1            0   \n",
       "\n",
       "    rs3752246  rs4147929  rs41289512  rs3865444  rs6024870  rs6014724  \\\n",
       "0           1          1           0          0          0          0   \n",
       "9           1          1           0          1          0          0   \n",
       "24          0          0           0          1          0          0   \n",
       "31          0          0           1          1          0          0   \n",
       "45          0          0           1          1          0          0   \n",
       "\n",
       "    rs7274581  rs429358  \n",
       "0           0         1  \n",
       "9           0         0  \n",
       "24          0         0  \n",
       "31          0         2  \n",
       "45          0         1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"View 1:\")\n",
    "display(view_1.head())\n",
    "print(\"View 2:\")\n",
    "display(view_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8102d",
   "metadata": {},
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abc22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a gpu exists, torch.device should be 'gpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the path to save the final learned features\n",
    "save_to = './DATA/ADNI_initial_DCCA_features.pkl'\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 50\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 145 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "# this apparently can be different for each network, some experimentation is needed!\n",
    "layer_sizes1 = [256, 1024, 1024, outdim_size]\n",
    "layer_sizes2 = [256, 1024, 1024, outdim_size]\n",
    "# layer_sizes1 = [64, 128, outdim_size]\n",
    "# layer_sizes2 = [64, 128, outdim_size]\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-3\n",
    "epoch_num = 200\n",
    "batch_size = 1000\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-3\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top \n",
    "# outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = False\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32dded",
   "metadata": {},
   "source": [
    "###  Building, training, and producing the new features by DCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4ebdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e14d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145) <class 'numpy.ndarray'> float64\n",
      "(1302, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1302, 145]) <class 'torch.Tensor'>\n",
      "torch.Size([1302, 54]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Scramble the datapoints for randomness:\n",
    "indices = np.arange(view_1_n.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "view_1_n = view_1_n[indices]\n",
    "view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f516e24f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2022-01-11 17:00:16,600 ] - DataParallel(\n",
      "  (module): DeepCCA(\n",
      "    (model1): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=145, out_features=256, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=50, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model2): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=54, out_features=256, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=50, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[ INFO : 2022-01-11 17:00:16,601 ] - RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    weight_decay: 0.001\n",
      ")\n",
      "[ INFO : 2022-01-11 17:00:17,476 ] - Epoch 1: val_loss improved from 0.0000 to -3.6485, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:17,491 ] - Epoch 1/200 - time: 0.89 - training_loss: -9.7289 - val_loss: -3.6485\n",
      "[ INFO : 2022-01-11 17:00:18,297 ] - Epoch 2: val_loss improved from -3.6485 to -5.6133, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:19,113 ] - Epoch 3: val_loss improved from -5.6133 to -7.1537, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:19,916 ] - Epoch 4: val_loss improved from -7.1537 to -8.5206, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:20,720 ] - Epoch 5: val_loss improved from -8.5206 to -9.2330, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:21,525 ] - Epoch 6: val_loss improved from -9.2330 to -10.1682, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:22,332 ] - Epoch 7: val_loss improved from -10.1682 to -11.1463, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:23,145 ] - Epoch 8: val_loss improved from -11.1463 to -11.8374, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:23,953 ] - Epoch 9: val_loss improved from -11.8374 to -12.3671, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:24,757 ] - Epoch 10: val_loss improved from -12.3671 to -12.5031, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:25,564 ] - Epoch 11: val_loss improved from -12.5031 to -13.1546, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:26,378 ] - Epoch 12: val_loss improved from -13.1546 to -13.7638, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:27,185 ] - Epoch 13: val_loss improved from -13.7638 to -14.1908, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:27,994 ] - Epoch 14: val_loss improved from -14.1908 to -14.4181, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:28,802 ] - Epoch 15: val_loss improved from -14.4181 to -15.0441, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:29,605 ] - Epoch 16: val_loss improved from -15.0441 to -15.3665, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:30,408 ] - Epoch 17: val_loss improved from -15.3665 to -15.8113, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:31,211 ] - Epoch 18: val_loss improved from -15.8113 to -16.1214, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:32,014 ] - Epoch 19: val_loss improved from -16.1214 to -16.4727, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:32,818 ] - Epoch 20: val_loss improved from -16.4727 to -16.8316, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:33,620 ] - Epoch 21: val_loss improved from -16.8316 to -17.3256, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:33,631 ] - Epoch 21/200 - time: 0.80 - training_loss: -31.8083 - val_loss: -17.3256\n",
      "[ INFO : 2022-01-11 17:00:34,423 ] - Epoch 22: val_loss improved from -17.3256 to -17.7935, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:35,225 ] - Epoch 23: val_loss improved from -17.7935 to -18.1654, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:36,026 ] - Epoch 24: val_loss improved from -18.1654 to -18.6437, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:36,829 ] - Epoch 25: val_loss improved from -18.6437 to -19.1168, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:37,632 ] - Epoch 26: val_loss improved from -19.1168 to -19.4621, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:38,437 ] - Epoch 27: val_loss improved from -19.4621 to -20.1561, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:39,245 ] - Epoch 28: val_loss improved from -20.1561 to -20.4291, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:40,055 ] - Epoch 29: val_loss improved from -20.4291 to -21.0763, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:40,868 ] - Epoch 30: val_loss improved from -21.0763 to -21.1003, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:41,694 ] - Epoch 31: val_loss improved from -21.1003 to -21.6769, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:42,515 ] - Epoch 32: val_loss improved from -21.6769 to -21.7631, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:43,320 ] - Epoch 33: val_loss improved from -21.7631 to -22.1044, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:44,128 ] - Epoch 34: val_loss improved from -22.1044 to -22.1141, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:44,935 ] - Epoch 35: val_loss improved from -22.1141 to -22.2355, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:45,739 ] - Epoch 36: val_loss improved from -22.2355 to -22.4842, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:46,559 ] - Epoch 37: val_loss improved from -22.4842 to -22.5045, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:47,379 ] - Epoch 38: val_loss improved from -22.5045 to -22.6571, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:48,195 ] - Epoch 39: val_loss improved from -22.6571 to -22.7067, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:49,009 ] - Epoch 40: val_loss improved from -22.7067 to -22.8223, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:49,824 ] - Epoch 41: val_loss did not improve from -22.8223\n",
      "[ INFO : 2022-01-11 17:00:49,824 ] - Epoch 41/200 - time: 0.80 - training_loss: -38.6885 - val_loss: -22.6722\n",
      "[ INFO : 2022-01-11 17:00:50,627 ] - Epoch 42: val_loss improved from -22.8223 to -22.8370, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:00:52,224 ] - Epoch 44: val_loss improved from -22.8370 to -22.9147, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:01:05,677 ] - Epoch 61: val_loss did not improve from -22.9147\n",
      "[ INFO : 2022-01-11 17:01:05,677 ] - Epoch 61/200 - time: 0.79 - training_loss: -41.9051 - val_loss: -22.8783\n",
      "[ INFO : 2022-01-11 17:01:07,262 ] - Epoch 63: val_loss improved from -22.9147 to -22.9666, saving model to checkpoint.model\n",
      "[ INFO : 2022-01-11 17:01:08,855 ] - Epoch 65: val_loss improved from -22.9666 to -23.0617, saving model to checkpoint.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2022-01-11 17:01:21,576 ] - Epoch 81: val_loss did not improve from -23.0617\n",
      "[ INFO : 2022-01-11 17:01:21,577 ] - Epoch 81/200 - time: 0.79 - training_loss: -43.7028 - val_loss: -22.7452\n",
      "[ INFO : 2022-01-11 17:01:37,474 ] - Epoch 101: val_loss did not improve from -23.0617\n",
      "[ INFO : 2022-01-11 17:01:37,474 ] - Epoch 101/200 - time: 0.79 - training_loss: -44.8188 - val_loss: -22.5855\n",
      "[ INFO : 2022-01-11 17:01:53,426 ] - Epoch 121: val_loss did not improve from -23.0617\n",
      "[ INFO : 2022-01-11 17:01:53,427 ] - Epoch 121/200 - time: 0.80 - training_loss: -45.5785 - val_loss: -22.6083\n",
      "[ INFO : 2022-01-11 17:02:10,228 ] - Epoch 141: val_loss did not improve from -23.0617\n",
      "[ INFO : 2022-01-11 17:02:10,229 ] - Epoch 141/200 - time: 0.88 - training_loss: -46.1268 - val_loss: -22.7041\n",
      "[ INFO : 2022-01-11 17:02:26,721 ] - Epoch 161: val_loss did not improve from -23.0617\n",
      "[ INFO : 2022-01-11 17:02:26,722 ] - Epoch 161/200 - time: 0.81 - training_loss: -46.5432 - val_loss: -22.6211\n",
      "[ INFO : 2022-01-11 17:02:42,828 ] - Epoch 181: val_loss did not improve from -23.0617\n",
      "[ INFO : 2022-01-11 17:02:42,829 ] - Epoch 181/200 - time: 0.80 - training_loss: -46.8696 - val_loss: -22.8081\n",
      "[ INFO : 2022-01-11 17:02:58,402 ] - loss on validation data: -23.0617\n",
      "[ INFO : 2022-01-11 17:02:58,441 ] - loss on test data: -27.5120\n"
     ]
    }
   ],
   "source": [
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "l_cca = None\n",
    "if apply_linear_cca:\n",
    "    l_cca = linear_cca()\n",
    "    \n",
    "    \n",
    "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
    "                learning_rate, reg_par, device=device, epoch_log_freq=20)\n",
    "s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "# Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "solver.fit(train1, train2, val1, val2, test1, test2)\n",
    "# TODO: Save linear_cca model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e11b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-48.005 -17.84 ]\n",
      "-32.9225\n"
     ]
    }
   ],
   "source": [
    "set_size = [0, \n",
    "            train1.size(0), \n",
    "            train1.size(0) + val1.size(0), \n",
    "            train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "\n",
    "losses, outputs = solver._get_outputs(data1, data2)\n",
    "losses = np.round(losses,3)\n",
    "print(losses)\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b361e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1302, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "(1302, 50)\n"
     ]
    }
   ],
   "source": [
    "print(type(outputs[0]))\n",
    "print(outputs[0].shape)\n",
    "print(type(outputs[1]))\n",
    "print(outputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e3e90",
   "metadata": {},
   "source": [
    "### Saving the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23a5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving new features in a gzip pickled file specified by save_to\n",
    "with open(save_to, 'wb') as f:\n",
    "    pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f517c8f",
   "metadata": {},
   "source": [
    "### Loading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacfa2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fcaab88fac0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.load('checkpoint.model')\n",
    "solver.model.load_state_dict(d)\n",
    "solver.model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5022e0f",
   "metadata": {},
   "source": [
    "### Testing the Correlation between inputs and outputs of the deep Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5357aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Network input correlation:  -9.61433374246316\n",
      "Deep Network output correlation:  -49.89852184343137\n"
     ]
    }
   ],
   "source": [
    "l_i = cca_loss(outdim_size, use_all_singular_values, device)\n",
    "loss_i = l_i.loss(data1[:,0:54], data2).item() # first 54 columns of imaging data\n",
    "l_o = cca_loss(outdim_size, use_all_singular_values, device)\n",
    "loss_o = l_o.loss(torch.from_numpy(outputs[0]), torch.from_numpy(outputs[0])).item()\n",
    "\n",
    "print(\"Deep Network input correlation: \",  loss_i)\n",
    "print(\"Deep Network output correlation: \", loss_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "019cb979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA on input data:\n",
      "-0.4337692736170777\n",
      "CCA on output data:\n",
      "0.5283700944219817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "print(\"CCA on input data:\")\n",
    "X = data1\n",
    "Y = data2\n",
    "cca = CCA(n_components=50)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "print(cca.score(X, Y))\n",
    "\n",
    "print(\"CCA on output data:\")\n",
    "X = outputs[0]\n",
    "Y = outputs[1]\n",
    "cca = CCA(n_components=50,max_iter=10000)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "print(cca.score(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16aa69",
   "metadata": {},
   "source": [
    "### Training and testing of SVM with linear kernel on the view 1 with new features vs old features: (Imaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93a074bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 1}\n",
      "Untrained Accuracy:  51.688\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    49.162\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_1, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[0], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84180f5",
   "metadata": {},
   "source": [
    "### Training and testing of SVM with linear kernel on the view 2 with new features vs old features: (Genetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "678964ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.0001}\n",
      "Untrained Accuracy:  48.08\n",
      "Best Parameters for trained data: {'C': 10}\n",
      "Trained Accuracy:    49.162\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_2, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[1], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017fe62",
   "metadata": {},
   "source": [
    "### Training and testing of SVM with linear kernel on both views with new features vs old features: (Imaging + Genetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "461324ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 50)\n",
      "(1302, 50)\n",
      "(1302, 100)\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)\n",
    "both = np.concatenate((outputs[0], outputs[1]), axis=1)\n",
    "print(both.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12fd3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.1}\n",
      "Untrained Accuracy:  52.912\n",
      "Best Parameters for trained data: {'C': 10}\n",
      "Trained Accuracy:    49.162\n"
     ]
    }
   ],
   "source": [
    "c = list(unique.columns)\n",
    "MRI_columns = c[c.index(\"MUSE_Volume_4\"):c.index(\"MUSE_Volume_207\")+1]\n",
    "genetic_columns = c[c.index(\"rs4575098\"):c.index(\"rs429358\")+1]\n",
    "columns_of_interest = []\n",
    "columns_of_interest += MRI_columns + genetic_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = unique[columns_of_interest] , unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = both, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
