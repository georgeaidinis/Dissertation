{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97cf239",
   "metadata": {},
   "source": [
    "# Use DeepCCA to transform ADNI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3582a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "from objectives import cca_loss\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08db7d",
   "metadata": {},
   "source": [
    "## Read the database, examine it:\n",
    "\n",
    "Instead of reading the whole database, we read only the data that's useful to us. That is, we read only specific columns of data, and we take only the row containing the first scan for each person. \n",
    "\n",
    "In \"ADNI Regressional Analysis.ipynb\" we have done that exactly, as well as performed linear regression transformation to the imaging data, in order to remove any age, sex, and DLICV_baseline effect. \n",
    "\n",
    "Furthermore, in \"ADNI OPNMF.ipynb\" we have performed dimensionality reduction through the OPNMF method, reducing the number of the ROIs from 145 to just 18. (Hasn't been done so this does not apply)\n",
    "\n",
    "The data is located at \"./DATA/Reduced_Linearly_Transformed_Unique_Dataset.pkl\" \n",
    "\n",
    "(Need to run the RA code if data is not found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009c840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 209)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>MRID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DLICV_baseline</th>\n",
       "      <th>APOE4_Alleles</th>\n",
       "      <th>APOE_Genotype</th>\n",
       "      <th>Diagnosis_nearest_2.0</th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>...</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "      <th>Diagnosis_nearest_2.0_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>002_S_0295_2006-04-18</td>\n",
       "      <td>2006-04-18</td>\n",
       "      <td>84.742466</td>\n",
       "      <td>0</td>\n",
       "      <td>1485405.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>-401.428503</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>002_S_0413_2006-05-02</td>\n",
       "      <td>2006-05-02</td>\n",
       "      <td>76.283562</td>\n",
       "      <td>1</td>\n",
       "      <td>1364116.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>596.355045</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>002_S_0559_2006-05-23</td>\n",
       "      <td>2006-05-23</td>\n",
       "      <td>79.223288</td>\n",
       "      <td>0</td>\n",
       "      <td>1570479.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>CN</td>\n",
       "      <td>224.874560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>002_S_0619</td>\n",
       "      <td>002_S_0619_2006-06-01</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>77.447945</td>\n",
       "      <td>0</td>\n",
       "      <td>1859348.250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>2633.277779</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>002_S_0729_2006-07-17</td>\n",
       "      <td>2006-07-17</td>\n",
       "      <td>65.056164</td>\n",
       "      <td>1</td>\n",
       "      <td>1166961.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>256.289641</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>002_S_0816_2006-08-30</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>70.767123</td>\n",
       "      <td>0</td>\n",
       "      <td>1444128.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E4/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-126.260419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>002_S_0938</td>\n",
       "      <td>002_S_0938_2006-10-05</td>\n",
       "      <td>2006-10-05</td>\n",
       "      <td>82.167123</td>\n",
       "      <td>1</td>\n",
       "      <td>1309685.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>200.102369</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>002_S_0954</td>\n",
       "      <td>002_S_0954_2006-10-10</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>69.198630</td>\n",
       "      <td>1</td>\n",
       "      <td>1075661.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-60.539913</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>002_S_0955</td>\n",
       "      <td>002_S_0955_2006-10-11</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>78.161644</td>\n",
       "      <td>1</td>\n",
       "      <td>1363607.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1058.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>002_S_1018</td>\n",
       "      <td>002_S_1018_2006-11-29</td>\n",
       "      <td>2006-11-29</td>\n",
       "      <td>70.658904</td>\n",
       "      <td>1</td>\n",
       "      <td>1355603.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>-485.048304</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>002_S_1070</td>\n",
       "      <td>002_S_1070_2006-11-28</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>73.564384</td>\n",
       "      <td>0</td>\n",
       "      <td>1550701.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>266.235891</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>002_S_1261</td>\n",
       "      <td>002_S_1261_2007-02-15</td>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>71.067123</td>\n",
       "      <td>1</td>\n",
       "      <td>1350714.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>CN</td>\n",
       "      <td>-202.715174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>002_S_1268</td>\n",
       "      <td>002_S_1268_2007-02-14</td>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>82.642466</td>\n",
       "      <td>0</td>\n",
       "      <td>1435189.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>246.512659</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>002_S_2043</td>\n",
       "      <td>002_S_2043_2010-08-31</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>72.180822</td>\n",
       "      <td>1</td>\n",
       "      <td>1280567.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E3/E4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>-499.901619</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>002_S_4171</td>\n",
       "      <td>002_S_4171_2011-08-08</td>\n",
       "      <td>2011-08-08</td>\n",
       "      <td>69.353425</td>\n",
       "      <td>0</td>\n",
       "      <td>1522107.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E3/E3</td>\n",
       "      <td>MCI</td>\n",
       "      <td>72.675098</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PTID                   MRID        Date        Age  Sex  \\\n",
       "0    002_S_0295  002_S_0295_2006-04-18  2006-04-18  84.742466    0   \n",
       "9    002_S_0413  002_S_0413_2006-05-02  2006-05-02  76.283562    1   \n",
       "24   002_S_0559  002_S_0559_2006-05-23  2006-05-23  79.223288    0   \n",
       "31   002_S_0619  002_S_0619_2006-06-01  2006-06-01  77.447945    0   \n",
       "45   002_S_0729  002_S_0729_2006-07-17  2006-07-17  65.056164    1   \n",
       "64   002_S_0816  002_S_0816_2006-08-30  2006-08-30  70.767123    0   \n",
       "69   002_S_0938  002_S_0938_2006-10-05  2006-10-05  82.167123    1   \n",
       "74   002_S_0954  002_S_0954_2006-10-10  2006-10-10  69.198630    1   \n",
       "81   002_S_0955  002_S_0955_2006-10-11  2006-10-11  78.161644    1   \n",
       "84   002_S_1018  002_S_1018_2006-11-29  2006-11-29  70.658904    1   \n",
       "90   002_S_1070  002_S_1070_2006-11-28  2006-11-28  73.564384    0   \n",
       "113  002_S_1261  002_S_1261_2007-02-15  2007-02-15  71.067123    1   \n",
       "127  002_S_1268  002_S_1268_2007-02-14  2007-02-14  82.642466    0   \n",
       "147  002_S_2043  002_S_2043_2010-08-31  2010-08-31  72.180822    1   \n",
       "163  002_S_4171  002_S_4171_2011-08-08  2011-08-08  69.353425    0   \n",
       "\n",
       "     DLICV_baseline  APOE4_Alleles APOE_Genotype Diagnosis_nearest_2.0  \\\n",
       "0       1485405.375            1.0         E3/E4                    CN   \n",
       "9       1364116.000            0.0         E3/E3                    CN   \n",
       "24      1570479.625            1.0         E3/E4                    CN   \n",
       "31      1859348.250            2.0         E4/E4              Dementia   \n",
       "45      1166961.750            1.0         E3/E4                   MCI   \n",
       "64      1444128.125            2.0         E4/E4              Dementia   \n",
       "69      1309685.000            0.0         E3/E3              Dementia   \n",
       "74      1075661.500            1.0         E3/E4                   MCI   \n",
       "81      1363607.000            1.0         E3/E4              Dementia   \n",
       "84      1355603.000            0.0         E3/E3              Dementia   \n",
       "90      1550701.375            0.0         E3/E3                   MCI   \n",
       "113     1350714.875            0.0         E3/E3                    CN   \n",
       "127     1435189.875            1.0         E3/E4                   MCI   \n",
       "147     1280567.125            1.0         E3/E4                   MCI   \n",
       "163     1522107.375            0.0         E3/E3                   MCI   \n",
       "\n",
       "     MUSE_Volume_4  ...  rs111278892  rs3752246  rs4147929  rs41289512  \\\n",
       "0      -401.428503  ...            1          1          1           0   \n",
       "9       596.355045  ...            0          1          1           0   \n",
       "24      224.874560  ...            0          0          0           0   \n",
       "31     2633.277779  ...            0          0          0           1   \n",
       "45      256.289641  ...            0          0          0           1   \n",
       "64     -126.260419  ...            0          0          0           0   \n",
       "69      200.102369  ...            0          1          1           0   \n",
       "74      -60.539913  ...            2          1          1           0   \n",
       "81     1058.028132  ...            1          0          0           0   \n",
       "84     -485.048304  ...            1          1          1           0   \n",
       "90      266.235891  ...            0          0          0           0   \n",
       "113    -202.715174  ...            0          0          0           0   \n",
       "127     246.512659  ...            0          0          0           0   \n",
       "147    -499.901619  ...            0          0          0           1   \n",
       "163      72.675098  ...            0          0          0           0   \n",
       "\n",
       "     rs3865444  rs6024870  rs6014724  rs7274581  rs429358  \\\n",
       "0            0          0          0          0         1   \n",
       "9            1          0          0          0         0   \n",
       "24           1          0          0          0         0   \n",
       "31           1          0          0          0         2   \n",
       "45           1          0          0          0         1   \n",
       "64           1          0          0          0         2   \n",
       "69           1          0          0          0         0   \n",
       "74           1          0          0          0         1   \n",
       "81           1          0          0          0         1   \n",
       "84           0          0          0          0         0   \n",
       "90           0          0          0          0         0   \n",
       "113          0          1          1          1         0   \n",
       "127          1          1          1          1         1   \n",
       "147          0          0          0          0         1   \n",
       "163          0          0          0          1         0   \n",
       "\n",
       "     Diagnosis_nearest_2.0_cat  \n",
       "0                            0  \n",
       "9                            0  \n",
       "24                           0  \n",
       "31                           1  \n",
       "45                           2  \n",
       "64                           1  \n",
       "69                           1  \n",
       "74                           2  \n",
       "81                           1  \n",
       "84                           1  \n",
       "90                           2  \n",
       "113                          0  \n",
       "127                          2  \n",
       "147                          2  \n",
       "163                          2  \n",
       "\n",
       "[15 rows x 209 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = pd.read_pickle(\"./DATA/Linearly_Transformed_Unique_Dataset.pkl\")\n",
    "print(unique.shape)\n",
    "unique.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e714f1-ad2e-4d18-9b55-265cfbac0509",
   "metadata": {},
   "source": [
    "##  Building, training, and producing the new features by DCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c020f",
   "metadata": {},
   "source": [
    "### Create the 2 views:\n",
    "\n",
    "The first view consists of the imaging data, that are in the form of 145 real numbers. Those numbers are based on a prediction from a Linear Regression estimator trained only on the Cognitive Normal datapoints. The predictions then are subtracted from the actual values, and the remaining value (residual) is the datapoint for each ROI.\n",
    "\n",
    "The second view consists of the 54 SNP (Single Nucleotide Polymorphism, \"snip\"), for each individual. They are either 0 or 1. \n",
    "\n",
    "The 2 views are the most basic views that can be used for the Deep CCA, and in further tests more features will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ded1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afced851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUSE_Volume_4</th>\n",
       "      <th>MUSE_Volume_11</th>\n",
       "      <th>MUSE_Volume_23</th>\n",
       "      <th>MUSE_Volume_30</th>\n",
       "      <th>MUSE_Volume_31</th>\n",
       "      <th>MUSE_Volume_32</th>\n",
       "      <th>MUSE_Volume_35</th>\n",
       "      <th>MUSE_Volume_36</th>\n",
       "      <th>MUSE_Volume_37</th>\n",
       "      <th>MUSE_Volume_38</th>\n",
       "      <th>...</th>\n",
       "      <th>MUSE_Volume_198</th>\n",
       "      <th>MUSE_Volume_199</th>\n",
       "      <th>MUSE_Volume_200</th>\n",
       "      <th>MUSE_Volume_201</th>\n",
       "      <th>MUSE_Volume_202</th>\n",
       "      <th>MUSE_Volume_203</th>\n",
       "      <th>MUSE_Volume_204</th>\n",
       "      <th>MUSE_Volume_205</th>\n",
       "      <th>MUSE_Volume_206</th>\n",
       "      <th>MUSE_Volume_207</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-401.428503</td>\n",
       "      <td>-475.082401</td>\n",
       "      <td>-38.009137</td>\n",
       "      <td>-25.646775</td>\n",
       "      <td>75.669198</td>\n",
       "      <td>126.590353</td>\n",
       "      <td>124.482040</td>\n",
       "      <td>54.813183</td>\n",
       "      <td>29.901574</td>\n",
       "      <td>4088.590752</td>\n",
       "      <td>...</td>\n",
       "      <td>789.359109</td>\n",
       "      <td>-170.422388</td>\n",
       "      <td>-1543.880458</td>\n",
       "      <td>-1674.618225</td>\n",
       "      <td>632.563713</td>\n",
       "      <td>-531.585707</td>\n",
       "      <td>-39.623451</td>\n",
       "      <td>260.649954</td>\n",
       "      <td>-115.085767</td>\n",
       "      <td>-81.954942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>596.355045</td>\n",
       "      <td>-177.499304</td>\n",
       "      <td>34.866428</td>\n",
       "      <td>-42.623326</td>\n",
       "      <td>36.073837</td>\n",
       "      <td>53.399103</td>\n",
       "      <td>-914.581355</td>\n",
       "      <td>-108.931623</td>\n",
       "      <td>124.883198</td>\n",
       "      <td>-972.814733</td>\n",
       "      <td>...</td>\n",
       "      <td>1335.363413</td>\n",
       "      <td>2649.942277</td>\n",
       "      <td>1411.230818</td>\n",
       "      <td>31.346635</td>\n",
       "      <td>-1267.747385</td>\n",
       "      <td>117.940453</td>\n",
       "      <td>-149.481247</td>\n",
       "      <td>-535.823873</td>\n",
       "      <td>-40.431290</td>\n",
       "      <td>-470.993059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>224.874560</td>\n",
       "      <td>1110.220538</td>\n",
       "      <td>134.798531</td>\n",
       "      <td>135.858384</td>\n",
       "      <td>109.271915</td>\n",
       "      <td>29.323465</td>\n",
       "      <td>1704.716715</td>\n",
       "      <td>-284.353318</td>\n",
       "      <td>-15.319536</td>\n",
       "      <td>-1099.592092</td>\n",
       "      <td>...</td>\n",
       "      <td>-1719.736333</td>\n",
       "      <td>-2192.002637</td>\n",
       "      <td>1513.234184</td>\n",
       "      <td>523.058557</td>\n",
       "      <td>1603.211181</td>\n",
       "      <td>2422.347525</td>\n",
       "      <td>218.967561</td>\n",
       "      <td>-66.321636</td>\n",
       "      <td>-200.393450</td>\n",
       "      <td>-107.128517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2633.277779</td>\n",
       "      <td>703.512999</td>\n",
       "      <td>-165.584181</td>\n",
       "      <td>-128.673356</td>\n",
       "      <td>-351.196493</td>\n",
       "      <td>-369.996116</td>\n",
       "      <td>-3669.094187</td>\n",
       "      <td>-871.937556</td>\n",
       "      <td>-752.247876</td>\n",
       "      <td>-503.572274</td>\n",
       "      <td>...</td>\n",
       "      <td>-616.963790</td>\n",
       "      <td>603.136888</td>\n",
       "      <td>-608.460701</td>\n",
       "      <td>-1332.047832</td>\n",
       "      <td>-3012.228200</td>\n",
       "      <td>-2804.914271</td>\n",
       "      <td>-791.597461</td>\n",
       "      <td>-822.562965</td>\n",
       "      <td>-356.240988</td>\n",
       "      <td>-118.945277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>256.289641</td>\n",
       "      <td>599.953746</td>\n",
       "      <td>10.855725</td>\n",
       "      <td>32.230306</td>\n",
       "      <td>-150.404626</td>\n",
       "      <td>-107.055211</td>\n",
       "      <td>472.978958</td>\n",
       "      <td>649.045998</td>\n",
       "      <td>130.401624</td>\n",
       "      <td>-85.434102</td>\n",
       "      <td>...</td>\n",
       "      <td>-317.885924</td>\n",
       "      <td>-670.024556</td>\n",
       "      <td>62.647813</td>\n",
       "      <td>986.709609</td>\n",
       "      <td>-1459.773538</td>\n",
       "      <td>-1367.048968</td>\n",
       "      <td>-141.267965</td>\n",
       "      <td>-197.021311</td>\n",
       "      <td>-217.041629</td>\n",
       "      <td>-277.950585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MUSE_Volume_4  MUSE_Volume_11  MUSE_Volume_23  MUSE_Volume_30  \\\n",
       "0     -401.428503     -475.082401      -38.009137      -25.646775   \n",
       "9      596.355045     -177.499304       34.866428      -42.623326   \n",
       "24     224.874560     1110.220538      134.798531      135.858384   \n",
       "31    2633.277779      703.512999     -165.584181     -128.673356   \n",
       "45     256.289641      599.953746       10.855725       32.230306   \n",
       "\n",
       "    MUSE_Volume_31  MUSE_Volume_32  MUSE_Volume_35  MUSE_Volume_36  \\\n",
       "0        75.669198      126.590353      124.482040       54.813183   \n",
       "9        36.073837       53.399103     -914.581355     -108.931623   \n",
       "24      109.271915       29.323465     1704.716715     -284.353318   \n",
       "31     -351.196493     -369.996116    -3669.094187     -871.937556   \n",
       "45     -150.404626     -107.055211      472.978958      649.045998   \n",
       "\n",
       "    MUSE_Volume_37  MUSE_Volume_38  ...  MUSE_Volume_198  MUSE_Volume_199  \\\n",
       "0        29.901574     4088.590752  ...       789.359109      -170.422388   \n",
       "9       124.883198     -972.814733  ...      1335.363413      2649.942277   \n",
       "24      -15.319536    -1099.592092  ...     -1719.736333     -2192.002637   \n",
       "31     -752.247876     -503.572274  ...      -616.963790       603.136888   \n",
       "45      130.401624      -85.434102  ...      -317.885924      -670.024556   \n",
       "\n",
       "    MUSE_Volume_200  MUSE_Volume_201  MUSE_Volume_202  MUSE_Volume_203  \\\n",
       "0      -1543.880458     -1674.618225       632.563713      -531.585707   \n",
       "9       1411.230818        31.346635     -1267.747385       117.940453   \n",
       "24      1513.234184       523.058557      1603.211181      2422.347525   \n",
       "31      -608.460701     -1332.047832     -3012.228200     -2804.914271   \n",
       "45        62.647813       986.709609     -1459.773538     -1367.048968   \n",
       "\n",
       "    MUSE_Volume_204  MUSE_Volume_205  MUSE_Volume_206  MUSE_Volume_207  \n",
       "0        -39.623451       260.649954      -115.085767       -81.954942  \n",
       "9       -149.481247      -535.823873       -40.431290      -470.993059  \n",
       "24       218.967561       -66.321636      -200.393450      -107.128517  \n",
       "31      -791.597461      -822.562965      -356.240988      -118.945277  \n",
       "45      -141.267965      -197.021311      -217.041629      -277.950585  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs4575098</th>\n",
       "      <th>rs6656401</th>\n",
       "      <th>rs2093760</th>\n",
       "      <th>rs4844610</th>\n",
       "      <th>rs4663105</th>\n",
       "      <th>rs6733839</th>\n",
       "      <th>rs10933431</th>\n",
       "      <th>rs35349669</th>\n",
       "      <th>rs6448453</th>\n",
       "      <th>rs190982</th>\n",
       "      <th>...</th>\n",
       "      <th>rs28394864</th>\n",
       "      <th>rs111278892</th>\n",
       "      <th>rs3752246</th>\n",
       "      <th>rs4147929</th>\n",
       "      <th>rs41289512</th>\n",
       "      <th>rs3865444</th>\n",
       "      <th>rs6024870</th>\n",
       "      <th>rs6014724</th>\n",
       "      <th>rs7274581</th>\n",
       "      <th>rs429358</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs4575098  rs6656401  rs2093760  rs4844610  rs4663105  rs6733839  \\\n",
       "0           0          0          0          0          1          1   \n",
       "9           1          0          0          0          0          0   \n",
       "24          0          0          0          0          1          0   \n",
       "31          0          1          1          1          0          0   \n",
       "45          0          0          0          0          1          1   \n",
       "\n",
       "    rs10933431  rs35349669  rs6448453  rs190982  ...  rs28394864  rs111278892  \\\n",
       "0            1           0          0         1  ...           0            1   \n",
       "9            0           1          0         0  ...           1            0   \n",
       "24           1           0          0         1  ...           2            0   \n",
       "31           0           2          1         1  ...           1            0   \n",
       "45           0           1          0         0  ...           1            0   \n",
       "\n",
       "    rs3752246  rs4147929  rs41289512  rs3865444  rs6024870  rs6014724  \\\n",
       "0           1          1           0          0          0          0   \n",
       "9           1          1           0          1          0          0   \n",
       "24          0          0           0          1          0          0   \n",
       "31          0          0           1          1          0          0   \n",
       "45          0          0           1          1          0          0   \n",
       "\n",
       "    rs7274581  rs429358  \n",
       "0           0         1  \n",
       "9           0         0  \n",
       "24          0         0  \n",
       "31          0         2  \n",
       "45          0         1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"View 1:\")\n",
    "display(view_1.head())\n",
    "print(\"View 2:\")\n",
    "display(view_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8102d",
   "metadata": {},
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2abc22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a gpu exists, torch.device should be 'gpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 145\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 145 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "# this apparently can be different for each network, some experimentation is needed!\n",
    "layer_sizes1 = [256, 1024, 1024, outdim_size]\n",
    "layer_sizes2 = [256, 1024, 1024, outdim_size]\n",
    "# layer_sizes1 = [64, 128, outdim_size]\n",
    "# layer_sizes2 = [64, 128, outdim_size]\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-4\n",
    "epoch_num = 150\n",
    "epoch_log_freq = 50\n",
    "batch_size = 1000\n",
    "\n",
    "# the path to save the final learned features, as DCCA-o-d.\n",
    "save_to = './DATA/ADNI_DCCA_features_'+str(outdim_size)+'_'+str(len(layer_sizes1)-1)+'.pkl'\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-3\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top \n",
    "# outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = False\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32dded",
   "metadata": {},
   "source": [
    "###  Training the DCCA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4ebdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e14d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145) <class 'numpy.ndarray'> float64\n",
      "(1302, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1302, 145]) <class 'torch.Tensor'>\n",
      "torch.Size([1302, 54]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]\n",
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()\n",
    "# Scramble the datapoints for randomness:\n",
    "indices = np.arange(view_1_n.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "view_1_n = view_1_n[indices]\n",
    "view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))\n",
    "\n",
    "data1 = view_1_t\n",
    "data2 = view_2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f516e24f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation data: -107.6490\n",
      "loss on test data: -114.0847\n"
     ]
    }
   ],
   "source": [
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "l_cca = None\n",
    "if apply_linear_cca:\n",
    "    l_cca = linear_cca()\n",
    "    \n",
    "    \n",
    "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
    "                learning_rate, reg_par, device=device, epoch_log_freq=epoch_log_freq, log=False)\n",
    "s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "# Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "loss = solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "training_losses, val_losses = solver.get_losses()\n",
    "# TODO: Save linear_cca model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e11b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-137.345  -86.334]\n"
     ]
    }
   ],
   "source": [
    "set_size = [0, \n",
    "            train1.size(0), \n",
    "            train1.size(0) + val1.size(0), \n",
    "            train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "\n",
    "losses, outputs = solver._get_outputs(data1, data2)\n",
    "losses = np.round(losses,3)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b361e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1302, 145)\n",
      "<class 'numpy.ndarray'>\n",
      "(1302, 145)\n"
     ]
    }
   ],
   "source": [
    "print(type(outputs[0]))\n",
    "print(outputs[0].shape)\n",
    "print(type(outputs[1]))\n",
    "print(outputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0e965-1757-4085-857b-ffe541adb8db",
   "metadata": {},
   "source": [
    "### Plotting the Losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f371c9de-f4b6-40db-9545-493b85b720be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(epoch_num)\n",
    "plt.figure(figsize=(10, 8), dpi=90)\n",
    "plt.plot(x, training_losses, color='blue', label=\"Training Loss\")\n",
    "plt.plot(x, val_losses, color='orange', label=\"Validation Loss\")\n",
    "plt.title(\"Losses for the training of the model\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (lower is better)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c952c-d01e-4a42-80c2-29395c1361b7",
   "metadata": {},
   "source": [
    "### Using GridSearch Cross with Validation to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede527bd-4bc2-47d9-aadb-c8532e8e5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145) <class 'numpy.ndarray'> float64\n",
      "(1302, 54) <class 'numpy.ndarray'> float64\n",
      "torch.Size([1302, 145]) <class 'torch.Tensor'>\n",
      "torch.Size([1302, 54]) <class 'torch.Tensor'>\n",
      "Variation  1 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0691\n",
      "loss on test data: -2.5383\n",
      "-2.538331363387658\n",
      "Variation  2 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.8383\n",
      "loss on test data: -2.4037\n",
      "-2.4036840246919575\n",
      "Variation  3 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.8182\n",
      "loss on test data: -2.3320\n",
      "-2.332039944771727\n",
      "Variation  4 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0932\n",
      "loss on test data: -2.5228\n",
      "-2.5228437796930177\n",
      "Variation  5 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.7835\n",
      "loss on test data: -2.4164\n",
      "-2.4164275830629833\n",
      "Variation  6 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.1342\n",
      "loss on test data: -2.5150\n",
      "-2.515028647920019\n",
      "Variation  7 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0055\n",
      "loss on test data: -2.4993\n",
      "-2.4992659766340055\n",
      "Variation  8 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.8598\n",
      "loss on test data: -2.3761\n",
      "-2.3761181986313114\n",
      "Variation  9 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9781\n",
      "loss on test data: -2.2706\n",
      "-2.2706065251299146\n",
      "Variation  10 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.8812\n",
      "loss on test data: -2.0095\n",
      "-2.0094800210471373\n",
      "Variation  11 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.8458\n",
      "loss on test data: -2.4007\n",
      "-2.4007457832718293\n",
      "Variation  12 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.8960\n",
      "loss on test data: -2.5432\n",
      "-2.543154274781208\n",
      "Variation  13 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.6837\n",
      "loss on test data: -2.1847\n",
      "-2.184651699088809\n",
      "Variation  14 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9329\n",
      "loss on test data: -2.4038\n",
      "-2.4038135320258727\n",
      "Variation  15 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.8629\n",
      "loss on test data: -2.1392\n",
      "-2.139220136978662\n",
      "Variation  16 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9229\n",
      "loss on test data: -2.2652\n",
      "-2.2651903518714773\n",
      "Variation  17 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9043\n",
      "loss on test data: -2.5600\n",
      "-2.5599781392721273\n",
      "Variation  18 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.8987\n",
      "loss on test data: -2.2831\n",
      "-2.283134395100727\n",
      "Variation  19 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0403\n",
      "loss on test data: -2.4460\n",
      "-2.4460350872907552\n",
      "Variation  20 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.8739\n",
      "loss on test data: -2.3043\n",
      "-2.304334811028916\n",
      "Variation  21 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9823\n",
      "loss on test data: -2.3525\n",
      "-2.3525092952339413\n",
      "Variation  22 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9983\n",
      "loss on test data: -2.4803\n",
      "-2.4802559311219814\n",
      "Variation  23 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9989\n",
      "loss on test data: -2.2908\n",
      "-2.290785926728601\n",
      "Variation  24 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9462\n",
      "loss on test data: -2.2144\n",
      "-2.2144247430276573\n",
      "Variation  25 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.7711\n",
      "loss on test data: -2.4342\n",
      "-2.4342450844643646\n",
      "Variation  26 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -2.1214\n",
      "loss on test data: -2.4909\n",
      "-2.4908911219743244\n",
      "Variation  27 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.0697\n",
      "loss on test data: -2.2574\n",
      "-2.2573549609098276\n",
      "Variation  28 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0143\n",
      "loss on test data: -2.3225\n",
      "-2.3225257462908093\n",
      "Variation  29 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -2.0530\n",
      "loss on test data: -2.6556\n",
      "-2.655592789384909\n",
      "Variation  30 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.0929\n",
      "loss on test data: -2.4908\n",
      "-2.4908239179779526\n",
      "Variation  31 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.8992\n",
      "loss on test data: -2.3747\n",
      "-2.374703330645125\n",
      "Variation  32 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -2.0289\n",
      "loss on test data: -2.3665\n",
      "-2.3665263370351908\n",
      "Variation  33 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.3077\n",
      "loss on test data: -2.2108\n",
      "-2.2107729301084698\n",
      "Variation  34 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.8813\n",
      "loss on test data: -2.1284\n",
      "-2.128418867248664\n",
      "Variation  35 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -2.1050\n",
      "loss on test data: -2.1742\n",
      "-2.174248523655061\n",
      "Variation  36 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9100\n",
      "loss on test data: -2.5478\n",
      "-2.5478157873547564\n",
      "Variation  37 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0706\n",
      "loss on test data: -2.7132\n",
      "-2.713239205402348\n",
      "Variation  38 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9905\n",
      "loss on test data: -2.6804\n",
      "-2.6804287660405146\n",
      "Variation  39 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9706\n",
      "loss on test data: -2.2194\n",
      "-2.2194006340186365\n",
      "Variation  40 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -2.2124\n",
      "loss on test data: -2.3048\n",
      "-2.3048143543923176\n",
      "Variation  41 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9415\n",
      "loss on test data: -2.6155\n",
      "-2.6155366785367113\n",
      "Variation  42 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.0177\n",
      "loss on test data: -2.3393\n",
      "-2.339331501508714\n",
      "Variation  43 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0961\n",
      "loss on test data: -2.6732\n",
      "-2.673246094483834\n",
      "Variation  44 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -2.0199\n",
      "loss on test data: -2.4793\n",
      "-2.4793288642782465\n",
      "Variation  45 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.7949\n",
      "loss on test data: -2.3295\n",
      "-2.3295060839845694\n",
      "Variation  46 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0747\n",
      "loss on test data: -2.2666\n",
      "-2.266626011971876\n",
      "Variation  47 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9843\n",
      "loss on test data: -2.1256\n",
      "-2.125628718999366\n",
      "Variation  48 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.3300\n",
      "loss on test data: -2.4072\n",
      "-2.407219126631223\n",
      "Variation  49 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0066\n",
      "loss on test data: -2.3398\n",
      "-2.3397944606819348\n",
      "Variation  50 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -2.1032\n",
      "loss on test data: -2.6199\n",
      "-2.6199484160803532\n",
      "Variation  51 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.0082\n",
      "loss on test data: -2.4211\n",
      "-2.4211428781292126\n",
      "Variation  52 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0594\n",
      "loss on test data: -2.1262\n",
      "-2.126175340059729\n",
      "Variation  53 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -2.0637\n",
      "loss on test data: -2.6034\n",
      "-2.6034224668137225\n",
      "Variation  54 : {'outdim': 10, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.1059\n",
      "loss on test data: -2.1715\n",
      "-2.171490757536721\n",
      "Variation  55 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9342\n",
      "loss on test data: -2.3699\n",
      "-2.3698603990155913\n",
      "Variation  56 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -2.1318\n",
      "loss on test data: -2.4164\n",
      "-2.4164472686535126\n",
      "Variation  57 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.0009\n",
      "loss on test data: -2.3990\n",
      "-2.3990351901277074\n",
      "Variation  58 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.8952\n",
      "loss on test data: -2.4771\n",
      "-2.477129534831049\n",
      "Variation  59 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9969\n",
      "loss on test data: -2.5068\n",
      "-2.5067838811014775\n",
      "Variation  60 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.1793\n",
      "loss on test data: -2.3354\n",
      "-2.335413417739923\n",
      "Variation  61 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -2.0069\n",
      "loss on test data: -2.5205\n",
      "-2.5204768363679126\n",
      "Variation  62 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -2.0878\n",
      "loss on test data: -2.6656\n",
      "-2.665585109988067\n",
      "Variation  63 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9452\n",
      "loss on test data: -2.8207\n",
      "-2.820742440757063\n",
      "Variation  64 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -1.9801\n",
      "loss on test data: -2.4311\n",
      "-2.4310879262707177\n",
      "Variation  65 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -1.8830\n",
      "loss on test data: -2.5233\n",
      "-2.523298696607251\n",
      "Variation  66 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9352\n",
      "loss on test data: -2.4448\n",
      "-2.4447646565419903\n",
      "Variation  67 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -1.7929\n",
      "loss on test data: -2.4821\n",
      "-2.4820998754544408\n",
      "Variation  68 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -1.9991\n",
      "loss on test data: -2.3069\n",
      "-2.3068675762537305\n",
      "Variation  69 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -2.1401\n",
      "loss on test data: -2.4131\n",
      "-2.4130618200065603\n",
      "Variation  70 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -2.1574\n",
      "loss on test data: -2.4243\n",
      "-2.4243034231635257\n",
      "Variation  71 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -2.1003\n",
      "loss on test data: -2.5354\n",
      "-2.53543416301019\n",
      "Variation  72 : {'outdim': 10, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -1.9477\n",
      "loss on test data: -2.4285\n",
      "-2.428503364688259\n",
      "Variation  73 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -21.7244\n",
      "loss on test data: -27.0160\n",
      "-27.015997870919488\n",
      "Variation  74 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -22.2237\n",
      "loss on test data: -27.9589\n",
      "-27.958908661211204\n",
      "Variation  75 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.1141\n",
      "loss on test data: -27.6094\n",
      "-27.609384186552635\n",
      "Variation  76 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -21.9842\n",
      "loss on test data: -27.5489\n",
      "-27.548908502253255\n",
      "Variation  77 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.0269\n",
      "loss on test data: -26.7901\n",
      "-26.79008340495549\n",
      "Variation  78 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.5151\n",
      "loss on test data: -27.7840\n",
      "-27.783961375895014\n",
      "Variation  79 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -21.8484\n",
      "loss on test data: -27.4193\n",
      "-27.419284116937245\n",
      "Variation  80 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -21.8583\n",
      "loss on test data: -27.0779\n",
      "-27.077932627345742\n",
      "Variation  81 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.0656\n",
      "loss on test data: -27.2537\n",
      "-27.253700309281044\n",
      "Variation  82 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -21.2657\n",
      "loss on test data: -26.7326\n",
      "-26.73255565141118\n",
      "Variation  83 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.2321\n",
      "loss on test data: -26.9111\n",
      "-26.9110963953973\n",
      "Variation  84 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.0570\n",
      "loss on test data: -27.1290\n",
      "-27.129007790809226\n",
      "Variation  85 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -21.4449\n",
      "loss on test data: -25.9503\n",
      "-25.950255314545153\n",
      "Variation  86 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -21.6302\n",
      "loss on test data: -25.3846\n",
      "-25.384571180481604\n",
      "Variation  87 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -21.2941\n",
      "loss on test data: -25.7218\n",
      "-25.721820137245277\n",
      "Variation  88 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -21.1868\n",
      "loss on test data: -25.4756\n",
      "-25.475636873440497\n",
      "Variation  89 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -21.2686\n",
      "loss on test data: -25.8246\n",
      "-25.824555398574212\n",
      "Variation  90 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -21.0363\n",
      "loss on test data: -25.0707\n",
      "-25.070699565650184\n",
      "Variation  91 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -22.4527\n",
      "loss on test data: -26.0820\n",
      "-26.082021803367944\n",
      "Variation  92 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -22.4695\n",
      "loss on test data: -27.8623\n",
      "-27.862296533866235\n",
      "Variation  93 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.3067\n",
      "loss on test data: -27.2363\n",
      "-27.236326568018256\n",
      "Variation  94 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -22.4008\n",
      "loss on test data: -27.2545\n",
      "-27.25453924893094\n",
      "Variation  95 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.4508\n",
      "loss on test data: -28.1410\n",
      "-28.140972274323275\n",
      "Variation  96 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.1806\n",
      "loss on test data: -27.5245\n",
      "-27.524455336863006\n",
      "Variation  97 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -22.1636\n",
      "loss on test data: -27.1929\n",
      "-27.19285596379489\n",
      "Variation  98 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -22.1534\n",
      "loss on test data: -27.0006\n",
      "-27.000646399104255\n",
      "Variation  99 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -21.8245\n",
      "loss on test data: -27.6888\n",
      "-27.688846171829983\n",
      "Variation  100 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -22.1598\n",
      "loss on test data: -27.1234\n",
      "-27.12338159976248\n",
      "Variation  101 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.2363\n",
      "loss on test data: -27.5688\n",
      "-27.568779780461423\n",
      "Variation  102 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.1497\n",
      "loss on test data: -27.3225\n",
      "-27.32253060204365\n",
      "Variation  103 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -22.0869\n",
      "loss on test data: -27.3539\n",
      "-27.353882712047323\n",
      "Variation  104 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -21.9430\n",
      "loss on test data: -27.1943\n",
      "-27.19432303453075\n",
      "Variation  105 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -21.8579\n",
      "loss on test data: -26.9805\n",
      "-26.980547036893327\n",
      "Variation  106 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -22.0841\n",
      "loss on test data: -26.9132\n",
      "-26.913227559342545\n",
      "Variation  107 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.1127\n",
      "loss on test data: -27.5691\n",
      "-27.5690663006883\n",
      "Variation  108 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -21.6335\n",
      "loss on test data: -26.9493\n",
      "-26.94925287952453\n",
      "Variation  109 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -13.4255\n",
      "loss on test data: -12.1623\n",
      "-12.162343998384012\n",
      "Variation  110 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -10.4860\n",
      "loss on test data: -12.1278\n",
      "-12.127794258398309\n",
      "Variation  111 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -16.9062\n",
      "loss on test data: -17.1074\n",
      "-17.107429800146495\n",
      "Variation  112 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -21.5544\n",
      "loss on test data: -26.2157\n",
      "-26.2157324029339\n",
      "Variation  113 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.5401\n",
      "loss on test data: -27.5092\n",
      "-27.509210448038562\n",
      "Variation  114 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -21.8427\n",
      "loss on test data: -27.4487\n",
      "-27.44867708174115\n",
      "Variation  115 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -22.1564\n",
      "loss on test data: -26.7500\n",
      "-26.75000887847997\n",
      "Variation  116 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -22.0623\n",
      "loss on test data: -27.0116\n",
      "-27.011569856636058\n",
      "Variation  117 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.0918\n",
      "loss on test data: -26.8231\n",
      "-26.823140122727384\n",
      "Variation  118 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -22.4007\n",
      "loss on test data: -26.9749\n",
      "-26.974891663186902\n",
      "Variation  119 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.0739\n",
      "loss on test data: -26.7434\n",
      "-26.743360965006914\n",
      "Variation  120 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.2547\n",
      "loss on test data: -27.0823\n",
      "-27.08228959696851\n",
      "Variation  121 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -21.1780\n",
      "loss on test data: -25.7750\n",
      "-25.775008720053474\n",
      "Variation  122 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -21.0795\n",
      "loss on test data: -25.8004\n",
      "-25.80043502743117\n",
      "Variation  123 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -21.3530\n",
      "loss on test data: -26.2025\n",
      "-26.202487376630415\n",
      "Variation  124 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -20.8658\n",
      "loss on test data: -25.5100\n",
      "-25.509992002618333\n",
      "Variation  125 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -20.9708\n",
      "loss on test data: -26.1694\n",
      "-26.16937904059704\n",
      "Variation  126 : {'outdim': 50, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -20.9392\n",
      "loss on test data: -25.6645\n",
      "-25.664533602030033\n",
      "Variation  127 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -22.0588\n",
      "loss on test data: -26.5601\n",
      "-26.560060655467304\n",
      "Variation  128 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -23.1538\n",
      "loss on test data: -26.5378\n",
      "-26.537777225269515\n",
      "Variation  129 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -20.8480\n",
      "loss on test data: -26.5131\n",
      "-26.51308487192511\n",
      "Variation  130 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -21.3580\n",
      "loss on test data: -26.6207\n",
      "-26.620685042303247\n",
      "Variation  131 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.0876\n",
      "loss on test data: -27.4825\n",
      "-27.482538720320814\n",
      "Variation  132 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.4422\n",
      "loss on test data: -28.1925\n",
      "-28.192537285764175\n",
      "Variation  133 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -22.5684\n",
      "loss on test data: -27.3822\n",
      "-27.38219365634857\n",
      "Variation  134 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -22.4233\n",
      "loss on test data: -27.7831\n",
      "-27.783092629824885\n",
      "Variation  135 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.1597\n",
      "loss on test data: -27.3871\n",
      "-27.387083447048912\n",
      "Variation  136 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -22.4184\n",
      "loss on test data: -27.2234\n",
      "-27.223439872945693\n",
      "Variation  137 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.4942\n",
      "loss on test data: -27.6589\n",
      "-27.658908305386184\n",
      "Variation  138 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.1140\n",
      "loss on test data: -27.2508\n",
      "-27.2507556679247\n",
      "Variation  139 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -22.1431\n",
      "loss on test data: -27.2327\n",
      "-27.232657170107146\n",
      "Variation  140 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -22.4878\n",
      "loss on test data: -27.4821\n",
      "-27.48214371749902\n",
      "Variation  141 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.0556\n",
      "loss on test data: -27.5375\n",
      "-27.53750838335955\n",
      "Variation  142 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -21.8914\n",
      "loss on test data: -27.2745\n",
      "-27.274499276850765\n",
      "Variation  143 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -22.0081\n",
      "loss on test data: -27.2928\n",
      "-27.29280742438649\n",
      "Variation  144 : {'outdim': 50, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.1827\n",
      "loss on test data: -27.2562\n",
      "-27.256160898530055\n",
      "Variation  145 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -33.0490\n",
      "loss on test data: -33.2871\n",
      "-33.287078837390645\n",
      "Variation  146 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -64.4163\n",
      "loss on test data: -80.9069\n",
      "-80.90687551805118\n",
      "Variation  147 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.7166\n",
      "loss on test data: -81.2924\n",
      "-81.29242071075342\n",
      "Variation  148 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -62.9825\n",
      "loss on test data: -77.7425\n",
      "-77.74245866528996\n",
      "Variation  149 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -64.5593\n",
      "loss on test data: -82.3594\n",
      "-82.35940259962521\n",
      "Variation  150 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.7842\n",
      "loss on test data: -81.8890\n",
      "-81.88898103182123\n",
      "Variation  151 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -63.1098\n",
      "loss on test data: -77.9000\n",
      "-77.89998212098075\n",
      "Variation  152 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -63.0508\n",
      "loss on test data: -78.1892\n",
      "-78.1891905371634\n",
      "Variation  153 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -63.4054\n",
      "loss on test data: -79.1565\n",
      "-79.15646168305467\n",
      "Variation  154 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -62.6479\n",
      "loss on test data: -77.5614\n",
      "-77.56144649665389\n",
      "Variation  155 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -63.1068\n",
      "loss on test data: -78.5075\n",
      "-78.50746692601265\n",
      "Variation  156 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -63.4284\n",
      "loss on test data: -78.6583\n",
      "-78.65826656855278\n",
      "Variation  157 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -60.4338\n",
      "loss on test data: -73.1840\n",
      "-73.18402621065995\n",
      "Variation  158 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -59.4024\n",
      "loss on test data: -71.8889\n",
      "-71.8888963852658\n",
      "Variation  159 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -59.7611\n",
      "loss on test data: -72.8815\n",
      "-72.88148928771409\n",
      "Variation  160 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -59.0353\n",
      "loss on test data: -70.6469\n",
      "-70.64694498344349\n",
      "Variation  161 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -59.2431\n",
      "loss on test data: -70.7830\n",
      "-70.78304492958041\n",
      "Variation  162 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -58.8125\n",
      "loss on test data: -71.0712\n",
      "-71.07121225482916\n",
      "Variation  163 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -59.5793\n",
      "loss on test data: -69.4277\n",
      "-69.42774659716693\n",
      "Variation  164 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -64.7380\n",
      "loss on test data: -82.6892\n",
      "-82.68920777562649\n",
      "Variation  165 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.9041\n",
      "loss on test data: -82.1098\n",
      "-82.10984897757936\n",
      "Variation  166 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -63.9434\n",
      "loss on test data: -80.4095\n",
      "-80.40946977260086\n",
      "Variation  167 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -65.3697\n",
      "loss on test data: -81.8106\n",
      "-81.81060831106394\n",
      "Variation  168 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.5405\n",
      "loss on test data: -82.3014\n",
      "-82.30140668906516\n",
      "Variation  169 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -63.8024\n",
      "loss on test data: -80.3860\n",
      "-80.38595416852827\n",
      "Variation  170 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -64.5767\n",
      "loss on test data: -81.4804\n",
      "-81.48038518060983\n",
      "Variation  171 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.4100\n",
      "loss on test data: -81.5145\n",
      "-81.51447745498257\n",
      "Variation  172 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -63.9202\n",
      "loss on test data: -80.8372\n",
      "-80.83723097134117\n",
      "Variation  173 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -64.0181\n",
      "loss on test data: -81.2738\n",
      "-81.2738282933218\n",
      "Variation  174 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.1781\n",
      "loss on test data: -81.2354\n",
      "-81.23536984120159\n",
      "Variation  175 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -63.8081\n",
      "loss on test data: -79.8350\n",
      "-79.83497351503081\n",
      "Variation  176 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -63.6416\n",
      "loss on test data: -79.7057\n",
      "-79.70566096664915\n",
      "Variation  177 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -63.8161\n",
      "loss on test data: -79.3483\n",
      "-79.3482647162378\n",
      "Variation  178 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -63.3272\n",
      "loss on test data: -79.1345\n",
      "-79.13451642785964\n",
      "Variation  179 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -63.0105\n",
      "loss on test data: -78.9909\n",
      "-78.99089154270723\n",
      "Variation  180 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -63.4121\n",
      "loss on test data: -78.8857\n",
      "-78.8856559605797\n",
      "Variation  181 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -33.3710\n",
      "loss on test data: -29.0476\n",
      "-29.047634791095376\n",
      "Variation  182 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -31.1271\n",
      "loss on test data: -25.3152\n",
      "-25.315235619111288\n",
      "Variation  183 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.0801\n",
      "loss on test data: -23.1935\n",
      "-23.19353088147674\n",
      "Variation  184 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -23.1454\n",
      "loss on test data: -26.3583\n",
      "-26.35833110095467\n",
      "Variation  185 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -46.0723\n",
      "loss on test data: -58.0150\n",
      "-58.01495036483931\n",
      "Variation  186 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -11.9437\n",
      "loss on test data: -9.8688\n",
      "-9.868846909335186\n",
      "Variation  187 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -63.5317\n",
      "loss on test data: -78.9603\n",
      "-78.96029075206262\n",
      "Variation  188 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -64.1469\n",
      "loss on test data: -79.7456\n",
      "-79.74555317705794\n",
      "Variation  189 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -63.0725\n",
      "loss on test data: -79.5422\n",
      "-79.54221048346517\n",
      "Variation  190 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -63.1049\n",
      "loss on test data: -77.9448\n",
      "-77.94483337085293\n",
      "Variation  191 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -64.0844\n",
      "loss on test data: -79.0010\n",
      "-79.00097361692656\n",
      "Variation  192 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -63.8233\n",
      "loss on test data: -79.2214\n",
      "-79.22138386745507\n",
      "Variation  193 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -60.2733\n",
      "loss on test data: -73.0752\n",
      "-73.07524839954391\n",
      "Variation  194 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -60.0625\n",
      "loss on test data: -73.2318\n",
      "-73.23182131812844\n",
      "Variation  195 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -60.5539\n",
      "loss on test data: -73.3037\n",
      "-73.30374319151424\n",
      "Variation  196 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -59.4808\n",
      "loss on test data: -71.4631\n",
      "-71.46308066991992\n",
      "Variation  197 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -59.3410\n",
      "loss on test data: -71.0437\n",
      "-71.04367269000174\n",
      "Variation  198 : {'outdim': 100, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -59.7140\n",
      "loss on test data: -71.9862\n",
      "-71.98619217010345\n",
      "Variation  199 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -59.2850\n",
      "loss on test data: -69.5025\n",
      "-69.50245507858972\n",
      "Variation  200 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -50.1342\n",
      "loss on test data: -46.3651\n",
      "-46.36506800826473\n",
      "Variation  201 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -65.0736\n",
      "loss on test data: -80.7438\n",
      "-80.74377734385106\n",
      "Variation  202 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -57.3595\n",
      "loss on test data: -64.9610\n",
      "-64.96103810099459\n",
      "Variation  203 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -64.4178\n",
      "loss on test data: -80.3367\n",
      "-80.3367395529455\n",
      "Variation  204 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -63.3578\n",
      "loss on test data: -79.1621\n",
      "-79.16205798969196\n",
      "Variation  205 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -64.2663\n",
      "loss on test data: -81.1306\n",
      "-81.13063975463223\n",
      "Variation  206 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -64.7356\n",
      "loss on test data: -82.0377\n",
      "-82.03765173643865\n",
      "Variation  207 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.6237\n",
      "loss on test data: -81.6050\n",
      "-81.60498358834153\n",
      "Variation  208 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -64.6167\n",
      "loss on test data: -81.2519\n",
      "-81.2518675205007\n",
      "Variation  209 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -64.5306\n",
      "loss on test data: -81.4897\n",
      "-81.48970767885697\n",
      "Variation  210 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.9122\n",
      "loss on test data: -81.7511\n",
      "-81.75109163071365\n",
      "Variation  211 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -63.8449\n",
      "loss on test data: -80.6607\n",
      "-80.66065635005648\n",
      "Variation  212 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -64.0749\n",
      "loss on test data: -80.9436\n",
      "-80.94358927814264\n",
      "Variation  213 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.1191\n",
      "loss on test data: -80.9493\n",
      "-80.94931674155949\n",
      "Variation  214 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -63.7353\n",
      "loss on test data: -79.4431\n",
      "-79.44310006562459\n",
      "Variation  215 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -64.0228\n",
      "loss on test data: -79.8626\n",
      "-79.86261901686356\n",
      "Variation  216 : {'outdim': 100, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -64.0283\n",
      "loss on test data: -80.1812\n",
      "-80.18123849442522\n",
      "Variation  217 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -42.7351\n",
      "loss on test data: -38.6357\n",
      "-38.635657867960674\n",
      "Variation  218 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -55.0267\n",
      "loss on test data: -49.3053\n",
      "-49.30530656586218\n",
      "Variation  219 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -62.4302\n",
      "loss on test data: -68.3782\n",
      "-68.37822546865824\n",
      "Variation  220 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -108.7503\n",
      "loss on test data: -111.6951\n",
      "-111.69508796881018\n",
      "Variation  221 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -122.1078\n",
      "loss on test data: -126.5354\n",
      "-126.53543729104608\n",
      "Variation  222 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -122.0357\n",
      "loss on test data: -125.8832\n",
      "-125.88319720113537\n",
      "Variation  223 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -116.9444\n",
      "loss on test data: -121.5536\n",
      "-121.55356682690928\n",
      "Variation  224 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -117.8565\n",
      "loss on test data: -123.0012\n",
      "-123.0012107749169\n",
      "Variation  225 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -118.3309\n",
      "loss on test data: -123.3044\n",
      "-123.30441587429843\n",
      "Variation  226 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -115.9476\n",
      "loss on test data: -120.2290\n",
      "-120.22898327714996\n",
      "Variation  227 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -117.0966\n",
      "loss on test data: -121.3136\n",
      "-121.31357796336411\n",
      "Variation  228 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -117.0072\n",
      "loss on test data: -121.7501\n",
      "-121.75006172637896\n",
      "Variation  229 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -108.6433\n",
      "loss on test data: -113.3244\n",
      "-113.32442766690167\n",
      "Variation  230 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -109.3964\n",
      "loss on test data: -114.3211\n",
      "-114.32108743313528\n",
      "Variation  231 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -109.2588\n",
      "loss on test data: -113.1029\n",
      "-113.10290935723881\n",
      "Variation  232 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -104.8075\n",
      "loss on test data: -109.0698\n",
      "-109.0697852511702\n",
      "Variation  233 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -104.2930\n",
      "loss on test data: -109.8164\n",
      "-109.81639119736239\n",
      "Variation  234 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256], 'hidden_layer_size2': [256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -105.2124\n",
      "loss on test data: -109.8410\n",
      "-109.84104860719117\n",
      "Variation  235 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -97.9835\n",
      "loss on test data: -92.3678\n",
      "-92.36784155132682\n",
      "Variation  236 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -122.9614\n",
      "loss on test data: -127.9782\n",
      "-127.97815230339546\n",
      "Variation  237 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -102.3353\n",
      "loss on test data: -98.5621\n",
      "-98.56207278968883\n",
      "Variation  238 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -118.5379\n",
      "loss on test data: -122.3410\n",
      "-122.34096054026092\n",
      "Variation  239 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -122.7941\n",
      "loss on test data: -127.9493\n",
      "-127.94928775409447\n",
      "Variation  240 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -122.9932\n",
      "loss on test data: -127.7646\n",
      "-127.76463285660459\n",
      "Variation  241 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -120.6387\n",
      "loss on test data: -125.8188\n",
      "-125.8187766595946\n",
      "Variation  242 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -122.1069\n",
      "loss on test data: -127.6249\n",
      "-127.6248936563866\n",
      "Variation  243 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -122.1589\n",
      "loss on test data: -127.7908\n",
      "-127.79084140458473\n",
      "Variation  244 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -121.2750\n",
      "loss on test data: -125.7833\n",
      "-125.78331598317814\n",
      "Variation  245 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -121.7678\n",
      "loss on test data: -127.4326\n",
      "-127.43264183607317\n",
      "Variation  246 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -122.3961\n",
      "loss on test data: -127.6417\n",
      "-127.64173612950486\n",
      "Variation  247 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -119.7992\n",
      "loss on test data: -124.4349\n",
      "-124.43494712866743\n",
      "Variation  248 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -119.7007\n",
      "loss on test data: -124.8080\n",
      "-124.80795372089042\n",
      "Variation  249 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -119.6478\n",
      "loss on test data: -124.7416\n",
      "-124.74156157778552\n",
      "Variation  250 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -118.7012\n",
      "loss on test data: -123.7425\n",
      "-123.74245555093724\n",
      "Variation  251 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -118.8495\n",
      "loss on test data: -123.5593\n",
      "-123.55932796329782\n",
      "Variation  252 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -119.4013\n",
      "loss on test data: -124.2774\n",
      "-124.27742686812479\n",
      "Variation  253 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -68.3746\n",
      "loss on test data: -57.9481\n",
      "-57.9481237728844\n",
      "Variation  254 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -49.6797\n",
      "loss on test data: -48.2592\n",
      "-48.25920662670867\n",
      "Variation  255 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -46.7725\n",
      "loss on test data: -41.1820\n",
      "-41.182030417850804\n",
      "Variation  256 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -32.8207\n",
      "loss on test data: -30.1981\n",
      "-30.198089915207696\n",
      "Variation  257 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -29.9394\n",
      "loss on test data: -31.4733\n",
      "-31.473334634603166\n",
      "Variation  258 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -22.6985\n",
      "loss on test data: -20.7825\n",
      "-20.782494933438414\n",
      "Variation  259 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -117.8882\n",
      "loss on test data: -122.2578\n",
      "-122.25779209581582\n",
      "Variation  260 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -119.5243\n",
      "loss on test data: -123.8182\n",
      "-123.81818378441895\n",
      "Variation  261 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -118.8380\n",
      "loss on test data: -123.9094\n",
      "-123.9094489084609\n",
      "Variation  262 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -116.5862\n",
      "loss on test data: -120.9530\n",
      "-120.95297206503555\n",
      "Variation  263 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -117.7425\n",
      "loss on test data: -122.6983\n",
      "-122.69834646438645\n",
      "Variation  264 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -118.1775\n",
      "loss on test data: -123.1404\n",
      "-123.14037942794654\n",
      "Variation  265 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -110.3288\n",
      "loss on test data: -114.8190\n",
      "-114.81899778190211\n",
      "Variation  266 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -109.4242\n",
      "loss on test data: -114.3672\n",
      "-114.36720016222834\n",
      "Variation  267 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -109.7315\n",
      "loss on test data: -114.4382\n",
      "-114.43824469027693\n",
      "Variation  268 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -106.7429\n",
      "loss on test data: -111.5904\n",
      "-111.59036449240458\n",
      "Variation  269 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -107.0308\n",
      "loss on test data: -111.4583\n",
      "-111.45825912864512\n",
      "Variation  270 : {'outdim': 150, 'hidden_layer_size1': [256, 256, 256, 256], 'hidden_layer_size2': [256, 256, 256, 256], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -106.1324\n",
      "loss on test data: -110.3701\n",
      "-110.37009680696809\n",
      "Variation  271 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -109.2996\n",
      "loss on test data: -109.0846\n",
      "-109.08458043441424\n",
      "Variation  272 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -69.4611\n",
      "loss on test data: -54.6613\n",
      "-54.66128273959085\n",
      "Variation  273 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -93.5788\n",
      "loss on test data: -68.0143\n",
      "-68.01432964857828\n",
      "Variation  274 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -91.5587\n",
      "loss on test data: -91.4046\n",
      "-91.40455627988305\n",
      "Variation  275 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -36.6673\n",
      "loss on test data: -24.7517\n",
      "-24.751653580885666\n",
      "Variation  276 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.01, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -114.5781\n",
      "loss on test data: -114.0116\n",
      "-114.0116377203087\n",
      "Variation  277 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -121.5799\n",
      "loss on test data: -126.7089\n",
      "-126.70894089916578\n",
      "Variation  278 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -122.6271\n",
      "loss on test data: -128.2165\n",
      "-128.21652915169182\n",
      "Variation  279 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -122.8284\n",
      "loss on test data: -128.6988\n",
      "-128.69881151305168\n",
      "Variation  280 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -121.8004\n",
      "loss on test data: -127.7328\n",
      "-127.73280978224875\n",
      "Variation  281 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -122.7661\n",
      "loss on test data: -128.6320\n",
      "-128.63199965644287\n",
      "Variation  282 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -123.4503\n",
      "loss on test data: -128.8204\n",
      "-128.82043919333248\n",
      "Variation  283 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.01}\n",
      "loss on validation data: -121.0142\n",
      "loss on test data: -126.2771\n",
      "-126.27706809037784\n",
      "Variation  284 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.001}\n",
      "loss on validation data: -121.3041\n",
      "loss on test data: -126.2130\n",
      "-126.21299268401683\n",
      "Variation  285 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 500, 'reg_par': 0.0001}\n",
      "loss on validation data: -120.7783\n",
      "loss on test data: -126.6393\n",
      "-126.63932777474822\n",
      "Variation  286 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.01}\n",
      "loss on validation data: -120.1696\n",
      "loss on test data: -125.5196\n",
      "-125.5196075143759\n",
      "Variation  287 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.001}\n",
      "loss on validation data: -120.8390\n",
      "loss on test data: -125.5963\n",
      "-125.59634900326442\n",
      "Variation  288 : {'outdim': 150, 'hidden_layer_size1': [1024, 1024, 1024, 1024], 'hidden_layer_size2': [1024, 1024, 1024, 1024], 'learning_rate': 0.0001, 'batch_sz': 1000, 'reg_par': 0.0001}\n",
      "loss on validation data: -120.5534\n",
      "loss on test data: -125.7934\n",
      "-125.79335052444779\n",
      "With a loss of -128.82043919333248, the configuration with the best Test loss was:\n",
      "{'batch_sz': 1000,\n",
      " 'hidden_layer_size1': [1024, 1024, 1024, 1024],\n",
      " 'hidden_layer_size2': [1024, 1024, 1024, 1024],\n",
      " 'learning_rate': 0.001,\n",
      " 'outdim': 150,\n",
      " 'reg_par': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# View 1:\n",
    "view_1 = unique.loc[:,\"MUSE_Volume_4\":\"MUSE_Volume_207\"]\n",
    "# View 2:\n",
    "view_2 = unique.loc[:,\"rs4575098\":\"rs429358\"]\n",
    "# Convert the pandas dataframe to numpy arrays for pytorch:\n",
    "view_1_n = view_1.to_numpy()\n",
    "view_2_n = view_2.to_numpy()\n",
    "# Scramble the datapoints for randomness:\n",
    "indices = np.arange(view_1_n.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "view_1_n = view_1_n[indices]\n",
    "view_2_n = view_2_n[indices].astype(np.float64) # DeepCCA MLP requires double type\n",
    "\n",
    "print(view_1_n.shape, type(view_1_n), view_1_n.dtype)\n",
    "print(view_2_n.shape, type(view_2_n), view_2_n.dtype)\n",
    "\n",
    "view_1_t = torch.from_numpy(view_1_n)\n",
    "print(view_1_t.shape, type(view_1_t))\n",
    "view_2_t = torch.from_numpy(view_2_n)\n",
    "print(view_2_t.shape, type(view_2_t))\n",
    "\n",
    "data1 = view_1_t\n",
    "data2 = view_2_t\n",
    "\n",
    "# Standard parameters that shouldn't be changed:\n",
    "input_shape1 = 145 # view_1.shape[1]\n",
    "input_shape2 = 54  # view_2.shape[2]\n",
    "epoch_log_freq = 50\n",
    "use_all_singular_values = False\n",
    "apply_linear_cca = True\n",
    "epoch_num = 100\n",
    "# Parameters that should be explored, example values:\n",
    "outdim_sizes = [10,50,100,150]\n",
    "hidden_layer_sizes = [[256,256,256],\n",
    "                      [1024,1024,1024],\n",
    "                      [256,256,256,256],\n",
    "                      [1024,1024,1024,1024]]\n",
    "learning_rates = [1e-2,1e-3,1e-4]\n",
    "batch_sizes = [500,1000]\n",
    "reg_pars = [1e-2,1e-3,1e-4]\n",
    "\n",
    "results = []\n",
    "best_test_loss = (1000,None)\n",
    "count=0\n",
    "\n",
    "for outdim_size in outdim_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        hidden_layer_size1 = hidden_layer_size\n",
    "        hidden_layer_size2 = hidden_layer_size\n",
    "        for learning_rate in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                for reg_par in reg_pars:\n",
    "                    count += 1\n",
    "                    parameters = {\"outdim\": outdim_size,\n",
    "                                  \"hidden_layer_size1\": hidden_layer_size1,\n",
    "                                  \"hidden_layer_size2\": hidden_layer_size2,\n",
    "                                  \"learning_rate\": learning_rate,\n",
    "                                  \"batch_sz\": batch_size,\n",
    "                                  \"reg_par\": reg_par}\n",
    "                    print(\"Variation \", count, \":\", parameters)\n",
    "                    layer_sizes1 = hidden_layer_size1 + [outdim_size]\n",
    "                    layer_sizes2 = hidden_layer_size2 + [outdim_size]\n",
    "\n",
    "                    model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1, input_shape2, outdim_size, \n",
    "                                    use_all_singular_values, device=device).double()\n",
    "\n",
    "                    solver = Solver(model, linear_cca(), outdim_size, epoch_num, batch_size,\n",
    "                                    learning_rate, reg_par, device=device, epoch_log_freq=epoch_log_freq, log=False)\n",
    "                    s_1, s_2 = data1.shape[0], data2.shape[0]\n",
    "\n",
    "                    # Split the dataset into training, validation and testing (75%-15%-10%):\n",
    "                    train1, train2 = data1[0:int(s_1 * 0.75)], data2[0:int(s_2 * 0.75)]\n",
    "                    val1, val2 = data1[int(s_1 * 0.75):int(s_1 * 0.9)], data2[int(s_2 * 0.75):int(s_2 * 0.9)]\n",
    "                    test1, test2 = data1[int(s_1 * 0.9):], data2[int(s_2 * 0.9):]\n",
    "\n",
    "                    test_loss = solver.fit(train1, train2, val1, val2, test1, test2, checkpoint=None)\n",
    "                    print(test_loss)\n",
    "                    if test_loss < best_test_loss[0]:\n",
    "                        best_test_loss = (test_loss, parameters)\n",
    "                    training_losses, val_losses = solver.get_losses()\n",
    "                    results.append((training_losses, val_losses, test_loss, parameters))\n",
    "\n",
    "print(\"With a loss of \" + str(best_test_loss[0]) + \", the configuration with the best Test loss was:\")\n",
    "pprint.pprint(best_test_loss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f51ce4-4b49-4111-9c70-db71429824c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GridSearch_Results\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(results, fp)\n",
    "\n",
    "with open(\"GridSearch_Results\", \"rb\") as fp:   # Unpickling\n",
    "    results = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e3e90",
   "metadata": {},
   "source": [
    "### Saving the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e23a5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving new features in a gzip pickled file specified by save_to\n",
    "with open(save_to, 'wb') as f:\n",
    "    pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f517c8f",
   "metadata": {},
   "source": [
    "### Loading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bacfa2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = torch.load('checkpoint.model')\n",
    "# solver.model.load_state_dict(d)\n",
    "# solver.model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d09c7-c1b5-4c68-bf8f-d1d96b320925",
   "metadata": {},
   "source": [
    "## Testing the Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5022e0f",
   "metadata": {},
   "source": [
    "### Testing the Correlation between inputs and outputs of the deep Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "019cb979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA on input data:\n",
      "-0.42426306714130085\n",
      "CCA on output data:\n",
      "0.27795515365866535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "print(\"CCA on input data:\")\n",
    "X = data1\n",
    "Y = data2\n",
    "cca = CCA(n_components=50)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "print(cca.score(X, Y))\n",
    "\n",
    "print(\"CCA on output data:\")\n",
    "X = outputs[0]\n",
    "Y = outputs[1]\n",
    "cca = CCA(n_components=50,max_iter=10000)\n",
    "cca.fit(X, Y)\n",
    "X_c, Y_c = cca.transform(X, Y)\n",
    "# The best possible score is 1.0 and it can be negative \n",
    "# (because the model can be arbitrarily worse)\n",
    "print(cca.score(X, Y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16aa69",
   "metadata": {},
   "source": [
    "### (Imaging) Training and testing of SVM with linear kernel on the view 1 with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a074bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 10}\n",
      "Untrained Accuracy:  51.381\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    48.849\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_1, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[0], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84180f5",
   "metadata": {},
   "source": [
    "### (Genetic) Training and testing of SVM with linear kernel on the view 2 with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678964ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.0001}\n",
      "Untrained Accuracy:  48.08\n",
      "Best Parameters for trained data: {'C': 0.01}\n",
      "Trained Accuracy:    46.929\n"
     ]
    }
   ],
   "source": [
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = view_2, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = outputs[1], unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017fe62",
   "metadata": {},
   "source": [
    "### (Imaging + Genetic) Training and testing of SVM with linear kernel on both views with new features vs old features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461324ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302, 145)\n",
      "(1302, 145)\n",
      "(1302, 290)\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)\n",
    "both = np.concatenate((outputs[0], outputs[1]), axis=1)\n",
    "print(both.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12fd3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for untrained data: {'C': 0.1}\n",
      "Untrained Accuracy:  52.988\n",
      "Best Parameters for trained data: {'C': 0.001}\n",
      "Trained Accuracy:    48.695\n"
     ]
    }
   ],
   "source": [
    "c = list(unique.columns)\n",
    "MRI_columns = c[c.index(\"MUSE_Volume_4\"):c.index(\"MUSE_Volume_207\")+1]\n",
    "genetic_columns = c[c.index(\"rs4575098\"):c.index(\"rs429358\")+1]\n",
    "columns_of_interest = []\n",
    "columns_of_interest += MRI_columns + genetic_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = unique[columns_of_interest] , unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for untrained data:\",clf.best_params_)\n",
    "acc_untrained = clf.best_score_\n",
    "print(\"Untrained Accuracy: \", round(np.mean(acc_untrained)*100,3))\n",
    "\n",
    "s = svm.LinearSVC(dual=False)\n",
    "X , Y = both, unique[\"Diagnosis_nearest_2.0_cat\"]\n",
    "parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(s, parameters, n_jobs=-1, cv=10)\n",
    "clf.fit(X,Y)\n",
    "print(\"Best Parameters for trained data:\",clf.best_params_)\n",
    "acc_trained = clf.best_score_\n",
    "print(\"Trained Accuracy:   \", round(np.mean(acc_trained)*100,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
